{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"centraal-client-flow \u00b6 centraal-client-flow es una librer\u00eda de Python dise\u00f1ada para facilitar la implementaci\u00f3n de una una soluci\u00f3n basada en eventos para la sincronizaci\u00f3n y consistencia de datos entre sistemas distribuidos de clientes utilizando Azure. Esta librer\u00eda proporciona herramientas para manejar eventos, aplicar reglas de procesamiento, integrar con sistemas externos y mantener un esquema unificado de clientes. Introducci\u00f3n \u00b6 Centraal-Cliente-Flow facilita la implementaci\u00f3n de arquitecturas de sincronizaci\u00f3n de datos en Azure, proporcionando una base s\u00f3lida para manejar eventos en tiempo real, reglas de negocio, integraci\u00f3n con APIs externas y mantenimiento de un log de auditor\u00eda. Arquitectura \u00b6 La arquitectura est\u00e1 dise\u00f1ada para unificar la informaci\u00f3n de los clientes alrededor de un identificador \u00fanico, asegurando la consistencia de los datos a trav\u00e9s de los siguientes componentes clave: Eventos : Gestionados por Azure Functions para manejar eventos entrantes en tiempo real y operaciones peri\u00f3dicas de extracci\u00f3n de datos. Reglas : Implementan la l\u00f3gica de procesamiento de eventos para actualizar un esquema unificado de clientes. Reglas de Integraci\u00f3n : Sincronizan las actualizaciones del esquema unificado con sistemas externos a trav\u00e9s de APIs REST. Esquema Unificado : Modelo de datos centralizado que asegura consistencia y escalabilidad en la informaci\u00f3n de los clientes. Log de Auditor\u00eda : Registra todas las actualizaciones del esquema unificado para asegurar trazabilidad. Uso de Pydantic : La libreria hace uso extensivo e incentiva que cada intercambio de datos este mediado por modelos Pydantic , ya de esta manera se asegura calidad y reglas de negocio. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 Evento ^ | v +------------------------------+ | Receiver/Timer Function | | (Valida y env\u00eda a la cola | | usando Pydantic) | +------------------------------+ | | [P]-EventoBase(IdModel) | v +------------------------------+ | Azure Service Bus Queue | | (Ordena eventos por | | Session ID) | +------------------------------+ | v +---------------------------------------+ | Processor Function | | Reglas de Actualizaci\u00f3n | | (Actualiza esquema y log de | | auditor\u00eda usando Pydantic, | | Publica actualizaciones) | +---------------------------------------+ | | | | [P]-EntradaEsquemaUnificado [P] - AuditoriaEntry | | | v v +-----------------------+ +-------------------------+ | Cosmos DB | | Azure Service Bus | | (Esquema Unificado y | | Topic | | Log de Auditor\u00eda) | | | +-----------------------+ +-------------------------+ | | | | [P]-AuditoriaEntry | | | v v +-----------------------+ +-------------------------+ | Log de Auditor\u00eda en | | Integration Function | | Cosmos DB | | Reglas y Estrategias | | (Registra cambios) | | de Integraci\u00f3n | +-----------------------+ | | | | +-------------------------+ | [P]-BaseModel | v +-------------------------+ | Sistemas Externos | | (Reciben actualizaciones| | a trav\u00e9s de APIs REST) | +-------------------------+ Componentes Clave \u00b6 1. Eventos \u00b6 Receiver Functions : Manejan eventos entrantes en tiempo real. Implementadas en el m\u00f3dulo receiver.py utilizando clases como EventFunctionBuilder . Timer Functions : Ejecutan tareas peri\u00f3dicas para extraer informaci\u00f3n de sistemas externos, definidas en timer.py usando TimerFunctionBuilder . 2. Reglas de Procesamiento \u00b6 Las reglas para actualizar el esquema unificado de clientes se implementan usando UpdateProcessor y RuleProcessor , que permiten procesar y aplicar reglas espec\u00edficas a los eventos entrantes. 3. Reglas de Integraci\u00f3n \u00b6 Se implementan en strategy.py usando la clase RESTIntegration , que permite la sincronizaci\u00f3n de datos con APIs REST externas. 4. Esquema Unificado \u00b6 Definido en schemas.py , utiliza modelos Pydantic para asegurar la validaci\u00f3n y consistencia de datos. Los modelos incluyen IDModel , EntradaEsquemaUnificado , y otros sub-esquemas espec\u00edficos. 5. Log de Auditor\u00eda \u00b6 Para asegurar la trazabilidad de las actualizaciones, todos los cambios en los sub-esquemas se registran en una colecci\u00f3n de auditor\u00eda en Cosmos DB. Uso de la Librer\u00eda \u00b6 1. Configuraci\u00f3n Inicial \u00b6 Aseg\u00farate de tener configuradas las variables de entorno necesarias para las conexiones a Cosmos DB y Azure Service Bus. 1 2 3 4 5 import os os . environ [ \"COSMOS_CONN\" ] = \"<tu_cosmos_db_connection_string>\" os . environ [ \"DATABASE\" ] = \"<tu_database_name>\" os . environ [ \"BUS_CONN\" ] = \"<tu_service_bus_connection_string>\" 2. Registrar Funciones de Azure \u00b6 Eventos \u00b6 Utiliza el siguiente ejemplo para registrar funciones receptoras y de temporizaci\u00f3n. 1 2 3 4 5 6 7 8 9 10 11 12 13 from azure.functions import FunctionApp from centraal_client_flow.receiver import Recieve from centraal_client_flow.timer import Pull app = FunctionApp () # Registrar funci\u00f3n receptora receiver = Recieve ( event_source = \"source_name\" , queue_name = \"queue_name\" , service_bus_client = service_bus_client_instance ) receiver . register_function ( app , processor = event_processor_instance , event_model = event_model_instance ) # Registrar funci\u00f3n de temporizaci\u00f3n pull = Pull ( schedule = \"0 */5 * * * *\" , event_source = \"source_name\" , queue_name = \"queue_name\" , service_bus_client = service_bus_client_instance ) pull . register_function ( app , processor = pull_processor_instance ) Reglas de Actualizaci\u00f3n \u00b6 1 2 3 4 5 from azure.functions import FunctionApp from update_rules import bp_update_rules app = FunctionApp () app . register_functions ( bp_update_rules ) Reglas de Integraci\u00f3n \u00b6 1 2 3 4 5 from azure.functions import FunctionApp from integration_rules import bp_int_rules app = FunctionApp () app . register_functions ( bp_int_rules ) 3. Definir Modelos y Procesadores \u00b6 Define los modelos de datos utilizando Pydantic para asegurar la validaci\u00f3n de datos entrantes. 1 2 3 4 5 6 from pydantic import BaseModel , EmailStr class EventoEjemplo ( BaseModel ): id : int nombre : str email : EmailStr Implementa procesadores para manejar la l\u00f3gica de actualizaci\u00f3n de acuerdo con las reglas de negocio. 1 2 3 4 5 6 7 from centraal_client_flow.rules.update import UpdateProcessor from modelos import EventoEjemplo class EjemploProcessor ( UpdateProcessor ): def process_message ( self , event : EventoEjemplo , current_registro = None ): # L\u00f3gica de procesamiento de eventos pass 4. Ejecutar la Aplicaci\u00f3n \u00b6 Aseg\u00farate de que todas las dependencias est\u00e9n instaladas y ejecuta la aplicaci\u00f3n utilizando un servidor de funciones de Azure. 1 func start Contribuciones \u00b6 Las contribuciones son bienvenidas. Por favor, abre un issue o un pull request en el repositorio para discutir cualquier cambio. Free software: Apache-2.0 Documentation: https://centraal-api.github.io/centraal_client_flow/ Credits \u00b6 This package was created with the ppw tool. For more information, please visit the project page .","title":"home"},{"location":"#centraal-client-flow","text":"centraal-client-flow es una librer\u00eda de Python dise\u00f1ada para facilitar la implementaci\u00f3n de una una soluci\u00f3n basada en eventos para la sincronizaci\u00f3n y consistencia de datos entre sistemas distribuidos de clientes utilizando Azure. Esta librer\u00eda proporciona herramientas para manejar eventos, aplicar reglas de procesamiento, integrar con sistemas externos y mantener un esquema unificado de clientes.","title":"centraal-client-flow"},{"location":"#introducci\u00f3n","text":"Centraal-Cliente-Flow facilita la implementaci\u00f3n de arquitecturas de sincronizaci\u00f3n de datos en Azure, proporcionando una base s\u00f3lida para manejar eventos en tiempo real, reglas de negocio, integraci\u00f3n con APIs externas y mantenimiento de un log de auditor\u00eda.","title":"Introducci\u00f3n"},{"location":"#arquitectura","text":"La arquitectura est\u00e1 dise\u00f1ada para unificar la informaci\u00f3n de los clientes alrededor de un identificador \u00fanico, asegurando la consistencia de los datos a trav\u00e9s de los siguientes componentes clave: Eventos : Gestionados por Azure Functions para manejar eventos entrantes en tiempo real y operaciones peri\u00f3dicas de extracci\u00f3n de datos. Reglas : Implementan la l\u00f3gica de procesamiento de eventos para actualizar un esquema unificado de clientes. Reglas de Integraci\u00f3n : Sincronizan las actualizaciones del esquema unificado con sistemas externos a trav\u00e9s de APIs REST. Esquema Unificado : Modelo de datos centralizado que asegura consistencia y escalabilidad en la informaci\u00f3n de los clientes. Log de Auditor\u00eda : Registra todas las actualizaciones del esquema unificado para asegurar trazabilidad. Uso de Pydantic : La libreria hace uso extensivo e incentiva que cada intercambio de datos este mediado por modelos Pydantic , ya de esta manera se asegura calidad y reglas de negocio. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 Evento ^ | v +------------------------------+ | Receiver/Timer Function | | (Valida y env\u00eda a la cola | | usando Pydantic) | +------------------------------+ | | [P]-EventoBase(IdModel) | v +------------------------------+ | Azure Service Bus Queue | | (Ordena eventos por | | Session ID) | +------------------------------+ | v +---------------------------------------+ | Processor Function | | Reglas de Actualizaci\u00f3n | | (Actualiza esquema y log de | | auditor\u00eda usando Pydantic, | | Publica actualizaciones) | +---------------------------------------+ | | | | [P]-EntradaEsquemaUnificado [P] - AuditoriaEntry | | | v v +-----------------------+ +-------------------------+ | Cosmos DB | | Azure Service Bus | | (Esquema Unificado y | | Topic | | Log de Auditor\u00eda) | | | +-----------------------+ +-------------------------+ | | | | [P]-AuditoriaEntry | | | v v +-----------------------+ +-------------------------+ | Log de Auditor\u00eda en | | Integration Function | | Cosmos DB | | Reglas y Estrategias | | (Registra cambios) | | de Integraci\u00f3n | +-----------------------+ | | | | +-------------------------+ | [P]-BaseModel | v +-------------------------+ | Sistemas Externos | | (Reciben actualizaciones| | a trav\u00e9s de APIs REST) | +-------------------------+","title":"Arquitectura"},{"location":"#componentes-clave","text":"","title":"Componentes Clave"},{"location":"#1-eventos","text":"Receiver Functions : Manejan eventos entrantes en tiempo real. Implementadas en el m\u00f3dulo receiver.py utilizando clases como EventFunctionBuilder . Timer Functions : Ejecutan tareas peri\u00f3dicas para extraer informaci\u00f3n de sistemas externos, definidas en timer.py usando TimerFunctionBuilder .","title":"1. Eventos"},{"location":"#2-reglas-de-procesamiento","text":"Las reglas para actualizar el esquema unificado de clientes se implementan usando UpdateProcessor y RuleProcessor , que permiten procesar y aplicar reglas espec\u00edficas a los eventos entrantes.","title":"2. Reglas de Procesamiento"},{"location":"#3-reglas-de-integraci\u00f3n","text":"Se implementan en strategy.py usando la clase RESTIntegration , que permite la sincronizaci\u00f3n de datos con APIs REST externas.","title":"3. Reglas de Integraci\u00f3n"},{"location":"#4-esquema-unificado","text":"Definido en schemas.py , utiliza modelos Pydantic para asegurar la validaci\u00f3n y consistencia de datos. Los modelos incluyen IDModel , EntradaEsquemaUnificado , y otros sub-esquemas espec\u00edficos.","title":"4. Esquema Unificado"},{"location":"#5-log-de-auditor\u00eda","text":"Para asegurar la trazabilidad de las actualizaciones, todos los cambios en los sub-esquemas se registran en una colecci\u00f3n de auditor\u00eda en Cosmos DB.","title":"5. Log de Auditor\u00eda"},{"location":"#uso-de-la-librer\u00eda","text":"","title":"Uso de la Librer\u00eda"},{"location":"#1-configuraci\u00f3n-inicial","text":"Aseg\u00farate de tener configuradas las variables de entorno necesarias para las conexiones a Cosmos DB y Azure Service Bus. 1 2 3 4 5 import os os . environ [ \"COSMOS_CONN\" ] = \"<tu_cosmos_db_connection_string>\" os . environ [ \"DATABASE\" ] = \"<tu_database_name>\" os . environ [ \"BUS_CONN\" ] = \"<tu_service_bus_connection_string>\"","title":"1. Configuraci\u00f3n Inicial"},{"location":"#2-registrar-funciones-de-azure","text":"","title":"2. Registrar Funciones de Azure"},{"location":"#eventos","text":"Utiliza el siguiente ejemplo para registrar funciones receptoras y de temporizaci\u00f3n. 1 2 3 4 5 6 7 8 9 10 11 12 13 from azure.functions import FunctionApp from centraal_client_flow.receiver import Recieve from centraal_client_flow.timer import Pull app = FunctionApp () # Registrar funci\u00f3n receptora receiver = Recieve ( event_source = \"source_name\" , queue_name = \"queue_name\" , service_bus_client = service_bus_client_instance ) receiver . register_function ( app , processor = event_processor_instance , event_model = event_model_instance ) # Registrar funci\u00f3n de temporizaci\u00f3n pull = Pull ( schedule = \"0 */5 * * * *\" , event_source = \"source_name\" , queue_name = \"queue_name\" , service_bus_client = service_bus_client_instance ) pull . register_function ( app , processor = pull_processor_instance )","title":"Eventos"},{"location":"#reglas-de-actualizaci\u00f3n","text":"1 2 3 4 5 from azure.functions import FunctionApp from update_rules import bp_update_rules app = FunctionApp () app . register_functions ( bp_update_rules )","title":"Reglas de Actualizaci\u00f3n"},{"location":"#reglas-de-integraci\u00f3n","text":"1 2 3 4 5 from azure.functions import FunctionApp from integration_rules import bp_int_rules app = FunctionApp () app . register_functions ( bp_int_rules )","title":"Reglas de Integraci\u00f3n"},{"location":"#3-definir-modelos-y-procesadores","text":"Define los modelos de datos utilizando Pydantic para asegurar la validaci\u00f3n de datos entrantes. 1 2 3 4 5 6 from pydantic import BaseModel , EmailStr class EventoEjemplo ( BaseModel ): id : int nombre : str email : EmailStr Implementa procesadores para manejar la l\u00f3gica de actualizaci\u00f3n de acuerdo con las reglas de negocio. 1 2 3 4 5 6 7 from centraal_client_flow.rules.update import UpdateProcessor from modelos import EventoEjemplo class EjemploProcessor ( UpdateProcessor ): def process_message ( self , event : EventoEjemplo , current_registro = None ): # L\u00f3gica de procesamiento de eventos pass","title":"3. Definir Modelos y Procesadores"},{"location":"#4-ejecutar-la-aplicaci\u00f3n","text":"Aseg\u00farate de que todas las dependencias est\u00e9n instaladas y ejecuta la aplicaci\u00f3n utilizando un servidor de funciones de Azure. 1 func start","title":"4. Ejecutar la Aplicaci\u00f3n"},{"location":"#contribuciones","text":"Las contribuciones son bienvenidas. Por favor, abre un issue o un pull request en el repositorio para discutir cualquier cambio. Free software: Apache-2.0 Documentation: https://centraal-api.github.io/centraal_client_flow/","title":"Contribuciones"},{"location":"#credits","text":"This package was created with the ppw tool. For more information, please visit the project page .","title":"Credits"},{"location":"api/","text":"Top-level package for centraal-client-flow. connections special \u00b6 cosmosdb \u00b6 Modulo de conexi\u00f3n a cosmos. CosmosDBSingleton \u00b6 Singleton class for Cosmos DB client. Source code in centraal_client_flow/connections/cosmosdb.py class CosmosDBSingleton : \"\"\"Singleton class for Cosmos DB client.\"\"\" _instance : Optional [ \"CosmosDBSingleton\" ] = None _lock : Lock = Lock () def __new__ ( cls , connection_string : Optional [ str ] = None , database_name : Optional [ str ] = None , ) -> \"CosmosDBSingleton\" : if cls . _instance is None : with cls . _lock : if cls . _instance is None : cls . _instance = super () . __new__ ( cls ) return cls . _instance def __init__ ( self , connection_string : Optional [ str ] = None , database_name : Optional [ str ] = None , ) -> None : if not hasattr ( self , \"_initialized\" ): self . _initialized = False self . client : Optional [ CosmosClient ] = None self . database : Optional [ CosmosClient ] = None self . connection_string = connection_string or os . getenv ( \"COSMOS_CONNECTION_STRING\" ) self . database_name = database_name or os . getenv ( \"DATABASE_NAME\" ) def _initialize ( self ) -> None : \"\"\"Initialize the Cosmos DB client and database.\"\"\" if self . client is None or self . database is None : if not self . connection_string or not self . database_name : raise ValueError ( \"Connection string and database name must be provided\" ) self . client = CosmosClient . from_connection_string ( self . connection_string ) self . database = self . client . get_database_client ( self . database_name ) self . _initialized = True def get_container_client ( self , container_name : str ) -> ContainerProxy : \"\"\"Get a container client.\"\"\" self . _initialize () return self . database . get_container_client ( container_name ) def set_mock_client ( self , mock_client : CosmosClient , mock_database : CosmosClient ) -> None : \"\"\"Set a mock client and database for testing purposes.\"\"\" self . client = mock_client self . database = mock_database __new__ ( cls , connection_string = None , database_name = None ) special staticmethod \u00b6 Create and return a new object. See help(type) for accurate signature. Source code in centraal_client_flow/connections/cosmosdb.py def __new__ ( cls , connection_string : Optional [ str ] = None , database_name : Optional [ str ] = None , ) -> \"CosmosDBSingleton\" : if cls . _instance is None : with cls . _lock : if cls . _instance is None : cls . _instance = super () . __new__ ( cls ) return cls . _instance get_container_client ( self , container_name ) \u00b6 Get a container client. Source code in centraal_client_flow/connections/cosmosdb.py def get_container_client ( self , container_name : str ) -> ContainerProxy : \"\"\"Get a container client.\"\"\" self . _initialize () return self . database . get_container_client ( container_name ) set_mock_client ( self , mock_client , mock_database ) \u00b6 Set a mock client and database for testing purposes. Source code in centraal_client_flow/connections/cosmosdb.py def set_mock_client ( self , mock_client : CosmosClient , mock_database : CosmosClient ) -> None : \"\"\"Set a mock client and database for testing purposes.\"\"\" self . client = mock_client self . database = mock_database service_bus \u00b6 Conexiones a service bus. IServiceBusClient ( Protocol ) \u00b6 Interfaz. Source code in centraal_client_flow/connections/service_bus.py @runtime_checkable class IServiceBusClient ( Protocol ): \"\"\"Interfaz.\"\"\" client : Optional [ ServiceBusClient ] = None connection_str : Optional [ str ] = None def send_message_to_queue ( self , message : dict , session_id : str , queue_name : str ): \"\"\"Env\u00eda un mensaje a la cola de Service Bus especificada. Args: message: El mensaje a enviar representado como un diccionario. session_id: ID de sesi\u00f3n para el mensaje. Debe ser el id del modelo. queue_name: Nombre de la cola a la que se enviar\u00e1 el mensaje. \"\"\" send_message_to_queue ( self , message , session_id , queue_name ) \u00b6 Env\u00eda un mensaje a la cola de Service Bus especificada. Parameters: Name Type Description Default message dict El mensaje a enviar representado como un diccionario. required session_id str ID de sesi\u00f3n para el mensaje. Debe ser el id del modelo. required queue_name str Nombre de la cola a la que se enviar\u00e1 el mensaje. required Source code in centraal_client_flow/connections/service_bus.py def send_message_to_queue ( self , message : dict , session_id : str , queue_name : str ): \"\"\"Env\u00eda un mensaje a la cola de Service Bus especificada. Args: message: El mensaje a enviar representado como un diccionario. session_id: ID de sesi\u00f3n para el mensaje. Debe ser el id del modelo. queue_name: Nombre de la cola a la que se enviar\u00e1 el mensaje. \"\"\" ServiceBusClientSingleton ( IServiceBusClient ) \u00b6 Singleton para manejar la conexi\u00f3n a Azure Service Bus. Source code in centraal_client_flow/connections/service_bus.py class ServiceBusClientSingleton ( IServiceBusClient ): \"\"\"Singleton para manejar la conexi\u00f3n a Azure Service Bus.\"\"\" _instance = None client : Optional [ ServiceBusClient ] = None connection_str : Optional [ str ] = None senders = {} MAX_RETRIES = 3 RETRY_DELAY = 1 def __new__ ( cls , connection_str : str ): \"\"\"Crea una instancia \u00fanica de ServiceBusClientSingleton si no existe. Args: connection_str: Cadena de conexi\u00f3n a Azure Service Bus. \"\"\" if cls . _instance is None : cls . _instance = super ( ServiceBusClientSingleton , cls ) . __new__ ( cls ) cls . _instance . connection_str = connection_str cls . _instance . _initialize_client () return cls . _instance def _initialize_client ( self ): \"\"\"Initialize the Service Bus client with retry logic.\"\"\" for attempt in range ( self . MAX_RETRIES ): try : self . client = ServiceBusClient . from_connection_string ( self . connection_str ) logger . info ( \"Successfully initialized Service Bus client\" ) return except ( ServiceBusError , ServiceBusConnectionError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to initialize Service Bus client after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise logger . warning ( f \"Attempt { attempt + 1 } failed to initialize Service Bus client: { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) def _ensure_client_connection ( self ): \"\"\"Ensure the client is connected and valid.\"\"\" if not self . client : self . _initialize_client () return self . client def get_sender ( self , queue_name : str ): \"\"\"Get or create a sender for the specified queue with retry logic.\"\"\" if queue_name not in self . senders : for attempt in range ( self . MAX_RETRIES ): try : client = self . _ensure_client_connection () if queue_name in self . senders : try : self . senders [ queue_name ] . close () except Exception as e : logger . warning ( f \"Error closing existing sender: { str ( e ) } \" ) self . senders [ queue_name ] = client . get_queue_sender ( queue_name ) logger . info ( f \"Successfully created sender for queue: { queue_name } \" ) break except ( ServiceBusError , ServiceBusConnectionError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to create sender for queue { queue_name } after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise logger . warning ( f \"Attempt { attempt + 1 } failed to create sender for queue { queue_name } : { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) self . _initialize_client () # Try to reinitialize the client return self . senders [ queue_name ] def send_message_to_queue ( self , message : dict , session_id : str , queue_name : str ): \"\"\"Env\u00eda un mensaje a la cola de Service Bus especificada con retry logic.\"\"\" for attempt in range ( self . MAX_RETRIES ): try : sender = self . get_sender ( queue_name ) msg = ServiceBusMessage ( body = json . dumps ( message )) msg . session_id = session_id sender . send_messages ( msg ) logger . debug ( f \"Successfully sent message to queue { queue_name } with session_id { session_id } \" ) return except ( ServiceBusError , ServiceBusConnectionError , ServiceRequestError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to send message to queue { queue_name } after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise e logger . warning ( f \"Attempt { attempt + 1 } failed to send message to queue { queue_name } : { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) self . _initialize_client () if queue_name in self . senders : try : self . senders [ queue_name ] . close () except Exception as close_error : logger . warning ( f \"Error closing sender during retry: { str ( close_error ) } \" ) del self . senders [ queue_name ] def close ( self ): \"\"\"Cierra la conexi\u00f3n con Azure Service Bus.\"\"\" try : for queue_name , sender in list ( self . senders . items ()): try : sender . close () logger . info ( f \"Successfully closed sender for queue: { queue_name } \" ) except Exception as e : logger . warning ( f \"Error closing sender for queue { queue_name } : { str ( e ) } \" ) if self . client : try : self . client . close () logger . info ( \"Successfully closed Service Bus client\" ) except Exception as e : logger . warning ( f \"Error closing client: { str ( e ) } \" ) self . senders . clear () self . client = None logger . info ( \"Successfully closed all Service Bus connections\" ) except Exception as e : logger . error ( f \"Error during Service Bus cleanup: { str ( e ) } \" ) raise __new__ ( cls , connection_str ) special staticmethod \u00b6 Crea una instancia \u00fanica de ServiceBusClientSingleton si no existe. Parameters: Name Type Description Default connection_str str Cadena de conexi\u00f3n a Azure Service Bus. required Source code in centraal_client_flow/connections/service_bus.py def __new__ ( cls , connection_str : str ): \"\"\"Crea una instancia \u00fanica de ServiceBusClientSingleton si no existe. Args: connection_str: Cadena de conexi\u00f3n a Azure Service Bus. \"\"\" if cls . _instance is None : cls . _instance = super ( ServiceBusClientSingleton , cls ) . __new__ ( cls ) cls . _instance . connection_str = connection_str cls . _instance . _initialize_client () return cls . _instance close ( self ) \u00b6 Cierra la conexi\u00f3n con Azure Service Bus. Source code in centraal_client_flow/connections/service_bus.py def close ( self ): \"\"\"Cierra la conexi\u00f3n con Azure Service Bus.\"\"\" try : for queue_name , sender in list ( self . senders . items ()): try : sender . close () logger . info ( f \"Successfully closed sender for queue: { queue_name } \" ) except Exception as e : logger . warning ( f \"Error closing sender for queue { queue_name } : { str ( e ) } \" ) if self . client : try : self . client . close () logger . info ( \"Successfully closed Service Bus client\" ) except Exception as e : logger . warning ( f \"Error closing client: { str ( e ) } \" ) self . senders . clear () self . client = None logger . info ( \"Successfully closed all Service Bus connections\" ) except Exception as e : logger . error ( f \"Error during Service Bus cleanup: { str ( e ) } \" ) raise get_sender ( self , queue_name ) \u00b6 Get or create a sender for the specified queue with retry logic. Source code in centraal_client_flow/connections/service_bus.py def get_sender ( self , queue_name : str ): \"\"\"Get or create a sender for the specified queue with retry logic.\"\"\" if queue_name not in self . senders : for attempt in range ( self . MAX_RETRIES ): try : client = self . _ensure_client_connection () if queue_name in self . senders : try : self . senders [ queue_name ] . close () except Exception as e : logger . warning ( f \"Error closing existing sender: { str ( e ) } \" ) self . senders [ queue_name ] = client . get_queue_sender ( queue_name ) logger . info ( f \"Successfully created sender for queue: { queue_name } \" ) break except ( ServiceBusError , ServiceBusConnectionError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to create sender for queue { queue_name } after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise logger . warning ( f \"Attempt { attempt + 1 } failed to create sender for queue { queue_name } : { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) self . _initialize_client () # Try to reinitialize the client return self . senders [ queue_name ] send_message_to_queue ( self , message , session_id , queue_name ) \u00b6 Env\u00eda un mensaje a la cola de Service Bus especificada con retry logic. Source code in centraal_client_flow/connections/service_bus.py def send_message_to_queue ( self , message : dict , session_id : str , queue_name : str ): \"\"\"Env\u00eda un mensaje a la cola de Service Bus especificada con retry logic.\"\"\" for attempt in range ( self . MAX_RETRIES ): try : sender = self . get_sender ( queue_name ) msg = ServiceBusMessage ( body = json . dumps ( message )) msg . session_id = session_id sender . send_messages ( msg ) logger . debug ( f \"Successfully sent message to queue { queue_name } with session_id { session_id } \" ) return except ( ServiceBusError , ServiceBusConnectionError , ServiceRequestError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to send message to queue { queue_name } after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise e logger . warning ( f \"Attempt { attempt + 1 } failed to send message to queue { queue_name } : { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) self . _initialize_client () if queue_name in self . senders : try : self . senders [ queue_name ] . close () except Exception as close_error : logger . warning ( f \"Error closing sender during retry: { str ( close_error ) } \" ) del self . senders [ queue_name ] events special \u00b6 Codigo compartido por los submodulos. EventProcessor ( LoggerMixin , ABC ) \u00b6 Clase base abstracta para procesadores de eventos. Source code in centraal_client_flow/events/__init__.py class EventProcessor ( LoggerMixin , ABC ): \"\"\"Clase base abstracta para procesadores de eventos.\"\"\" @abstractmethod def process_event ( self , event : BaseModel ) -> EventoBase : \"\"\" Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: event: Objeto que corresponde a modelo pydantic. \"\"\" process_event ( self , event ) \u00b6 Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: Name Type Description Default event BaseModel Objeto que corresponde a modelo pydantic. required Source code in centraal_client_flow/events/__init__.py @abstractmethod def process_event ( self , event : BaseModel ) -> EventoBase : \"\"\" Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: event: Objeto que corresponde a modelo pydantic. \"\"\" PullProcessor ( LoggerMixin , ABC ) \u00b6 Clase base abstracta para procesadores de eventos. Source code in centraal_client_flow/events/__init__.py class PullProcessor ( LoggerMixin , ABC ): \"\"\"Clase base abstracta para procesadores de eventos.\"\"\" @abstractmethod def get_data ( self ) -> List [ BaseModel ]: \"\"\" Obtiene la informacion \"\"\" @abstractmethod def process_event ( self , event_data : BaseModel ) -> EventoBase : \"\"\" Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: event_data: Objeto que corresponde a modelo pydantic. \"\"\" get_data ( self ) \u00b6 Obtiene la informacion Source code in centraal_client_flow/events/__init__.py @abstractmethod def get_data ( self ) -> List [ BaseModel ]: \"\"\" Obtiene la informacion \"\"\" process_event ( self , event_data ) \u00b6 Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: Name Type Description Default event_data BaseModel Objeto que corresponde a modelo pydantic. required Source code in centraal_client_flow/events/__init__.py @abstractmethod def process_event ( self , event_data : BaseModel ) -> EventoBase : \"\"\" Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: event_data: Objeto que corresponde a modelo pydantic. \"\"\" processor \u00b6 Definicion de clase EventProcessor. EventProcessor ( ABC ) \u00b6 Clase para procesar eventos. Esta clase estandariza la manera de procesar eventos basado en pydantic. La clase sirve coom clase a heredar y debe implementar un metodo: - process_event que general puede recibir cualquier tipo de dato pero debe devolver un evento validado (EventoBase) o una lista de evento validados (List[EventoBase]). el usuario solo tiene implemenetar ese metodo ya que luego la clase se encarga de: 1. controlar errores de validaci\u00f3n, para hacer un logger adecuado 2. enviar el evento a la cola de eventos de manera asincrona(usando batch si es necesario). Source code in centraal_client_flow/events/processor.py class EventProcessor ( ABC ): \"\"\"Clase para procesar eventos. Esta clase estandariza la manera de procesar eventos basado en pydantic. La clase sirve coom clase a heredar y debe implementar un metodo: - process_event que general puede recibir cualquier tipo de dato pero debe devolver un evento validado (EventoBase) o una lista de evento validados (List[EventoBase]). el usuario solo tiene implemenetar ese metodo ya que luego la clase se encarga de: 1. controlar errores de validaci\u00f3n, para hacer un logger adecuado 2. enviar el evento a la cola de eventos de manera asincrona(usando batch si es necesario). \"\"\" @abstractmethod def process_event ( self , event : Any ) -> Union [ EventoBase , List [ EventoBase ]]: \"\"\"Procesa un evento.\"\"\" pass def handle_event ( self , data : Any ) -> None : try : eventos = self . process_event ( data ) if not isinstance ( eventos , list ): eventos = [ eventos ] self . send_to_queue ( eventos ) except ValidationError as ve : # Aqu\u00ed manejar\u00edas el logging adecuado de los errores de validaci\u00f3n print ( f \"Error de validaci\u00f3n: { ve } \" ) except Exception as e : # Manejo de otras excepciones print ( f \"Error al procesar el evento: { e } \" ) def send_to_queue ( self , eventos : List [ EventoBase ]) -> None : \"\"\"Envia un evento a la cola de eventos.\"\"\" pass process_event ( self , event ) \u00b6 Procesa un evento. Source code in centraal_client_flow/events/processor.py @abstractmethod def process_event ( self , event : Any ) -> Union [ EventoBase , List [ EventoBase ]]: \"\"\"Procesa un evento.\"\"\" pass send_to_queue ( self , eventos ) \u00b6 Envia un evento a la cola de eventos. Source code in centraal_client_flow/events/processor.py def send_to_queue ( self , eventos : List [ EventoBase ]) -> None : \"\"\"Envia un evento a la cola de eventos.\"\"\" pass receiver \u00b6 M\u00f3dulo para recibir eventos desde una fuente externa y procesarlos a trav\u00e9s de Azure Functions. EventFunctionBuilder \u00b6 Clase para construir y registrar funciones de Azure para recibir y procesar eventos. Esta clase permite construir din\u00e1micamente funciones de Azure que se desencadenan por solicitudes HTTP POST para recibir y procesar eventos utilizando un modelo de evento espec\u00edfico y un procesador de eventos. Source code in centraal_client_flow/events/receiver.py class EventFunctionBuilder : \"\"\" Clase para construir y registrar funciones de Azure para recibir y procesar eventos. Esta clase permite construir din\u00e1micamente funciones de Azure que se desencadenan por solicitudes HTTP POST para recibir y procesar eventos utilizando un modelo de evento espec\u00edfico y un procesador de eventos. \"\"\" def __init__ ( self , function_name : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , processor : EventProcessor , event_model : type [ BaseModel ], ): \"\"\" Inicializa un constructor de funciones para eventos con los par\u00e1metros especificados. Args: function_name: Nombre \u00fanico de la funci\u00f3n que se va a registrar. event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. processor: Procesador de eventos que hereda de EventProcessor. event_model: Modelo Pydantic para validar y parsear los eventos. \"\"\" self . function_name = function_name self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client self . processor = processor self . event_model = event_model def build_function ( self ): \"\"\" Construye la funci\u00f3n de Azure para recibir y procesar eventos. Returns: Una funci\u00f3n que procesa solicitudes HTTP POST, valida los eventos recibidos y los env\u00eda a una cola de Service Bus. \"\"\" def receive_event ( req : HttpRequest ) -> HttpResponse : event_data = req . get_json () logging . info ( \"validando informacion\" ) event = self . event_model . model_validate ( event_data ) event_validado = self . processor . process_event ( event ) data_validada = event_validado . model_dump ( mode = \"json\" , exclude_none = True ) logging . info ( \"enviando informacion\" ) self . service_bus_client . send_message_to_queue ( data_validada , str ( event_validado . id ), self . queue_name ) return HttpResponse ( f \"Evento de { self . event_source } es procesado.\" , status_code = 200 ) return receive_event def register_function ( self , bp : Blueprint ): \"\"\" Registra la funci\u00f3n construida en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. Returns: El Blueprint actualizado con la funci\u00f3n registrada. \"\"\" receive_event = self . build_function () bp . function_name ( name = self . function_name )( bp . route ( methods = [ \"POST\" ])( receive_event ) ) return bp __init__ ( self , function_name , event_source , queue_name , service_bus_client , processor , event_model ) special \u00b6 Inicializa un constructor de funciones para eventos con los par\u00e1metros especificados. Parameters: Name Type Description Default function_name str Nombre \u00fanico de la funci\u00f3n que se va a registrar. required event_source str Nombre de la fuente del evento. required queue_name str Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. required service_bus_client IServiceBusClient Cliente de Service Bus para enviar mensajes. required processor EventProcessor Procesador de eventos que hereda de EventProcessor. required event_model type[pydantic.main.BaseModel] Modelo Pydantic para validar y parsear los eventos. required Source code in centraal_client_flow/events/receiver.py def __init__ ( self , function_name : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , processor : EventProcessor , event_model : type [ BaseModel ], ): \"\"\" Inicializa un constructor de funciones para eventos con los par\u00e1metros especificados. Args: function_name: Nombre \u00fanico de la funci\u00f3n que se va a registrar. event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. processor: Procesador de eventos que hereda de EventProcessor. event_model: Modelo Pydantic para validar y parsear los eventos. \"\"\" self . function_name = function_name self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client self . processor = processor self . event_model = event_model build_function ( self ) \u00b6 Construye la funci\u00f3n de Azure para recibir y procesar eventos. Returns: Type Description Una funci\u00f3n que procesa solicitudes HTTP POST, valida los eventos recibidos y los env\u00eda a una cola de Service Bus. Source code in centraal_client_flow/events/receiver.py def build_function ( self ): \"\"\" Construye la funci\u00f3n de Azure para recibir y procesar eventos. Returns: Una funci\u00f3n que procesa solicitudes HTTP POST, valida los eventos recibidos y los env\u00eda a una cola de Service Bus. \"\"\" def receive_event ( req : HttpRequest ) -> HttpResponse : event_data = req . get_json () logging . info ( \"validando informacion\" ) event = self . event_model . model_validate ( event_data ) event_validado = self . processor . process_event ( event ) data_validada = event_validado . model_dump ( mode = \"json\" , exclude_none = True ) logging . info ( \"enviando informacion\" ) self . service_bus_client . send_message_to_queue ( data_validada , str ( event_validado . id ), self . queue_name ) return HttpResponse ( f \"Evento de { self . event_source } es procesado.\" , status_code = 200 ) return receive_event register_function ( self , bp ) \u00b6 Registra la funci\u00f3n construida en el Blueprint proporcionado. Parameters: Name Type Description Default bp Blueprint Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. required Returns: Type Description El Blueprint actualizado con la funci\u00f3n registrada. Source code in centraal_client_flow/events/receiver.py def register_function ( self , bp : Blueprint ): \"\"\" Registra la funci\u00f3n construida en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. Returns: El Blueprint actualizado con la funci\u00f3n registrada. \"\"\" receive_event = self . build_function () bp . function_name ( name = self . function_name )( bp . route ( methods = [ \"POST\" ])( receive_event ) ) return bp Recieve \u00b6 Clase para manejar la recepci\u00f3n y procesamiento de eventos desde una fuente espec\u00edfica. Esta clase define y registra reglas de procesamiento de eventos utilizando una fuente de eventos, un modelo de evento, y un procesador de eventos. Source code in centraal_client_flow/events/receiver.py class Recieve : \"\"\" Clase para manejar la recepci\u00f3n y procesamiento de eventos desde una fuente espec\u00edfica. Esta clase define y registra reglas de procesamiento de eventos utilizando una fuente de eventos, un modelo de evento, y un procesador de eventos. \"\"\" def __init__ ( self , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , ): \"\"\" Inicializa una instancia de Receiver. Args: event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. \"\"\" self . function_name = f \" { event_source . lower () } _receive_event\" self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client def register_function ( self , bp : Blueprint , processor : EventProcessor , event_model : type [ BaseModel ], ) -> None : \"\"\" Crea y registra una funci\u00f3n para recibir y procesar eventos en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. processor: Instancia de una clase que hereda de EventProcessor. event_model: Modelo Pydantic para validar y parsear el evento. Returns: El Blueprint actualizado con la funci\u00f3n de procesamiento de eventos registrada. \"\"\" builder = EventFunctionBuilder ( function_name = self . function_name , event_source = self . event_source , queue_name = self . queue_name , service_bus_client = self . service_bus_client , processor = processor , event_model = event_model , ) builder . register_function ( bp ) __init__ ( self , event_source , queue_name , service_bus_client ) special \u00b6 Inicializa una instancia de Receiver. Parameters: Name Type Description Default event_source str Nombre de la fuente del evento. required queue_name str Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. required service_bus_client IServiceBusClient Cliente de Service Bus para enviar mensajes. required Source code in centraal_client_flow/events/receiver.py def __init__ ( self , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , ): \"\"\" Inicializa una instancia de Receiver. Args: event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. \"\"\" self . function_name = f \" { event_source . lower () } _receive_event\" self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client register_function ( self , bp , processor , event_model ) \u00b6 Crea y registra una funci\u00f3n para recibir y procesar eventos en el Blueprint proporcionado. Parameters: Name Type Description Default bp Blueprint Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. required processor EventProcessor Instancia de una clase que hereda de EventProcessor. required event_model type[pydantic.main.BaseModel] Modelo Pydantic para validar y parsear el evento. required Returns: Type Description None El Blueprint actualizado con la funci\u00f3n de procesamiento de eventos registrada. Source code in centraal_client_flow/events/receiver.py def register_function ( self , bp : Blueprint , processor : EventProcessor , event_model : type [ BaseModel ], ) -> None : \"\"\" Crea y registra una funci\u00f3n para recibir y procesar eventos en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. processor: Instancia de una clase que hereda de EventProcessor. event_model: Modelo Pydantic para validar y parsear el evento. Returns: El Blueprint actualizado con la funci\u00f3n de procesamiento de eventos registrada. \"\"\" builder = EventFunctionBuilder ( function_name = self . function_name , event_source = self . event_source , queue_name = self . queue_name , service_bus_client = self . service_bus_client , processor = processor , event_model = event_model , ) builder . register_function ( bp ) timer \u00b6 M\u00f3dulo para recibir eventos desde una fuente externa y procesarlos a trav\u00e9s de Azure Functions. Pull \u00b6 Clase para manejar la ejecuci\u00f3n de tareas programadas y el env\u00edo de datos a Service Bus. Esta clase define y registra reglas de procesamiento de tareas utilizando un temporizador, un procesador de eventos y un cliente de Service Bus. Source code in centraal_client_flow/events/timer.py class Pull : \"\"\" Clase para manejar la ejecuci\u00f3n de tareas programadas y el env\u00edo de datos a Service Bus. Esta clase define y registra reglas de procesamiento de tareas utilizando un temporizador, un procesador de eventos y un cliente de Service Bus. \"\"\" def __init__ ( self , schedule : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , ): \"\"\" Inicializa una instancia de Pull. Args: schedule: Cadena que define el horario del temporizador (CRON). event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. \"\"\" self . function_name = f \" { event_source . lower () } _scheduled_event\" self . schedule = schedule self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client def register_function ( self , bp : Blueprint , processor : PullProcessor , ) -> None : \"\"\" Crea y registra una funci\u00f3n programada para ejecutar tareas peri\u00f3dicamente en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. processor: Instancia de una clase que hereda de PullProcessor. Returns: El Blueprint actualizado con la funci\u00f3n programada registrada. \"\"\" builder = TimerFunctionBuilder ( function_name = self . function_name , schedule = self . schedule , event_source = self . event_source , queue_name = self . queue_name , service_bus_client = self . service_bus_client , processor = processor , ) builder . register_function ( bp ) __init__ ( self , schedule , event_source , queue_name , service_bus_client ) special \u00b6 Inicializa una instancia de Pull. Parameters: Name Type Description Default schedule str Cadena que define el horario del temporizador (CRON). required event_source str Nombre de la fuente del evento. required queue_name str Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. required service_bus_client IServiceBusClient Cliente de Service Bus para enviar mensajes. required Source code in centraal_client_flow/events/timer.py def __init__ ( self , schedule : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , ): \"\"\" Inicializa una instancia de Pull. Args: schedule: Cadena que define el horario del temporizador (CRON). event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. \"\"\" self . function_name = f \" { event_source . lower () } _scheduled_event\" self . schedule = schedule self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client register_function ( self , bp , processor ) \u00b6 Crea y registra una funci\u00f3n programada para ejecutar tareas peri\u00f3dicamente en el Blueprint proporcionado. Parameters: Name Type Description Default bp Blueprint Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. required processor PullProcessor Instancia de una clase que hereda de PullProcessor. required Returns: Type Description None El Blueprint actualizado con la funci\u00f3n programada registrada. Source code in centraal_client_flow/events/timer.py def register_function ( self , bp : Blueprint , processor : PullProcessor , ) -> None : \"\"\" Crea y registra una funci\u00f3n programada para ejecutar tareas peri\u00f3dicamente en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. processor: Instancia de una clase que hereda de PullProcessor. Returns: El Blueprint actualizado con la funci\u00f3n programada registrada. \"\"\" builder = TimerFunctionBuilder ( function_name = self . function_name , schedule = self . schedule , event_source = self . event_source , queue_name = self . queue_name , service_bus_client = self . service_bus_client , processor = processor , ) builder . register_function ( bp ) TimerFunctionBuilder \u00b6 Clase para construir y registrar funciones de Azure programadas. Esta clase permite construir din\u00e1micamente funciones de Azure que se desencadenan por un temporizador, procesan eventos y los env\u00edan a un Service Bus. Source code in centraal_client_flow/events/timer.py class TimerFunctionBuilder : \"\"\" Clase para construir y registrar funciones de Azure programadas. Esta clase permite construir din\u00e1micamente funciones de Azure que se desencadenan por un temporizador, procesan eventos y los env\u00edan a un Service Bus. \"\"\" def __init__ ( self , function_name : str , schedule : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , processor : PullProcessor , ): \"\"\" Inicializa un constructor de funciones programadas con los par\u00e1metros especificados. Args: function_name: Nombre \u00fanico de la funci\u00f3n que se va a registrar. schedule: Cadena que define el horario del temporizador (CRON). event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. processor: Procesador de eventos que hereda de PullProcessor. \"\"\" self . function_name = function_name self . schedule = schedule self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client self . processor = processor def build_function ( self ): \"\"\" Construye la funci\u00f3n de Azure programada para ejecutar tareas peri\u00f3dicamente. Returns: Una funci\u00f3n que se ejecuta en base a un temporizador, procesa datos y los env\u00eda a una cola de Service Bus. \"\"\" def timer_function ( mytimer : TimerRequest ): if mytimer . past_due : logging . info ( \"The timer is past due!\" ) event_data = self . processor . get_data () for event_in_data in event_data : try : event_validado = self . processor . process_event ( event_in_data ) data_validada = event_validado . model_dump ( mode = \"json\" , exclude_none = True ) self . service_bus_client . send_message_to_queue ( data_validada , str ( event_validado . id ), self . queue_name ) except ValidationError as e : logging . error ( \"Error en %s , excepci\u00f3n: \\n %s \" , event_in_data , e ) return timer_function def register_function ( self , bp : Blueprint ): \"\"\" Registra la funci\u00f3n construida en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. Returns: El Blueprint actualizado con la funci\u00f3n registrada. \"\"\" timer_function = self . build_function () bp . function_name ( name = self . function_name )( bp . schedule ( schedule = self . schedule , arg_name = \"mytimer\" , run_on_startup = False )( timer_function ) ) return bp __init__ ( self , function_name , schedule , event_source , queue_name , service_bus_client , processor ) special \u00b6 Inicializa un constructor de funciones programadas con los par\u00e1metros especificados. Parameters: Name Type Description Default function_name str Nombre \u00fanico de la funci\u00f3n que se va a registrar. required schedule str Cadena que define el horario del temporizador (CRON). required event_source str Nombre de la fuente del evento. required queue_name str Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. required service_bus_client IServiceBusClient Cliente de Service Bus para enviar mensajes. required processor PullProcessor Procesador de eventos que hereda de PullProcessor. required Source code in centraal_client_flow/events/timer.py def __init__ ( self , function_name : str , schedule : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , processor : PullProcessor , ): \"\"\" Inicializa un constructor de funciones programadas con los par\u00e1metros especificados. Args: function_name: Nombre \u00fanico de la funci\u00f3n que se va a registrar. schedule: Cadena que define el horario del temporizador (CRON). event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. processor: Procesador de eventos que hereda de PullProcessor. \"\"\" self . function_name = function_name self . schedule = schedule self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client self . processor = processor build_function ( self ) \u00b6 Construye la funci\u00f3n de Azure programada para ejecutar tareas peri\u00f3dicamente. Returns: Type Description Una funci\u00f3n que se ejecuta en base a un temporizador, procesa datos y los env\u00eda a una cola de Service Bus. Source code in centraal_client_flow/events/timer.py def build_function ( self ): \"\"\" Construye la funci\u00f3n de Azure programada para ejecutar tareas peri\u00f3dicamente. Returns: Una funci\u00f3n que se ejecuta en base a un temporizador, procesa datos y los env\u00eda a una cola de Service Bus. \"\"\" def timer_function ( mytimer : TimerRequest ): if mytimer . past_due : logging . info ( \"The timer is past due!\" ) event_data = self . processor . get_data () for event_in_data in event_data : try : event_validado = self . processor . process_event ( event_in_data ) data_validada = event_validado . model_dump ( mode = \"json\" , exclude_none = True ) self . service_bus_client . send_message_to_queue ( data_validada , str ( event_validado . id ), self . queue_name ) except ValidationError as e : logging . error ( \"Error en %s , excepci\u00f3n: \\n %s \" , event_in_data , e ) return timer_function register_function ( self , bp ) \u00b6 Registra la funci\u00f3n construida en el Blueprint proporcionado. Parameters: Name Type Description Default bp Blueprint Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. required Returns: Type Description El Blueprint actualizado con la funci\u00f3n registrada. Source code in centraal_client_flow/events/timer.py def register_function ( self , bp : Blueprint ): \"\"\" Registra la funci\u00f3n construida en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. Returns: El Blueprint actualizado con la funci\u00f3n registrada. \"\"\" timer_function = self . build_function () bp . function_name ( name = self . function_name )( bp . schedule ( schedule = self . schedule , arg_name = \"mytimer\" , run_on_startup = False )( timer_function ) ) return bp helpers special \u00b6 cosmos \u00b6 Helpers para interactuar con cosmos. save_model_to_cosmos ( cosmos_db , container_name , model_instance ) \u00b6 Saves a Pydantic model instance to the specified Cosmos DB container. Source code in centraal_client_flow/helpers/cosmos.py def save_model_to_cosmos ( cosmos_db : CosmosDBSingleton , container_name : str , model_instance : Type [ BaseModel ] ) -> dict : \"\"\"Saves a Pydantic model instance to the specified Cosmos DB container.\"\"\" container_client = cosmos_db . get_container_client ( container_name ) item_written = write_model_to_cosmos ( container_client , model_instance ) return item_written write_model_to_cosmos ( container_client , model_instance ) \u00b6 Writes a Pydantic model instance to the specified Cosmos DB container. Source code in centraal_client_flow/helpers/cosmos.py def write_model_to_cosmos ( container_client : ContainerProxy , model_instance : Type [ BaseModel ] ) -> dict : \"\"\"Writes a Pydantic model instance to the specified Cosmos DB container.\"\"\" return container_client . upsert_item ( body = model_instance . model_dump ( mode = \"json\" , exclude_none = True ) ) logger \u00b6 Utilidades para logger. LoggerMixin \u00b6 Clase base abstracta para proveer funcionalidad de logging. Source code in centraal_client_flow/helpers/logger.py class LoggerMixin : \"\"\"Clase base abstracta para proveer funcionalidad de logging.\"\"\" def __init__ ( self , logger : Optional [ logging . Logger ] = None ): \"\"\" Inicializa la clase base con un logger opcional. Parameters: logger: Instancia de logging.Logger para registrar eventos. \"\"\" self . logger = logger or logging . getLogger ( self . __class__ . __name__ ) __init__ ( self , logger = None ) special \u00b6 Inicializa la clase base con un logger opcional. Parameters: Name Type Description Default logger Optional[logging.Logger] Instancia de logging.Logger para registrar eventos. None Source code in centraal_client_flow/helpers/logger.py def __init__ ( self , logger : Optional [ logging . Logger ] = None ): \"\"\" Inicializa la clase base con un logger opcional. Parameters: logger: Instancia de logging.Logger para registrar eventos. \"\"\" self . logger = logger or logging . getLogger ( self . __class__ . __name__ ) pydantic \u00b6 Helpers relacionados con pydantic. built_valid_json_str_with_aditional_info ( error_message , additional_info ) \u00b6 Construye una cadena JSON v\u00e1lida con informaci\u00f3n adicional. Source code in centraal_client_flow/helpers/pydantic.py def built_valid_json_str_with_aditional_info ( error_message : str , additional_info : str ) -> str : \"\"\" Construye una cadena JSON v\u00e1lida con informaci\u00f3n adicional. \"\"\" valid_dict = { \"error_validacion\" : error_message } if additional_info : valid_dict [ \"error_validacion_detalle\" ] = additional_info return json . dumps ( valid_dict , ensure_ascii = False ) serialize_validation_errors ( errors ) \u00b6 Serializa los errores de validaci\u00f3n en una cadena JSON adecuada para Cosmos DB. Parameters: Name Type Description Default errors list[pydantic_core.ErrorDetails] Lista de diccionarios que describen los errores de validaci\u00f3n. required Returns: Type Description str Cadena JSON que representa los errores de validaci\u00f3n. Source code in centraal_client_flow/helpers/pydantic.py def serialize_validation_errors ( errors : list [ ErrorDetails ]) -> str : \"\"\" Serializa los errores de validaci\u00f3n en una cadena JSON adecuada para Cosmos DB. Args: errors: Lista de diccionarios que describen los errores de validaci\u00f3n. Returns: Cadena JSON que representa los errores de validaci\u00f3n. \"\"\" return json . dumps ( errors , default = _custom_serializer , ensure_ascii = False ) rules special \u00b6 Comun para rules. NoHayReglas ( Exception ) \u00b6 Excepci\u00f3n personalizada cuando no existen reglas. Source code in centraal_client_flow/rules/__init__.py class NoHayReglas ( Exception ): \"\"\"Excepci\u00f3n personalizada cuando no existen reglas.\"\"\" def __init__ ( self , mensaje : str ): super () . __init__ ( mensaje ) self . mensaje = mensaje integration special \u00b6 processor \u00b6 Reglas de integraci\u00f3n. IntegrationRule \u00b6 Clase para definir y registrar reglas de integraci\u00f3n basadas en topics de Service Bus. Esta clase encapsula la l\u00f3gica para definir una regla de integraci\u00f3n utilizando un topic, una suscripci\u00f3n y una estrategia de integraci\u00f3n espec\u00edfica. Source code in centraal_client_flow/rules/integration/processor.py class IntegrationRule : \"\"\" Clase para definir y registrar reglas de integraci\u00f3n basadas en topics de Service Bus. Esta clase encapsula la l\u00f3gica para definir una regla de integraci\u00f3n utilizando un topic, una suscripci\u00f3n y una estrategia de integraci\u00f3n espec\u00edfica. \"\"\" def __init__ ( self , topic_name : str , connection_str : str , subscription_name : str , integration_strategy : IntegrationStrategy , model_unficado : type [ EntradaEsquemaUnificado ], ): \"\"\" Inicializa una regla de integraci\u00f3n con los par\u00e1metros especificados. Args: topic_name: Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. connection_str: Cadena de conexi\u00f3n para el Service Bus. subscription_name: Nombre de la suscripci\u00f3n en el topic de Service Bus. integration_strategy: Estrategia de integraci\u00f3n a aplicar en los mensajes procesados. model_unficado: Modelo de esquema unificado para validar y mapear los mensajes recibidos. \"\"\" if integration_strategy . name is not None : self . function_name = ( f \" { integration_strategy . name . lower () } _ { topic_name } _intrule\" ) else : self . function_name = f \" { topic_name } _intrule\" self . topic_name = topic_name self . connection_str = connection_str self . subscription_name = subscription_name self . integration_strategy = integration_strategy self . model_unficado = model_unficado self . id_esquema : Optional [ IDModel ] = None def run ( self , message : ServiceBusMessage | dict , logger : logging . Logger ) -> Optional [ StrategyResult ]: \"\"\"Ejecuta la regla de integraci\u00f3n.\"\"\" if isinstance ( message , ServiceBusMessage ): message = json . loads ( message . message ) try : message_esquema = self . model_unficado . model_validate ( message ) self . id_esquema = message_esquema . id output_model = self . integration_strategy . modelo_unificado_mapping ( message_esquema ) except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) logger . error ( \"Error antes de integraci\u00f3n en validaci\u00f3n %s \" , error_val_cosmos_friendly , exc_info = True , ) return StrategyResult ( success = False , response = { \"error_validacion\" : error_val_cosmos_friendly }, bodysent = { \"error_validacion\" : True }, ) return self . integration_strategy . integrate ( output_model ) def register_log ( self , result : StrategyResult , cosmos_client : CosmosDBSingleton , container_name : str , ): container = cosmos_client . get_container_client ( container_name ) if self . id_esquema is not None : entry = AuditoriaEntryIntegracion ( id = self . id_esquema , regla = self . function_name , contenido = result . bodysent , sucess = result . success , response = result . response , ) item_written = container . upsert_item ( entry . model_dump ( mode = \"json\" , exclude_none = True ), ) return item_written raise ValueError ( \"No es posible usar registro del log.\" ) __init__ ( self , topic_name , connection_str , subscription_name , integration_strategy , model_unficado ) special \u00b6 Inicializa una regla de integraci\u00f3n con los par\u00e1metros especificados. Parameters: Name Type Description Default topic_name str Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. required connection_str str Cadena de conexi\u00f3n para el Service Bus. required subscription_name str Nombre de la suscripci\u00f3n en el topic de Service Bus. required integration_strategy IntegrationStrategy Estrategia de integraci\u00f3n a aplicar en los mensajes procesados. required model_unficado type[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] Modelo de esquema unificado para validar y mapear los mensajes recibidos. required Source code in centraal_client_flow/rules/integration/processor.py def __init__ ( self , topic_name : str , connection_str : str , subscription_name : str , integration_strategy : IntegrationStrategy , model_unficado : type [ EntradaEsquemaUnificado ], ): \"\"\" Inicializa una regla de integraci\u00f3n con los par\u00e1metros especificados. Args: topic_name: Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. connection_str: Cadena de conexi\u00f3n para el Service Bus. subscription_name: Nombre de la suscripci\u00f3n en el topic de Service Bus. integration_strategy: Estrategia de integraci\u00f3n a aplicar en los mensajes procesados. model_unficado: Modelo de esquema unificado para validar y mapear los mensajes recibidos. \"\"\" if integration_strategy . name is not None : self . function_name = ( f \" { integration_strategy . name . lower () } _ { topic_name } _intrule\" ) else : self . function_name = f \" { topic_name } _intrule\" self . topic_name = topic_name self . connection_str = connection_str self . subscription_name = subscription_name self . integration_strategy = integration_strategy self . model_unficado = model_unficado self . id_esquema : Optional [ IDModel ] = None run ( self , message , logger ) \u00b6 Ejecuta la regla de integraci\u00f3n. Source code in centraal_client_flow/rules/integration/processor.py def run ( self , message : ServiceBusMessage | dict , logger : logging . Logger ) -> Optional [ StrategyResult ]: \"\"\"Ejecuta la regla de integraci\u00f3n.\"\"\" if isinstance ( message , ServiceBusMessage ): message = json . loads ( message . message ) try : message_esquema = self . model_unficado . model_validate ( message ) self . id_esquema = message_esquema . id output_model = self . integration_strategy . modelo_unificado_mapping ( message_esquema ) except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) logger . error ( \"Error antes de integraci\u00f3n en validaci\u00f3n %s \" , error_val_cosmos_friendly , exc_info = True , ) return StrategyResult ( success = False , response = { \"error_validacion\" : error_val_cosmos_friendly }, bodysent = { \"error_validacion\" : True }, ) return self . integration_strategy . integrate ( output_model ) strategy \u00b6 Estrategias. IntegrationStrategy ( ABC ) \u00b6 Clase Abstracta para definir estrategias de integracion. Source code in centraal_client_flow/rules/integration/strategy.py class IntegrationStrategy ( ABC ): \"\"\"Clase Abstracta para definir estrategias de integracion.\"\"\" name : Optional [ str ] = None logger : logging . Logger def __init__ ( self , logger : Optional [ logging . Logger ] = None , name : Optional [ str ] = None ): \"\"\" Inicializa la estrategia de integraci\u00f3n con un logger opcional. Parameters: logger: Instancia opcional de logging.Logger. \"\"\" self . logger = logger or logging . getLogger ( self . __class__ . __name__ ) self . name = name @abstractmethod def modelo_unificado_mapping ( self , message : EntradaEsquemaUnificado ) -> Optional [ BaseModel ]: \"\"\"Mapea el mensaje de entrada a un modelo unificado de salida. Args: message: El mensaje de entrada a ser mapeado. Returns: Un modelo Pydantic que representa la salida mapeada. \"\"\" @abstractmethod def integrate ( self , output_model : Optional [ BaseModel ]) -> Optional [ Any ]: \"\"\"Realiza la integraci\u00f3n utilizando el modelo de salida. Args: output_model: El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. Returns: La respuesta de la integraci\u00f3n, generalmente en formato JSON. \"\"\" __init__ ( self , logger = None , name = None ) special \u00b6 Inicializa la estrategia de integraci\u00f3n con un logger opcional. Parameters: Name Type Description Default logger Optional[logging.Logger] Instancia opcional de logging.Logger. None Source code in centraal_client_flow/rules/integration/strategy.py def __init__ ( self , logger : Optional [ logging . Logger ] = None , name : Optional [ str ] = None ): \"\"\" Inicializa la estrategia de integraci\u00f3n con un logger opcional. Parameters: logger: Instancia opcional de logging.Logger. \"\"\" self . logger = logger or logging . getLogger ( self . __class__ . __name__ ) self . name = name integrate ( self , output_model ) \u00b6 Realiza la integraci\u00f3n utilizando el modelo de salida. Parameters: Name Type Description Default output_model Optional[pydantic.main.BaseModel] El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. required Returns: Type Description Optional[Any] La respuesta de la integraci\u00f3n, generalmente en formato JSON. Source code in centraal_client_flow/rules/integration/strategy.py @abstractmethod def integrate ( self , output_model : Optional [ BaseModel ]) -> Optional [ Any ]: \"\"\"Realiza la integraci\u00f3n utilizando el modelo de salida. Args: output_model: El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. Returns: La respuesta de la integraci\u00f3n, generalmente en formato JSON. \"\"\" modelo_unificado_mapping ( self , message ) \u00b6 Mapea el mensaje de entrada a un modelo unificado de salida. Parameters: Name Type Description Default message EntradaEsquemaUnificado El mensaje de entrada a ser mapeado. required Returns: Type Description Optional[pydantic.main.BaseModel] Un modelo Pydantic que representa la salida mapeada. Source code in centraal_client_flow/rules/integration/strategy.py @abstractmethod def modelo_unificado_mapping ( self , message : EntradaEsquemaUnificado ) -> Optional [ BaseModel ]: \"\"\"Mapea el mensaje de entrada a un modelo unificado de salida. Args: message: El mensaje de entrada a ser mapeado. Returns: Un modelo Pydantic que representa la salida mapeada. \"\"\" OAuthConfigPassFlow dataclass \u00b6 Configuraci\u00f3n necesaria para la autenticaci\u00f3n OAuth 2.0 con grant_type=password. Source code in centraal_client_flow/rules/integration/strategy.py @dataclass class OAuthConfigPassFlow : \"\"\"Configuraci\u00f3n necesaria para la autenticaci\u00f3n OAuth 2.0 con grant_type=password.\"\"\" client_id : str client_secret : str username : str password : str token_resource : str api_url : str use_url_params_for_auth : bool = True OAuthTokenPass dataclass \u00b6 Representa el token OAuth obtenido tras la autenticaci\u00f3n. Source code in centraal_client_flow/rules/integration/strategy.py @dataclass class OAuthTokenPass : \"\"\"Representa el token OAuth obtenido tras la autenticaci\u00f3n.\"\"\" access_token : str instance_url : str id : str token_type : str issued_at : int signature : str expires_in : int = 1800 def __post_init__ ( self ): if isinstance ( self . issued_at , str ): self . issued_at = int ( self . issued_at ) RESTIntegration ( IntegrationStrategy ) \u00b6 Estrategia de integracion basada en REST. Source code in centraal_client_flow/rules/integration/strategy.py class RESTIntegration ( IntegrationStrategy ): \"\"\"Estrategia de integracion basada en REST.\"\"\" def __init__ ( self , oauth_config : OAuthConfigPassFlow , method : str = \"POST\" , resource : str = \"\" , mapping_function : Optional [ Callable [[ EntradaEsquemaUnificado ], Optional [ BaseModel ]] ] = None , logger : Optional [ logging . Logger ] = None , ): \"\"\"Inicializa una instancia de RESTIntegration con la configuraci\u00f3n de OAuth y los par\u00e1metros REST. Args: oauth_config: Configuraci\u00f3n necesaria para autenticarse con OAuth 2.0. method: El m\u00e9todo HTTP que se utilizar\u00e1 para la integraci\u00f3n (por ejemplo, 'POST', 'PATCH'). resource: El recurso espec\u00edfico de la API con el cual se interactuar\u00e1. mapping_function: Una funci\u00f3n opcional que define c\u00f3mo mapear un `EntradaEsquemaUnificado` a un modelo Pydantic. \"\"\" if mapping_function is not None : super () . __init__ ( logger = logger , name = f \" { method } _ { mapping_function . __name__ } \" ) self . oauth_config = oauth_config self . method = method self . resource = resource self . mapping_function = mapping_function self . response_processor = lambda r , m : StrategyResult ( success = True , response = r , bodysent = m ) self . _token : Optional [ OAuthTokenPass ] = None def _authenticate ( self ) -> OAuthTokenPass : \"\"\"Autentica usando OAuth 2.0 con grant_type=password y obtiene un token de acceso. Returns: Un objeto `OAuthTokenPass` que contiene el token de acceso y otra informaci\u00f3n relevante. \"\"\" auth_data = { \"grant_type\" : \"password\" , \"client_id\" : self . oauth_config . client_id , \"client_secret\" : self . oauth_config . client_secret , \"username\" : self . oauth_config . username , \"password\" : self . oauth_config . password , } if self . oauth_config . use_url_params_for_auth : token_url = f \" { self . oauth_config . api_url } / { self . oauth_config . token_resource } ? { urlencode ( auth_data ) } \" response = requests . post ( token_url , headers = {}, timeout = 30 ) else : token_url = ( f \" { self . oauth_config . api_url } / { self . oauth_config . token_resource } \" ) response = requests . post ( token_url , data = auth_data , headers = {}, timeout = 30 ) response . raise_for_status () token_data = response . json () self . _token = OAuthTokenPass ( ** token_data ) return self . _token def _get_token ( self ) -> Optional [ str ]: \"\"\"Obtiene el token actual o lo renueva si ha expirado. Returns: El token de acceso en formato de cadena. \"\"\" if self . _token is None : self . _authenticate () if self . _token is not None : current_time = int ( time . time ()) expiration_time = self . _token . issued_at / 1000 + self . _token . expires_in if current_time >= expiration_time : self . logger . info ( \"El token ha expirado. Renovando...\" ) self . _authenticate () return self . _token . access_token raise ValueError ( \"error en autenticaci\u00f3n\" ) def modelo_unificado_mapping ( self , message : EntradaEsquemaUnificado ) -> Optional [ BaseModel ]: \"\"\"Mapea el mensaje de entrada a un modelo unificado de salida utilizando la funci\u00f3n de mapeo proporcionada. Args: message: El mensaje de entrada que ser\u00e1 mapeado. Returns: Un modelo Pydantic que representa la salida mapeada. Raises: TypeError: Si el mensaje no es una instancia de `EntradaEsquemaUnificado`. NotImplementedError: Si no se ha proporcionado una funci\u00f3n de mapeo personalizada. \"\"\" if self . mapping_function : if not isinstance ( message , EntradaEsquemaUnificado ): raise TypeError ( \"El mensaje debe ser una instancia de EntradaEsquemaUnificado\" ) return self . mapping_function ( message ) raise NotImplementedError ( \"No se ha proporcionado una funci\u00f3n de mapeo personalizada.\" ) def integrate ( self , output_model : Optional [ BaseModel ]) -> Optional [ StrategyResult ]: \"\"\"Realiza la integraci\u00f3n utilizando el modelo de salida mapeado. Args: output_model: El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. Returns: La respuesta defina en response_processor. Raises: HTTPError: Si la solicitud HTTP a la API falla. \"\"\" token = self . _get_token () headers = { \"Authorization\" : f \"Bearer { token } \" , \"Content-Type\" : \"application/json\" , } url = f \" { self . oauth_config . api_url } / { self . resource } \" if output_model is not None : response = requests . request ( self . method , url , json = output_model . model_dump ( mode = \"json\" , exclude_none = True ), headers = headers , timeout = 300 , ) response . raise_for_status () return self . response_processor ( response , output_model ) self . logger . info ( \"Evento es ignorado.\" ) return StrategyResult ( success = True , response = { \"evento_ignorado\" : True }, bodysent = { \"evento_ignorado\" : True }, ) def set_response_processor ( self , processor : Callable [[ requests . Response , BaseModel ], StrategyResult ] ): \"\"\"Configura un procesamiento de la respuesta.\"\"\" self . response_processor = processor __init__ ( self , oauth_config , method = 'POST' , resource = '' , mapping_function = None , logger = None ) special \u00b6 Inicializa una instancia de RESTIntegration con la configuraci\u00f3n de OAuth y los par\u00e1metros REST. Parameters: Name Type Description Default oauth_config OAuthConfigPassFlow Configuraci\u00f3n necesaria para autenticarse con OAuth 2.0. required method str El m\u00e9todo HTTP que se utilizar\u00e1 para la integraci\u00f3n (por ejemplo, 'POST', 'PATCH'). 'POST' resource str El recurso espec\u00edfico de la API con el cual se interactuar\u00e1. '' mapping_function Optional[Callable[[centraal_client_flow.models.schemas.EntradaEsquemaUnificado], Optional[pydantic.main.BaseModel]]] Una funci\u00f3n opcional que define c\u00f3mo mapear un EntradaEsquemaUnificado a un modelo Pydantic. None Source code in centraal_client_flow/rules/integration/strategy.py def __init__ ( self , oauth_config : OAuthConfigPassFlow , method : str = \"POST\" , resource : str = \"\" , mapping_function : Optional [ Callable [[ EntradaEsquemaUnificado ], Optional [ BaseModel ]] ] = None , logger : Optional [ logging . Logger ] = None , ): \"\"\"Inicializa una instancia de RESTIntegration con la configuraci\u00f3n de OAuth y los par\u00e1metros REST. Args: oauth_config: Configuraci\u00f3n necesaria para autenticarse con OAuth 2.0. method: El m\u00e9todo HTTP que se utilizar\u00e1 para la integraci\u00f3n (por ejemplo, 'POST', 'PATCH'). resource: El recurso espec\u00edfico de la API con el cual se interactuar\u00e1. mapping_function: Una funci\u00f3n opcional que define c\u00f3mo mapear un `EntradaEsquemaUnificado` a un modelo Pydantic. \"\"\" if mapping_function is not None : super () . __init__ ( logger = logger , name = f \" { method } _ { mapping_function . __name__ } \" ) self . oauth_config = oauth_config self . method = method self . resource = resource self . mapping_function = mapping_function self . response_processor = lambda r , m : StrategyResult ( success = True , response = r , bodysent = m ) self . _token : Optional [ OAuthTokenPass ] = None integrate ( self , output_model ) \u00b6 Realiza la integraci\u00f3n utilizando el modelo de salida mapeado. Parameters: Name Type Description Default output_model Optional[pydantic.main.BaseModel] El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. required Returns: Type Description Optional[centraal_client_flow.rules.integration.strategy.StrategyResult] La respuesta defina en response_processor. Exceptions: Type Description HTTPError Si la solicitud HTTP a la API falla. Source code in centraal_client_flow/rules/integration/strategy.py def integrate ( self , output_model : Optional [ BaseModel ]) -> Optional [ StrategyResult ]: \"\"\"Realiza la integraci\u00f3n utilizando el modelo de salida mapeado. Args: output_model: El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. Returns: La respuesta defina en response_processor. Raises: HTTPError: Si la solicitud HTTP a la API falla. \"\"\" token = self . _get_token () headers = { \"Authorization\" : f \"Bearer { token } \" , \"Content-Type\" : \"application/json\" , } url = f \" { self . oauth_config . api_url } / { self . resource } \" if output_model is not None : response = requests . request ( self . method , url , json = output_model . model_dump ( mode = \"json\" , exclude_none = True ), headers = headers , timeout = 300 , ) response . raise_for_status () return self . response_processor ( response , output_model ) self . logger . info ( \"Evento es ignorado.\" ) return StrategyResult ( success = True , response = { \"evento_ignorado\" : True }, bodysent = { \"evento_ignorado\" : True }, ) modelo_unificado_mapping ( self , message ) \u00b6 Mapea el mensaje de entrada a un modelo unificado de salida utilizando la funci\u00f3n de mapeo proporcionada. Parameters: Name Type Description Default message EntradaEsquemaUnificado El mensaje de entrada que ser\u00e1 mapeado. required Returns: Type Description Optional[pydantic.main.BaseModel] Un modelo Pydantic que representa la salida mapeada. Exceptions: Type Description TypeError Si el mensaje no es una instancia de EntradaEsquemaUnificado . NotImplementedError Si no se ha proporcionado una funci\u00f3n de mapeo personalizada. Source code in centraal_client_flow/rules/integration/strategy.py def modelo_unificado_mapping ( self , message : EntradaEsquemaUnificado ) -> Optional [ BaseModel ]: \"\"\"Mapea el mensaje de entrada a un modelo unificado de salida utilizando la funci\u00f3n de mapeo proporcionada. Args: message: El mensaje de entrada que ser\u00e1 mapeado. Returns: Un modelo Pydantic que representa la salida mapeada. Raises: TypeError: Si el mensaje no es una instancia de `EntradaEsquemaUnificado`. NotImplementedError: Si no se ha proporcionado una funci\u00f3n de mapeo personalizada. \"\"\" if self . mapping_function : if not isinstance ( message , EntradaEsquemaUnificado ): raise TypeError ( \"El mensaje debe ser una instancia de EntradaEsquemaUnificado\" ) return self . mapping_function ( message ) raise NotImplementedError ( \"No se ha proporcionado una funci\u00f3n de mapeo personalizada.\" ) set_response_processor ( self , processor ) \u00b6 Configura un procesamiento de la respuesta. Source code in centraal_client_flow/rules/integration/strategy.py def set_response_processor ( self , processor : Callable [[ requests . Response , BaseModel ], StrategyResult ] ): \"\"\"Configura un procesamiento de la respuesta.\"\"\" self . response_processor = processor StrategyResult dataclass \u00b6 Resultado de Estrategia. Source code in centraal_client_flow/rules/integration/strategy.py @dataclass class StrategyResult : \"\"\"Resultado de Estrategia.\"\"\" success : bool response : dict bodysent : dict v2 \u00b6 Implementaci\u00f3n de la regla de integraci\u00f3n v2. IntegrationResult dataclass \u00b6 Resultado de integraci\u00f3n. Source code in centraal_client_flow/rules/integration/v2.py @dataclass class IntegrationResult : \"\"\"Resultado de integraci\u00f3n.\"\"\" success : bool response : dict bodysent : dict def __post_init__ ( self ): \"\"\"Valida que bodysent no sea un diccionario vac\u00edo.\"\"\" if not self . bodysent : raise ValueError ( \"bodysent no puede ser un diccionario vac\u00edo\" ) if not self . response : raise ValueError ( \"response no puede ser un diccionario vac\u00edo\" ) __post_init__ ( self ) special \u00b6 Valida que bodysent no sea un diccionario vac\u00edo. Source code in centraal_client_flow/rules/integration/v2.py def __post_init__ ( self ): \"\"\"Valida que bodysent no sea un diccionario vac\u00edo.\"\"\" if not self . bodysent : raise ValueError ( \"bodysent no puede ser un diccionario vac\u00edo\" ) if not self . response : raise ValueError ( \"response no puede ser un diccionario vac\u00edo\" ) IntegrationRule ( ABC ) \u00b6 Implementaci\u00f3n de la regla de integraci\u00f3n v2. Esta implementaci\u00f3n es una regla tiene el objetivo de simplicar la implementaci\u00f3n, se observa que en los casos de uso la estrategias de integraci\u00f3n no son valiosas y dan muy poca flexibilidad. Adicional en general las reglas de integraci\u00f3n son un concpeto mas directo y claro para representar la logica de transformaci\u00f3n del modelo unficaido a lo que necesita el sistema destino, esto ayudara a que el usuario implemente directamente la transformaci\u00f3n y operaciones necesarias sin necesidad de definirla en un objeto diferente. La reglas integraci\u00f3n se implementa como una clase abstracta con metodos compartidos, el usuario solo debera implementar el metodo abstracto integrate , que debe recibir el mensaje del topic, codificarlo mediante el modelo unificado y hacer la implemetaci\u00f3n que requiera (inlcuido mapping o logicas adicionales para realizar la integraci\u00f3n), y el set de body_sent que se enviara a la auditoria de cosmos, par asaber que se envio al sistema destino. con el unico requisito de devolver un IntegrationResult, que indicara el resultado de la transformaci\u00f3n. la clase abstracta tendra la implementaci\u00f3n de metodos concretos: run: se encarga de ejecutar integrate y realizar el logging a la auditoria de cosmos. register_log: se encarga de realizar el logging de la auditoria de cosmos. Source code in centraal_client_flow/rules/integration/v2.py class IntegrationRule ( ABC ): \"\"\"Implementaci\u00f3n de la regla de integraci\u00f3n v2. Esta implementaci\u00f3n es una regla tiene el objetivo de simplicar la implementaci\u00f3n, se observa que en los casos de uso la estrategias de integraci\u00f3n no son valiosas y dan muy poca flexibilidad. Adicional en general las reglas de integraci\u00f3n son un concpeto mas directo y claro para representar la logica de transformaci\u00f3n del modelo unficaido a lo que necesita el sistema destino, esto ayudara a que el usuario implemente directamente la transformaci\u00f3n y operaciones necesarias sin necesidad de definirla en un objeto diferente. La reglas integraci\u00f3n se implementa como una clase abstracta con metodos compartidos, el usuario solo debera implementar el metodo abstracto `integrate`, que debe recibir el mensaje del topic, codificarlo mediante el modelo unificado y hacer la implemetaci\u00f3n que requiera (inlcuido mapping o logicas adicionales para realizar la integraci\u00f3n), y el set de body_sent que se enviara a la auditoria de cosmos, par asaber que se envio al sistema destino. con el unico requisito de devolver un IntegrationResult, que indicara el resultado de la transformaci\u00f3n. la clase abstracta tendra la implementaci\u00f3n de metodos concretos: run: se encarga de ejecutar `integrate` y realizar el logging a la auditoria de cosmos. register_log: se encarga de realizar el logging de la auditoria de cosmos. \"\"\" def __init__ ( self , name : str , model_unficado : type [ EntradaEsquemaUnificado ], logger : logging . Logger , container_name_aud : str , ): \"\"\" Inicializa una regla de integraci\u00f3n. Args: name: Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. model_unficado: Modelo de esquema unificado para validar y mapear los mensajes recibidos. container_name_aud: Nombre del contenedor de la auditoria de cosmos. \"\"\" self . name = name self . model_unficado = model_unficado self . logger = logger self . id_esquema = None self . container_name_aud = container_name_aud self . body_sent = {} @abstractmethod def integrate ( self , entrada_esquema_unificado : EntradaEsquemaUnificado ) -> Optional [ IntegrationResult ]: pass def _validate_modelo_unificado ( self , message : dict ) -> Union [ IntegrationResult , EntradaEsquemaUnificado ]: try : message_esquema = self . model_unficado . model_validate ( message ) self . id_esquema = message_esquema . id return message_esquema except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) response = built_valid_json_str_with_aditional_info ( error_val_cosmos_friendly , f \"Mensaje no cumple con el esquema { self . model_unficado . __name__ } \" , ) self . logger . error ( \"Error en validaci\u00f3n del modelo unificado %s \" , error_val_cosmos_friendly , exc_info = True , ) return IntegrationResult ( success = False , response = response , bodysent = { \"error_validacion\" : True }, ) def run ( self , message : Union [ ServiceBusMessage , dict ], cosmos_client : CosmosDBSingleton , ): \"\"\"Ejecuta la regla de integraci\u00f3n.\"\"\" if isinstance ( message , ServiceBusMessage ): message = json . loads ( message . get_body () . decode ( \"utf-8\" )) message_esquema = self . _validate_modelo_unificado ( message ) if isinstance ( message_esquema , IntegrationResult ): raise ValueError ( f \"Error en validaci\u00f3n del modelo unificado. Se recibe un mensaje no valido { message_esquema } \" ) try : self . id_esquema = message_esquema . id result = self . _retry_with_exponential_backoff ( self . integrate , message_esquema ) if self . body_sent is None : raise ValueError ( \"No se ha definido el body_sent. Integrate debe setear el atributo body_sent.\" ) except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) self . logger . error ( \"Error de validaci\u00f3n en integraci\u00f3n %s \" , error_val_cosmos_friendly , exc_info = True , ) result = IntegrationResult ( success = False , response = { \"error_validacion\" : error_val_cosmos_friendly }, bodysent = { \"error_validacion\" : True }, ) except Exception as e : self . logger . error ( \"Error en integraci\u00f3n %s \" , e , exc_info = True , ) raise e self . register_log ( result , cosmos_client ) return result def register_log ( self , result : IntegrationResult , cosmos_client : CosmosDBSingleton , ): container = cosmos_client . get_container_client ( self . container_name_aud ) if self . id_esquema is not None : entry = AuditoriaEntryIntegracion ( id = self . id_esquema , regla = self . name , contenido = result . bodysent , sucess = result . success , response = result . response , ) item_written = container . upsert_item ( entry . model_dump ( mode = \"json\" , exclude_none = True ), ) return item_written raise ValueError ( \"No es posible usar registro del log.\" ) def _retry_with_exponential_backoff ( self , func , * args , max_retries = 3 , base_delay = 1 , ** kwargs ): \"\"\"Retries a function with exponential backoff.\"\"\" for attempt in range ( max_retries ): try : return func ( * args , ** kwargs ) except Exception as e : if attempt < max_retries - 1 : delay = base_delay * ( 2 ** attempt ) self . logger . warning ( \"Retrying due to error: %s . Attempt %d / %d . Retrying in %d seconds...\" , e , attempt + 1 , max_retries , delay , ) time . sleep ( delay ) else : self . logger . error ( \"Max retries reached. Last error: %s \" , e , exc_info = True ) raise e __init__ ( self , name , model_unficado , logger , container_name_aud ) special \u00b6 Inicializa una regla de integraci\u00f3n. Parameters: Name Type Description Default name str Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. required model_unficado type[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] Modelo de esquema unificado para validar y mapear los mensajes recibidos. required container_name_aud str Nombre del contenedor de la auditoria de cosmos. required Source code in centraal_client_flow/rules/integration/v2.py def __init__ ( self , name : str , model_unficado : type [ EntradaEsquemaUnificado ], logger : logging . Logger , container_name_aud : str , ): \"\"\" Inicializa una regla de integraci\u00f3n. Args: name: Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. model_unficado: Modelo de esquema unificado para validar y mapear los mensajes recibidos. container_name_aud: Nombre del contenedor de la auditoria de cosmos. \"\"\" self . name = name self . model_unficado = model_unficado self . logger = logger self . id_esquema = None self . container_name_aud = container_name_aud self . body_sent = {} run ( self , message , cosmos_client ) \u00b6 Ejecuta la regla de integraci\u00f3n. Source code in centraal_client_flow/rules/integration/v2.py def run ( self , message : Union [ ServiceBusMessage , dict ], cosmos_client : CosmosDBSingleton , ): \"\"\"Ejecuta la regla de integraci\u00f3n.\"\"\" if isinstance ( message , ServiceBusMessage ): message = json . loads ( message . get_body () . decode ( \"utf-8\" )) message_esquema = self . _validate_modelo_unificado ( message ) if isinstance ( message_esquema , IntegrationResult ): raise ValueError ( f \"Error en validaci\u00f3n del modelo unificado. Se recibe un mensaje no valido { message_esquema } \" ) try : self . id_esquema = message_esquema . id result = self . _retry_with_exponential_backoff ( self . integrate , message_esquema ) if self . body_sent is None : raise ValueError ( \"No se ha definido el body_sent. Integrate debe setear el atributo body_sent.\" ) except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) self . logger . error ( \"Error de validaci\u00f3n en integraci\u00f3n %s \" , error_val_cosmos_friendly , exc_info = True , ) result = IntegrationResult ( success = False , response = { \"error_validacion\" : error_val_cosmos_friendly }, bodysent = { \"error_validacion\" : True }, ) except Exception as e : self . logger . error ( \"Error en integraci\u00f3n %s \" , e , exc_info = True , ) raise e self . register_log ( result , cosmos_client ) return result update \u00b6 M\u00f3dulo para las reglas de actualizaci\u00f3n. Rule dataclass \u00b6 Representa una regla de procesamiento que asocia un modelo Pydantic con un procesador y los t\u00f3picos relevantes. Attributes: Name Type Description model Type[centraal_client_flow.models.schemas.EventoBase] El tipo de modelo Pydantic que la regla procesa. processor UpdateProcessor El procesador que manejar\u00e1 la l\u00f3gica de actualizaci\u00f3n. topics Set[str] Los t\u00f3picos a los que la regla est\u00e1 asociada. name str El nombre asignado a la regla basado en el nombre de la clase del modelo. Source code in centraal_client_flow/rules/update.py @dataclass class Rule : \"\"\" Representa una regla de procesamiento que asocia un modelo Pydantic con un procesador y los t\u00f3picos relevantes. Attributes: model: El tipo de modelo Pydantic que la regla procesa. processor: El procesador que manejar\u00e1 la l\u00f3gica de actualizaci\u00f3n. topics: Los t\u00f3picos a los que la regla est\u00e1 asociada. name: El nombre asignado a la regla basado en el nombre de la clase del modelo. \"\"\" model : Type [ EventoBase ] processor : UpdateProcessor topics : Set [ str ] name : str = \"\" def __post_init__ ( self ): \"\"\"Inicializa el nombre de la regla basado en el nombre de la clase del modelo.\"\"\" self . name = self . model . __name__ def process_rule ( self , data : EventoBase , current : Optional [ EntradaEsquemaUnificado ] ) -> EntradaEsquemaUnificado : \"\"\" Procesa una entrada de datos usando la regla definida. Parameters: data: El evento que se procesar\u00e1. current: El registro actual a ser actualizado. Returns: EntradaEsquemaUnificado: El registro actualizado. \"\"\" data_copy = data . model_copy ( deep = True ) current_copy = current . model_copy ( deep = True ) if current else None result = self . processor . process_message ( data_copy , current_copy ) return result __post_init__ ( self ) special \u00b6 Inicializa el nombre de la regla basado en el nombre de la clase del modelo. Source code in centraal_client_flow/rules/update.py def __post_init__ ( self ): \"\"\"Inicializa el nombre de la regla basado en el nombre de la clase del modelo.\"\"\" self . name = self . model . __name__ process_rule ( self , data , current ) \u00b6 Procesa una entrada de datos usando la regla definida. Parameters: Name Type Description Default data EventoBase El evento que se procesar\u00e1. required current Optional[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] El registro actual a ser actualizado. required Returns: Type Description EntradaEsquemaUnificado El registro actualizado. Source code in centraal_client_flow/rules/update.py def process_rule ( self , data : EventoBase , current : Optional [ EntradaEsquemaUnificado ] ) -> EntradaEsquemaUnificado : \"\"\" Procesa una entrada de datos usando la regla definida. Parameters: data: El evento que se procesar\u00e1. current: El registro actual a ser actualizado. Returns: EntradaEsquemaUnificado: El registro actualizado. \"\"\" data_copy = data . model_copy ( deep = True ) current_copy = current . model_copy ( deep = True ) if current else None result = self . processor . process_message ( data_copy , current_copy ) return result RuleProcessor \u00b6 Clase que orquesta el procesamiento de reglas y la interacci\u00f3n con Service Bus y Cosmos DB. Source code in centraal_client_flow/rules/update.py class RuleProcessor : \"\"\"Clase que orquesta el procesamiento de reglas y la interacci\u00f3n con Service Bus y Cosmos DB.\"\"\" def __init__ ( self , queue_name : str , unified_container_name : str , auditoria_container_name : str , service_bus_client : IServiceBusClient , cosmos_client : CosmosDBSingleton , rule_selector : RuleSelector , ): self . queue_name = queue_name self . unified_container_name = unified_container_name self . auditoria_container_name = auditoria_container_name self . service_bus_client = service_bus_client self . cosmos_client = cosmos_client self . rule_selector = rule_selector def save_unified_model ( self , new_data : EntradaEsquemaUnificado , ) -> dict : \"\"\" Guarda el modelo de EntradaEsquemaUnificado actualizado en Cosmos DB. Parameters: new_data: El modelo actualizado de EntradaEsquemaUnificado. Returns: EntradaEsquemaUnificado: El modelo almacenado en la base de datos. \"\"\" container = self . cosmos_client . get_container_client ( self . unified_container_name ) item_written = container . upsert_item ( new_data . model_dump ( mode = \"json\" , exclude_none = True ) ) return item_written def record_auditoria ( self , changes : List [ AuditoriaEntry ]): \"\"\" Registra los cambios detectados en el contenedor de auditor\u00eda de Cosmos DB. Parameters: changes: Lista de entradas de auditor\u00eda que contienen los cambios detectados. \"\"\" container = self . cosmos_client . get_container_client ( self . auditoria_container_name ) for change in changes : container . create_item ( change . model_dump ( mode = \"json\" , exclude_none = True ), enable_automatic_id_generation = True , ) def get_current_entrada ( self , id_entrada : IDModel , model_unificado : EntradaEsquemaUnificado ) -> Optional [ EntradaEsquemaUnificado ]: \"\"\" Recupera el registro actual desde Cosmos DB basado en el ID proporcionado. Parameters: id_entrada: El ID del registro que se desea recuperar. Returns: Optional[EntradaEsquemaUnificado]: El registro actual, si existe. \"\"\" container = self . cosmos_client . get_container_client ( self . unified_container_name ) query = f \"SELECT * FROM c WHERE c.id = ' { id_entrada . model_dump () } '\" current_items = list ( container . query_items ( query , enable_cross_partition_query = True ) ) if current_items : return model_unificado . model_validate ( current_items [ 0 ]) return None def detect_changes ( self , current_data : Optional [ EntradaEsquemaUnificado ], updated_data : EntradaEsquemaUnificado , id_model : IDModel , regla_name : str , ) -> List [ AuditoriaEntry ]: \"\"\" Detecta cambios entre los datos actuales y los actualizados en el modelo EntradaEsquemaUnificado. Parameters: current_data: Los datos actuales en la base de datos. updated_data: Los datos actualizados a comparar. id_model: El ID del modelo que se est\u00e1 procesando. Returns: List[AuditoriaEntry]: Lista de entradas de auditor\u00eda que reflejan los cambios detectados. \"\"\" changes = [] def _log_changes ( subesquema_name : str , old_value : Any , new_value : Any , field_name : str ): \"\"\"Funci\u00f3n auxiliar para registrar cambios detectados.\"\"\" changes . append ( AuditoriaEntry ( id_entrada = id_model , subesquema = subesquema_name , campo = field_name , new_value = new_value , old_value = old_value , regla = regla_name , ) ) if current_data is None : # No hay datos actuales, se registran todos los campos como cambios for field_name in updated_data . model_fields_set : new_value = getattr ( updated_data , field_name ) if isinstance ( new_value , BaseModel ) and not ( isinstance ( new_value , IDModel ) ): # Es un modelo Pydantic anidado (subesquema) for sub_field_name in new_value . model_fields_set : sub_field_value = getattr ( new_value , sub_field_name ) _log_changes ( field_name , None , sub_field_value , sub_field_name ) else : # Si es principal es \"root\" _log_changes ( \"root\" , None , new_value , field_name ) else : for field_name in updated_data . model_fields_set : old_value = getattr ( current_data , field_name ) new_value = getattr ( updated_data , field_name ) if isinstance ( new_value , BaseModel ): # Es un modelo Pydantic anidado (subesquema) for sub_field_name in new_value . model_fields_set : sub_old_value = ( getattr ( old_value , sub_field_name , None ) if old_value else None ) sub_new_value = getattr ( new_value , sub_field_name , None ) if sub_old_value != sub_new_value : _log_changes ( field_name , sub_old_value , sub_new_value , sub_field_name ) else : if old_value != new_value : _log_changes ( \"root\" , old_value , new_value , field_name ) if not changes : changes . append ( AuditoriaEntry ( id_entrada = id_model , subesquema = \"No Changes\" , campo = \"Ninguno\" , new_value = \"No cambios\" , old_value = \"No cambios\" , regla = regla_name , ) ) return changes def publish_to_topics ( self , processed_data : EntradaEsquemaUnificado , topic_names : List [ str ], ): \"\"\" Publica los datos procesados a los t\u00f3picos de Service Bus relevantes. Parameters: processed_data: Los datos procesados que se enviar\u00e1n. topic_names: Lista de t\u00f3picos a los que se enviar\u00e1n los datos. \"\"\" client = self . service_bus_client . client for topic_name in topic_names : body = processed_data . model_dump ( mode = \"json\" , exclude_none = True ) with client . get_topic_sender ( topic_name = topic_name ) as sender : message = SBMessage ( body = json . dumps ( body )) sender . send_messages ( message ) detect_changes ( self , current_data , updated_data , id_model , regla_name ) \u00b6 Detecta cambios entre los datos actuales y los actualizados en el modelo EntradaEsquemaUnificado. Parameters: Name Type Description Default current_data Optional[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] Los datos actuales en la base de datos. required updated_data EntradaEsquemaUnificado Los datos actualizados a comparar. required id_model IDModel El ID del modelo que se est\u00e1 procesando. required Returns: Type Description List[AuditoriaEntry] Lista de entradas de auditor\u00eda que reflejan los cambios detectados. Source code in centraal_client_flow/rules/update.py def detect_changes ( self , current_data : Optional [ EntradaEsquemaUnificado ], updated_data : EntradaEsquemaUnificado , id_model : IDModel , regla_name : str , ) -> List [ AuditoriaEntry ]: \"\"\" Detecta cambios entre los datos actuales y los actualizados en el modelo EntradaEsquemaUnificado. Parameters: current_data: Los datos actuales en la base de datos. updated_data: Los datos actualizados a comparar. id_model: El ID del modelo que se est\u00e1 procesando. Returns: List[AuditoriaEntry]: Lista de entradas de auditor\u00eda que reflejan los cambios detectados. \"\"\" changes = [] def _log_changes ( subesquema_name : str , old_value : Any , new_value : Any , field_name : str ): \"\"\"Funci\u00f3n auxiliar para registrar cambios detectados.\"\"\" changes . append ( AuditoriaEntry ( id_entrada = id_model , subesquema = subesquema_name , campo = field_name , new_value = new_value , old_value = old_value , regla = regla_name , ) ) if current_data is None : # No hay datos actuales, se registran todos los campos como cambios for field_name in updated_data . model_fields_set : new_value = getattr ( updated_data , field_name ) if isinstance ( new_value , BaseModel ) and not ( isinstance ( new_value , IDModel ) ): # Es un modelo Pydantic anidado (subesquema) for sub_field_name in new_value . model_fields_set : sub_field_value = getattr ( new_value , sub_field_name ) _log_changes ( field_name , None , sub_field_value , sub_field_name ) else : # Si es principal es \"root\" _log_changes ( \"root\" , None , new_value , field_name ) else : for field_name in updated_data . model_fields_set : old_value = getattr ( current_data , field_name ) new_value = getattr ( updated_data , field_name ) if isinstance ( new_value , BaseModel ): # Es un modelo Pydantic anidado (subesquema) for sub_field_name in new_value . model_fields_set : sub_old_value = ( getattr ( old_value , sub_field_name , None ) if old_value else None ) sub_new_value = getattr ( new_value , sub_field_name , None ) if sub_old_value != sub_new_value : _log_changes ( field_name , sub_old_value , sub_new_value , sub_field_name ) else : if old_value != new_value : _log_changes ( \"root\" , old_value , new_value , field_name ) if not changes : changes . append ( AuditoriaEntry ( id_entrada = id_model , subesquema = \"No Changes\" , campo = \"Ninguno\" , new_value = \"No cambios\" , old_value = \"No cambios\" , regla = regla_name , ) ) return changes get_current_entrada ( self , id_entrada , model_unificado ) \u00b6 Recupera el registro actual desde Cosmos DB basado en el ID proporcionado. Parameters: Name Type Description Default id_entrada IDModel El ID del registro que se desea recuperar. required Returns: Type Description Optional[EntradaEsquemaUnificado] El registro actual, si existe. Source code in centraal_client_flow/rules/update.py def get_current_entrada ( self , id_entrada : IDModel , model_unificado : EntradaEsquemaUnificado ) -> Optional [ EntradaEsquemaUnificado ]: \"\"\" Recupera el registro actual desde Cosmos DB basado en el ID proporcionado. Parameters: id_entrada: El ID del registro que se desea recuperar. Returns: Optional[EntradaEsquemaUnificado]: El registro actual, si existe. \"\"\" container = self . cosmos_client . get_container_client ( self . unified_container_name ) query = f \"SELECT * FROM c WHERE c.id = ' { id_entrada . model_dump () } '\" current_items = list ( container . query_items ( query , enable_cross_partition_query = True ) ) if current_items : return model_unificado . model_validate ( current_items [ 0 ]) return None publish_to_topics ( self , processed_data , topic_names ) \u00b6 Publica los datos procesados a los t\u00f3picos de Service Bus relevantes. Parameters: Name Type Description Default processed_data EntradaEsquemaUnificado Los datos procesados que se enviar\u00e1n. required topic_names List[str] Lista de t\u00f3picos a los que se enviar\u00e1n los datos. required Source code in centraal_client_flow/rules/update.py def publish_to_topics ( self , processed_data : EntradaEsquemaUnificado , topic_names : List [ str ], ): \"\"\" Publica los datos procesados a los t\u00f3picos de Service Bus relevantes. Parameters: processed_data: Los datos procesados que se enviar\u00e1n. topic_names: Lista de t\u00f3picos a los que se enviar\u00e1n los datos. \"\"\" client = self . service_bus_client . client for topic_name in topic_names : body = processed_data . model_dump ( mode = \"json\" , exclude_none = True ) with client . get_topic_sender ( topic_name = topic_name ) as sender : message = SBMessage ( body = json . dumps ( body )) sender . send_messages ( message ) record_auditoria ( self , changes ) \u00b6 Registra los cambios detectados en el contenedor de auditor\u00eda de Cosmos DB. Parameters: Name Type Description Default changes List[centraal_client_flow.models.schemas.AuditoriaEntry] Lista de entradas de auditor\u00eda que contienen los cambios detectados. required Source code in centraal_client_flow/rules/update.py def record_auditoria ( self , changes : List [ AuditoriaEntry ]): \"\"\" Registra los cambios detectados en el contenedor de auditor\u00eda de Cosmos DB. Parameters: changes: Lista de entradas de auditor\u00eda que contienen los cambios detectados. \"\"\" container = self . cosmos_client . get_container_client ( self . auditoria_container_name ) for change in changes : container . create_item ( change . model_dump ( mode = \"json\" , exclude_none = True ), enable_automatic_id_generation = True , ) save_unified_model ( self , new_data ) \u00b6 Guarda el modelo de EntradaEsquemaUnificado actualizado en Cosmos DB. Parameters: Name Type Description Default new_data EntradaEsquemaUnificado El modelo actualizado de EntradaEsquemaUnificado. required Returns: Type Description EntradaEsquemaUnificado El modelo almacenado en la base de datos. Source code in centraal_client_flow/rules/update.py def save_unified_model ( self , new_data : EntradaEsquemaUnificado , ) -> dict : \"\"\" Guarda el modelo de EntradaEsquemaUnificado actualizado en Cosmos DB. Parameters: new_data: El modelo actualizado de EntradaEsquemaUnificado. Returns: EntradaEsquemaUnificado: El modelo almacenado en la base de datos. \"\"\" container = self . cosmos_client . get_container_client ( self . unified_container_name ) item_written = container . upsert_item ( new_data . model_dump ( mode = \"json\" , exclude_none = True ) ) return item_written RuleSelector \u00b6 Clase encargada de seleccionar y aplicar reglas de procesamiento sobre los eventos. Source code in centraal_client_flow/rules/update.py class RuleSelector : \"\"\"Clase encargada de seleccionar y aplicar reglas de procesamiento sobre los eventos.\"\"\" def __init__ ( self , modelo_unificado : EntradaEsquemaUnificado ): self . rules : List [ Rule ] = [] self . modelo_unificado = modelo_unificado def register_rule ( self , rule : Rule ): \"\"\" Registra una nueva regla para su uso futuro en el procesamiento de eventos. Parameters: rule: La regla que se va a registrar. \"\"\" self . _validate_rule ( rule ) self . rules . append ( rule ) def _validate_rule ( self , rule : Rule ): \"\"\" Valida que los t\u00f3picos de la regla coincidan con los subesquemas en el modelo unificado. Parameters: rule: La regla a validar. Raises: ValueError: Si alg\u00fan t\u00f3pico de la regla no corresponde a un subesquema v\u00e1lido. \"\"\" model_fields = set ( self . modelo_unificado . model_fields ) for t in rule . topics : if t == \"root\" : pass elif t not in model_fields : raise ValueError ( f \"El t\u00f3pico { t } debe corresponder a un subesquema { model_fields } \" ) def select_rule ( self , data : dict ) -> Tuple [ EventoBase , Rule ]: \"\"\" Selecciona la regla adecuada para los datos proporcionados. Parameters: data: Un diccionario con los datos a validar y procesar. Returns: Tuple[EventoBase, Rule]: Los datos validados y la regla seleccionada. Raises: NoHayReglas: Si no se encuentra una regla v\u00e1lida para los datos proporcionados. \"\"\" for rule in self . rules : try : validated_data = rule . model . model_validate ( data ) return validated_data , rule except ValidationError : continue raise NoHayReglas ( f \"No se encontr\u00f3 una regla v\u00e1lida para { data } .\" ) def get_topics_by_changes ( self , rule_topics : Set [ str ], changes : List [ AuditoriaEntry ], include_root : bool = False , ) -> List [ str ]: \"\"\" Selecciona los t\u00f3picos relevantes basados en los cambios detectados. Parameters: rule_topics: Conjunto de t\u00f3picos definidos en la regla. changes: Lista de entradas de auditor\u00eda con los cambios detectados. Returns: List[str]: Lista de t\u00f3picos que necesitan ser notificados. \"\"\" topics_to_notify = set () for change in changes : if change . subesquema in rule_topics : if include_root : topics_to_notify . add ( change . subesquema ) elif change . subesquema != \"root\" : topics_to_notify . add ( change . subesquema ) return list ( topics_to_notify ) get_topics_by_changes ( self , rule_topics , changes , include_root = False ) \u00b6 Selecciona los t\u00f3picos relevantes basados en los cambios detectados. Parameters: Name Type Description Default rule_topics Set[str] Conjunto de t\u00f3picos definidos en la regla. required changes List[centraal_client_flow.models.schemas.AuditoriaEntry] Lista de entradas de auditor\u00eda con los cambios detectados. required Returns: Type Description List[str] Lista de t\u00f3picos que necesitan ser notificados. Source code in centraal_client_flow/rules/update.py def get_topics_by_changes ( self , rule_topics : Set [ str ], changes : List [ AuditoriaEntry ], include_root : bool = False , ) -> List [ str ]: \"\"\" Selecciona los t\u00f3picos relevantes basados en los cambios detectados. Parameters: rule_topics: Conjunto de t\u00f3picos definidos en la regla. changes: Lista de entradas de auditor\u00eda con los cambios detectados. Returns: List[str]: Lista de t\u00f3picos que necesitan ser notificados. \"\"\" topics_to_notify = set () for change in changes : if change . subesquema in rule_topics : if include_root : topics_to_notify . add ( change . subesquema ) elif change . subesquema != \"root\" : topics_to_notify . add ( change . subesquema ) return list ( topics_to_notify ) register_rule ( self , rule ) \u00b6 Registra una nueva regla para su uso futuro en el procesamiento de eventos. Parameters: Name Type Description Default rule Rule La regla que se va a registrar. required Source code in centraal_client_flow/rules/update.py def register_rule ( self , rule : Rule ): \"\"\" Registra una nueva regla para su uso futuro en el procesamiento de eventos. Parameters: rule: La regla que se va a registrar. \"\"\" self . _validate_rule ( rule ) self . rules . append ( rule ) select_rule ( self , data ) \u00b6 Selecciona la regla adecuada para los datos proporcionados. Parameters: Name Type Description Default data dict Un diccionario con los datos a validar y procesar. required Returns: Type Description Tuple[EventoBase, Rule] Los datos validados y la regla seleccionada. Exceptions: Type Description NoHayReglas Si no se encuentra una regla v\u00e1lida para los datos proporcionados. Source code in centraal_client_flow/rules/update.py def select_rule ( self , data : dict ) -> Tuple [ EventoBase , Rule ]: \"\"\" Selecciona la regla adecuada para los datos proporcionados. Parameters: data: Un diccionario con los datos a validar y procesar. Returns: Tuple[EventoBase, Rule]: Los datos validados y la regla seleccionada. Raises: NoHayReglas: Si no se encuentra una regla v\u00e1lida para los datos proporcionados. \"\"\" for rule in self . rules : try : validated_data = rule . model . model_validate ( data ) return validated_data , rule except ValidationError : continue raise NoHayReglas ( f \"No se encontr\u00f3 una regla v\u00e1lida para { data } .\" ) UpdateProcessor ( LoggerMixin , ABC ) \u00b6 Clase base abstracta para procesadores de eventos. Source code in centraal_client_flow/rules/update.py class UpdateProcessor ( LoggerMixin , ABC ): \"\"\"Clase base abstracta para procesadores de eventos.\"\"\" @abstractmethod def process_message ( self , event : EventoBase , current_registro : Optional [ EntradaEsquemaUnificado ] ) -> EntradaEsquemaUnificado : \"\"\" Procesa el evento recibido y retorna un modelo actualizado de EntradaEsquemaUnificado. Parameters: event: El evento que contiene la informaci\u00f3n del cambio, basado en un modelo Pydantic. current_registro: El registro actual que ser\u00e1 actualizado. Returns: EntradaEsquemaUnificado: El registro actualizado despu\u00e9s de aplicar el evento. \"\"\" process_message ( self , event , current_registro ) \u00b6 Procesa el evento recibido y retorna un modelo actualizado de EntradaEsquemaUnificado. Parameters: Name Type Description Default event EventoBase El evento que contiene la informaci\u00f3n del cambio, basado en un modelo Pydantic. required current_registro Optional[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] El registro actual que ser\u00e1 actualizado. required Returns: Type Description EntradaEsquemaUnificado El registro actualizado despu\u00e9s de aplicar el evento. Source code in centraal_client_flow/rules/update.py @abstractmethod def process_message ( self , event : EventoBase , current_registro : Optional [ EntradaEsquemaUnificado ] ) -> EntradaEsquemaUnificado : \"\"\" Procesa el evento recibido y retorna un modelo actualizado de EntradaEsquemaUnificado. Parameters: event: El evento que contiene la informaci\u00f3n del cambio, basado en un modelo Pydantic. current_registro: El registro actual que ser\u00e1 actualizado. Returns: EntradaEsquemaUnificado: El registro actualizado despu\u00e9s de aplicar el evento. \"\"\"","title":"modules"},{"location":"api/#centraal_client_flow.connections","text":"","title":"connections"},{"location":"api/#centraal_client_flow.connections.cosmosdb","text":"Modulo de conexi\u00f3n a cosmos.","title":"cosmosdb"},{"location":"api/#centraal_client_flow.connections.cosmosdb.CosmosDBSingleton","text":"Singleton class for Cosmos DB client. Source code in centraal_client_flow/connections/cosmosdb.py class CosmosDBSingleton : \"\"\"Singleton class for Cosmos DB client.\"\"\" _instance : Optional [ \"CosmosDBSingleton\" ] = None _lock : Lock = Lock () def __new__ ( cls , connection_string : Optional [ str ] = None , database_name : Optional [ str ] = None , ) -> \"CosmosDBSingleton\" : if cls . _instance is None : with cls . _lock : if cls . _instance is None : cls . _instance = super () . __new__ ( cls ) return cls . _instance def __init__ ( self , connection_string : Optional [ str ] = None , database_name : Optional [ str ] = None , ) -> None : if not hasattr ( self , \"_initialized\" ): self . _initialized = False self . client : Optional [ CosmosClient ] = None self . database : Optional [ CosmosClient ] = None self . connection_string = connection_string or os . getenv ( \"COSMOS_CONNECTION_STRING\" ) self . database_name = database_name or os . getenv ( \"DATABASE_NAME\" ) def _initialize ( self ) -> None : \"\"\"Initialize the Cosmos DB client and database.\"\"\" if self . client is None or self . database is None : if not self . connection_string or not self . database_name : raise ValueError ( \"Connection string and database name must be provided\" ) self . client = CosmosClient . from_connection_string ( self . connection_string ) self . database = self . client . get_database_client ( self . database_name ) self . _initialized = True def get_container_client ( self , container_name : str ) -> ContainerProxy : \"\"\"Get a container client.\"\"\" self . _initialize () return self . database . get_container_client ( container_name ) def set_mock_client ( self , mock_client : CosmosClient , mock_database : CosmosClient ) -> None : \"\"\"Set a mock client and database for testing purposes.\"\"\" self . client = mock_client self . database = mock_database","title":"CosmosDBSingleton"},{"location":"api/#centraal_client_flow.connections.cosmosdb.CosmosDBSingleton.__new__","text":"Create and return a new object. See help(type) for accurate signature. Source code in centraal_client_flow/connections/cosmosdb.py def __new__ ( cls , connection_string : Optional [ str ] = None , database_name : Optional [ str ] = None , ) -> \"CosmosDBSingleton\" : if cls . _instance is None : with cls . _lock : if cls . _instance is None : cls . _instance = super () . __new__ ( cls ) return cls . _instance","title":"__new__()"},{"location":"api/#centraal_client_flow.connections.cosmosdb.CosmosDBSingleton.get_container_client","text":"Get a container client. Source code in centraal_client_flow/connections/cosmosdb.py def get_container_client ( self , container_name : str ) -> ContainerProxy : \"\"\"Get a container client.\"\"\" self . _initialize () return self . database . get_container_client ( container_name )","title":"get_container_client()"},{"location":"api/#centraal_client_flow.connections.cosmosdb.CosmosDBSingleton.set_mock_client","text":"Set a mock client and database for testing purposes. Source code in centraal_client_flow/connections/cosmosdb.py def set_mock_client ( self , mock_client : CosmosClient , mock_database : CosmosClient ) -> None : \"\"\"Set a mock client and database for testing purposes.\"\"\" self . client = mock_client self . database = mock_database","title":"set_mock_client()"},{"location":"api/#centraal_client_flow.connections.service_bus","text":"Conexiones a service bus.","title":"service_bus"},{"location":"api/#centraal_client_flow.connections.service_bus.IServiceBusClient","text":"Interfaz. Source code in centraal_client_flow/connections/service_bus.py @runtime_checkable class IServiceBusClient ( Protocol ): \"\"\"Interfaz.\"\"\" client : Optional [ ServiceBusClient ] = None connection_str : Optional [ str ] = None def send_message_to_queue ( self , message : dict , session_id : str , queue_name : str ): \"\"\"Env\u00eda un mensaje a la cola de Service Bus especificada. Args: message: El mensaje a enviar representado como un diccionario. session_id: ID de sesi\u00f3n para el mensaje. Debe ser el id del modelo. queue_name: Nombre de la cola a la que se enviar\u00e1 el mensaje. \"\"\"","title":"IServiceBusClient"},{"location":"api/#centraal_client_flow.connections.service_bus.IServiceBusClient.send_message_to_queue","text":"Env\u00eda un mensaje a la cola de Service Bus especificada. Parameters: Name Type Description Default message dict El mensaje a enviar representado como un diccionario. required session_id str ID de sesi\u00f3n para el mensaje. Debe ser el id del modelo. required queue_name str Nombre de la cola a la que se enviar\u00e1 el mensaje. required Source code in centraal_client_flow/connections/service_bus.py def send_message_to_queue ( self , message : dict , session_id : str , queue_name : str ): \"\"\"Env\u00eda un mensaje a la cola de Service Bus especificada. Args: message: El mensaje a enviar representado como un diccionario. session_id: ID de sesi\u00f3n para el mensaje. Debe ser el id del modelo. queue_name: Nombre de la cola a la que se enviar\u00e1 el mensaje. \"\"\"","title":"send_message_to_queue()"},{"location":"api/#centraal_client_flow.connections.service_bus.ServiceBusClientSingleton","text":"Singleton para manejar la conexi\u00f3n a Azure Service Bus. Source code in centraal_client_flow/connections/service_bus.py class ServiceBusClientSingleton ( IServiceBusClient ): \"\"\"Singleton para manejar la conexi\u00f3n a Azure Service Bus.\"\"\" _instance = None client : Optional [ ServiceBusClient ] = None connection_str : Optional [ str ] = None senders = {} MAX_RETRIES = 3 RETRY_DELAY = 1 def __new__ ( cls , connection_str : str ): \"\"\"Crea una instancia \u00fanica de ServiceBusClientSingleton si no existe. Args: connection_str: Cadena de conexi\u00f3n a Azure Service Bus. \"\"\" if cls . _instance is None : cls . _instance = super ( ServiceBusClientSingleton , cls ) . __new__ ( cls ) cls . _instance . connection_str = connection_str cls . _instance . _initialize_client () return cls . _instance def _initialize_client ( self ): \"\"\"Initialize the Service Bus client with retry logic.\"\"\" for attempt in range ( self . MAX_RETRIES ): try : self . client = ServiceBusClient . from_connection_string ( self . connection_str ) logger . info ( \"Successfully initialized Service Bus client\" ) return except ( ServiceBusError , ServiceBusConnectionError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to initialize Service Bus client after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise logger . warning ( f \"Attempt { attempt + 1 } failed to initialize Service Bus client: { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) def _ensure_client_connection ( self ): \"\"\"Ensure the client is connected and valid.\"\"\" if not self . client : self . _initialize_client () return self . client def get_sender ( self , queue_name : str ): \"\"\"Get or create a sender for the specified queue with retry logic.\"\"\" if queue_name not in self . senders : for attempt in range ( self . MAX_RETRIES ): try : client = self . _ensure_client_connection () if queue_name in self . senders : try : self . senders [ queue_name ] . close () except Exception as e : logger . warning ( f \"Error closing existing sender: { str ( e ) } \" ) self . senders [ queue_name ] = client . get_queue_sender ( queue_name ) logger . info ( f \"Successfully created sender for queue: { queue_name } \" ) break except ( ServiceBusError , ServiceBusConnectionError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to create sender for queue { queue_name } after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise logger . warning ( f \"Attempt { attempt + 1 } failed to create sender for queue { queue_name } : { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) self . _initialize_client () # Try to reinitialize the client return self . senders [ queue_name ] def send_message_to_queue ( self , message : dict , session_id : str , queue_name : str ): \"\"\"Env\u00eda un mensaje a la cola de Service Bus especificada con retry logic.\"\"\" for attempt in range ( self . MAX_RETRIES ): try : sender = self . get_sender ( queue_name ) msg = ServiceBusMessage ( body = json . dumps ( message )) msg . session_id = session_id sender . send_messages ( msg ) logger . debug ( f \"Successfully sent message to queue { queue_name } with session_id { session_id } \" ) return except ( ServiceBusError , ServiceBusConnectionError , ServiceRequestError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to send message to queue { queue_name } after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise e logger . warning ( f \"Attempt { attempt + 1 } failed to send message to queue { queue_name } : { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) self . _initialize_client () if queue_name in self . senders : try : self . senders [ queue_name ] . close () except Exception as close_error : logger . warning ( f \"Error closing sender during retry: { str ( close_error ) } \" ) del self . senders [ queue_name ] def close ( self ): \"\"\"Cierra la conexi\u00f3n con Azure Service Bus.\"\"\" try : for queue_name , sender in list ( self . senders . items ()): try : sender . close () logger . info ( f \"Successfully closed sender for queue: { queue_name } \" ) except Exception as e : logger . warning ( f \"Error closing sender for queue { queue_name } : { str ( e ) } \" ) if self . client : try : self . client . close () logger . info ( \"Successfully closed Service Bus client\" ) except Exception as e : logger . warning ( f \"Error closing client: { str ( e ) } \" ) self . senders . clear () self . client = None logger . info ( \"Successfully closed all Service Bus connections\" ) except Exception as e : logger . error ( f \"Error during Service Bus cleanup: { str ( e ) } \" ) raise","title":"ServiceBusClientSingleton"},{"location":"api/#centraal_client_flow.connections.service_bus.ServiceBusClientSingleton.__new__","text":"Crea una instancia \u00fanica de ServiceBusClientSingleton si no existe. Parameters: Name Type Description Default connection_str str Cadena de conexi\u00f3n a Azure Service Bus. required Source code in centraal_client_flow/connections/service_bus.py def __new__ ( cls , connection_str : str ): \"\"\"Crea una instancia \u00fanica de ServiceBusClientSingleton si no existe. Args: connection_str: Cadena de conexi\u00f3n a Azure Service Bus. \"\"\" if cls . _instance is None : cls . _instance = super ( ServiceBusClientSingleton , cls ) . __new__ ( cls ) cls . _instance . connection_str = connection_str cls . _instance . _initialize_client () return cls . _instance","title":"__new__()"},{"location":"api/#centraal_client_flow.connections.service_bus.ServiceBusClientSingleton.close","text":"Cierra la conexi\u00f3n con Azure Service Bus. Source code in centraal_client_flow/connections/service_bus.py def close ( self ): \"\"\"Cierra la conexi\u00f3n con Azure Service Bus.\"\"\" try : for queue_name , sender in list ( self . senders . items ()): try : sender . close () logger . info ( f \"Successfully closed sender for queue: { queue_name } \" ) except Exception as e : logger . warning ( f \"Error closing sender for queue { queue_name } : { str ( e ) } \" ) if self . client : try : self . client . close () logger . info ( \"Successfully closed Service Bus client\" ) except Exception as e : logger . warning ( f \"Error closing client: { str ( e ) } \" ) self . senders . clear () self . client = None logger . info ( \"Successfully closed all Service Bus connections\" ) except Exception as e : logger . error ( f \"Error during Service Bus cleanup: { str ( e ) } \" ) raise","title":"close()"},{"location":"api/#centraal_client_flow.connections.service_bus.ServiceBusClientSingleton.get_sender","text":"Get or create a sender for the specified queue with retry logic. Source code in centraal_client_flow/connections/service_bus.py def get_sender ( self , queue_name : str ): \"\"\"Get or create a sender for the specified queue with retry logic.\"\"\" if queue_name not in self . senders : for attempt in range ( self . MAX_RETRIES ): try : client = self . _ensure_client_connection () if queue_name in self . senders : try : self . senders [ queue_name ] . close () except Exception as e : logger . warning ( f \"Error closing existing sender: { str ( e ) } \" ) self . senders [ queue_name ] = client . get_queue_sender ( queue_name ) logger . info ( f \"Successfully created sender for queue: { queue_name } \" ) break except ( ServiceBusError , ServiceBusConnectionError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to create sender for queue { queue_name } after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise logger . warning ( f \"Attempt { attempt + 1 } failed to create sender for queue { queue_name } : { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) self . _initialize_client () # Try to reinitialize the client return self . senders [ queue_name ]","title":"get_sender()"},{"location":"api/#centraal_client_flow.connections.service_bus.ServiceBusClientSingleton.send_message_to_queue","text":"Env\u00eda un mensaje a la cola de Service Bus especificada con retry logic. Source code in centraal_client_flow/connections/service_bus.py def send_message_to_queue ( self , message : dict , session_id : str , queue_name : str ): \"\"\"Env\u00eda un mensaje a la cola de Service Bus especificada con retry logic.\"\"\" for attempt in range ( self . MAX_RETRIES ): try : sender = self . get_sender ( queue_name ) msg = ServiceBusMessage ( body = json . dumps ( message )) msg . session_id = session_id sender . send_messages ( msg ) logger . debug ( f \"Successfully sent message to queue { queue_name } with session_id { session_id } \" ) return except ( ServiceBusError , ServiceBusConnectionError , ServiceRequestError , AttributeError ) as e : if attempt == self . MAX_RETRIES - 1 : logger . error ( f \"Failed to send message to queue { queue_name } after { self . MAX_RETRIES } attempts: { str ( e ) } \" ) raise e logger . warning ( f \"Attempt { attempt + 1 } failed to send message to queue { queue_name } : { str ( e ) } \" ) time . sleep ( self . RETRY_DELAY ) self . _initialize_client () if queue_name in self . senders : try : self . senders [ queue_name ] . close () except Exception as close_error : logger . warning ( f \"Error closing sender during retry: { str ( close_error ) } \" ) del self . senders [ queue_name ]","title":"send_message_to_queue()"},{"location":"api/#centraal_client_flow.events","text":"Codigo compartido por los submodulos.","title":"events"},{"location":"api/#centraal_client_flow.events.EventProcessor","text":"Clase base abstracta para procesadores de eventos. Source code in centraal_client_flow/events/__init__.py class EventProcessor ( LoggerMixin , ABC ): \"\"\"Clase base abstracta para procesadores de eventos.\"\"\" @abstractmethod def process_event ( self , event : BaseModel ) -> EventoBase : \"\"\" Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: event: Objeto que corresponde a modelo pydantic. \"\"\"","title":"EventProcessor"},{"location":"api/#centraal_client_flow.events.EventProcessor.process_event","text":"Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: Name Type Description Default event BaseModel Objeto que corresponde a modelo pydantic. required Source code in centraal_client_flow/events/__init__.py @abstractmethod def process_event ( self , event : BaseModel ) -> EventoBase : \"\"\" Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: event: Objeto que corresponde a modelo pydantic. \"\"\"","title":"process_event()"},{"location":"api/#centraal_client_flow.events.PullProcessor","text":"Clase base abstracta para procesadores de eventos. Source code in centraal_client_flow/events/__init__.py class PullProcessor ( LoggerMixin , ABC ): \"\"\"Clase base abstracta para procesadores de eventos.\"\"\" @abstractmethod def get_data ( self ) -> List [ BaseModel ]: \"\"\" Obtiene la informacion \"\"\" @abstractmethod def process_event ( self , event_data : BaseModel ) -> EventoBase : \"\"\" Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: event_data: Objeto que corresponde a modelo pydantic. \"\"\"","title":"PullProcessor"},{"location":"api/#centraal_client_flow.events.PullProcessor.get_data","text":"Obtiene la informacion Source code in centraal_client_flow/events/__init__.py @abstractmethod def get_data ( self ) -> List [ BaseModel ]: \"\"\" Obtiene la informacion \"\"\"","title":"get_data()"},{"location":"api/#centraal_client_flow.events.PullProcessor.process_event","text":"Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: Name Type Description Default event_data BaseModel Objeto que corresponde a modelo pydantic. required Source code in centraal_client_flow/events/__init__.py @abstractmethod def process_event ( self , event_data : BaseModel ) -> EventoBase : \"\"\" Procesa el evento recibido. y retorna el modelo de EventoBase Parameters: event_data: Objeto que corresponde a modelo pydantic. \"\"\"","title":"process_event()"},{"location":"api/#centraal_client_flow.events.processor","text":"Definicion de clase EventProcessor.","title":"processor"},{"location":"api/#centraal_client_flow.events.processor.EventProcessor","text":"Clase para procesar eventos. Esta clase estandariza la manera de procesar eventos basado en pydantic. La clase sirve coom clase a heredar y debe implementar un metodo: - process_event que general puede recibir cualquier tipo de dato pero debe devolver un evento validado (EventoBase) o una lista de evento validados (List[EventoBase]). el usuario solo tiene implemenetar ese metodo ya que luego la clase se encarga de: 1. controlar errores de validaci\u00f3n, para hacer un logger adecuado 2. enviar el evento a la cola de eventos de manera asincrona(usando batch si es necesario). Source code in centraal_client_flow/events/processor.py class EventProcessor ( ABC ): \"\"\"Clase para procesar eventos. Esta clase estandariza la manera de procesar eventos basado en pydantic. La clase sirve coom clase a heredar y debe implementar un metodo: - process_event que general puede recibir cualquier tipo de dato pero debe devolver un evento validado (EventoBase) o una lista de evento validados (List[EventoBase]). el usuario solo tiene implemenetar ese metodo ya que luego la clase se encarga de: 1. controlar errores de validaci\u00f3n, para hacer un logger adecuado 2. enviar el evento a la cola de eventos de manera asincrona(usando batch si es necesario). \"\"\" @abstractmethod def process_event ( self , event : Any ) -> Union [ EventoBase , List [ EventoBase ]]: \"\"\"Procesa un evento.\"\"\" pass def handle_event ( self , data : Any ) -> None : try : eventos = self . process_event ( data ) if not isinstance ( eventos , list ): eventos = [ eventos ] self . send_to_queue ( eventos ) except ValidationError as ve : # Aqu\u00ed manejar\u00edas el logging adecuado de los errores de validaci\u00f3n print ( f \"Error de validaci\u00f3n: { ve } \" ) except Exception as e : # Manejo de otras excepciones print ( f \"Error al procesar el evento: { e } \" ) def send_to_queue ( self , eventos : List [ EventoBase ]) -> None : \"\"\"Envia un evento a la cola de eventos.\"\"\" pass","title":"EventProcessor"},{"location":"api/#centraal_client_flow.events.processor.EventProcessor.process_event","text":"Procesa un evento. Source code in centraal_client_flow/events/processor.py @abstractmethod def process_event ( self , event : Any ) -> Union [ EventoBase , List [ EventoBase ]]: \"\"\"Procesa un evento.\"\"\" pass","title":"process_event()"},{"location":"api/#centraal_client_flow.events.processor.EventProcessor.send_to_queue","text":"Envia un evento a la cola de eventos. Source code in centraal_client_flow/events/processor.py def send_to_queue ( self , eventos : List [ EventoBase ]) -> None : \"\"\"Envia un evento a la cola de eventos.\"\"\" pass","title":"send_to_queue()"},{"location":"api/#centraal_client_flow.events.receiver","text":"M\u00f3dulo para recibir eventos desde una fuente externa y procesarlos a trav\u00e9s de Azure Functions.","title":"receiver"},{"location":"api/#centraal_client_flow.events.receiver.EventFunctionBuilder","text":"Clase para construir y registrar funciones de Azure para recibir y procesar eventos. Esta clase permite construir din\u00e1micamente funciones de Azure que se desencadenan por solicitudes HTTP POST para recibir y procesar eventos utilizando un modelo de evento espec\u00edfico y un procesador de eventos. Source code in centraal_client_flow/events/receiver.py class EventFunctionBuilder : \"\"\" Clase para construir y registrar funciones de Azure para recibir y procesar eventos. Esta clase permite construir din\u00e1micamente funciones de Azure que se desencadenan por solicitudes HTTP POST para recibir y procesar eventos utilizando un modelo de evento espec\u00edfico y un procesador de eventos. \"\"\" def __init__ ( self , function_name : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , processor : EventProcessor , event_model : type [ BaseModel ], ): \"\"\" Inicializa un constructor de funciones para eventos con los par\u00e1metros especificados. Args: function_name: Nombre \u00fanico de la funci\u00f3n que se va a registrar. event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. processor: Procesador de eventos que hereda de EventProcessor. event_model: Modelo Pydantic para validar y parsear los eventos. \"\"\" self . function_name = function_name self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client self . processor = processor self . event_model = event_model def build_function ( self ): \"\"\" Construye la funci\u00f3n de Azure para recibir y procesar eventos. Returns: Una funci\u00f3n que procesa solicitudes HTTP POST, valida los eventos recibidos y los env\u00eda a una cola de Service Bus. \"\"\" def receive_event ( req : HttpRequest ) -> HttpResponse : event_data = req . get_json () logging . info ( \"validando informacion\" ) event = self . event_model . model_validate ( event_data ) event_validado = self . processor . process_event ( event ) data_validada = event_validado . model_dump ( mode = \"json\" , exclude_none = True ) logging . info ( \"enviando informacion\" ) self . service_bus_client . send_message_to_queue ( data_validada , str ( event_validado . id ), self . queue_name ) return HttpResponse ( f \"Evento de { self . event_source } es procesado.\" , status_code = 200 ) return receive_event def register_function ( self , bp : Blueprint ): \"\"\" Registra la funci\u00f3n construida en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. Returns: El Blueprint actualizado con la funci\u00f3n registrada. \"\"\" receive_event = self . build_function () bp . function_name ( name = self . function_name )( bp . route ( methods = [ \"POST\" ])( receive_event ) ) return bp","title":"EventFunctionBuilder"},{"location":"api/#centraal_client_flow.events.receiver.EventFunctionBuilder.__init__","text":"Inicializa un constructor de funciones para eventos con los par\u00e1metros especificados. Parameters: Name Type Description Default function_name str Nombre \u00fanico de la funci\u00f3n que se va a registrar. required event_source str Nombre de la fuente del evento. required queue_name str Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. required service_bus_client IServiceBusClient Cliente de Service Bus para enviar mensajes. required processor EventProcessor Procesador de eventos que hereda de EventProcessor. required event_model type[pydantic.main.BaseModel] Modelo Pydantic para validar y parsear los eventos. required Source code in centraal_client_flow/events/receiver.py def __init__ ( self , function_name : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , processor : EventProcessor , event_model : type [ BaseModel ], ): \"\"\" Inicializa un constructor de funciones para eventos con los par\u00e1metros especificados. Args: function_name: Nombre \u00fanico de la funci\u00f3n que se va a registrar. event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. processor: Procesador de eventos que hereda de EventProcessor. event_model: Modelo Pydantic para validar y parsear los eventos. \"\"\" self . function_name = function_name self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client self . processor = processor self . event_model = event_model","title":"__init__()"},{"location":"api/#centraal_client_flow.events.receiver.EventFunctionBuilder.build_function","text":"Construye la funci\u00f3n de Azure para recibir y procesar eventos. Returns: Type Description Una funci\u00f3n que procesa solicitudes HTTP POST, valida los eventos recibidos y los env\u00eda a una cola de Service Bus. Source code in centraal_client_flow/events/receiver.py def build_function ( self ): \"\"\" Construye la funci\u00f3n de Azure para recibir y procesar eventos. Returns: Una funci\u00f3n que procesa solicitudes HTTP POST, valida los eventos recibidos y los env\u00eda a una cola de Service Bus. \"\"\" def receive_event ( req : HttpRequest ) -> HttpResponse : event_data = req . get_json () logging . info ( \"validando informacion\" ) event = self . event_model . model_validate ( event_data ) event_validado = self . processor . process_event ( event ) data_validada = event_validado . model_dump ( mode = \"json\" , exclude_none = True ) logging . info ( \"enviando informacion\" ) self . service_bus_client . send_message_to_queue ( data_validada , str ( event_validado . id ), self . queue_name ) return HttpResponse ( f \"Evento de { self . event_source } es procesado.\" , status_code = 200 ) return receive_event","title":"build_function()"},{"location":"api/#centraal_client_flow.events.receiver.EventFunctionBuilder.register_function","text":"Registra la funci\u00f3n construida en el Blueprint proporcionado. Parameters: Name Type Description Default bp Blueprint Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. required Returns: Type Description El Blueprint actualizado con la funci\u00f3n registrada. Source code in centraal_client_flow/events/receiver.py def register_function ( self , bp : Blueprint ): \"\"\" Registra la funci\u00f3n construida en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. Returns: El Blueprint actualizado con la funci\u00f3n registrada. \"\"\" receive_event = self . build_function () bp . function_name ( name = self . function_name )( bp . route ( methods = [ \"POST\" ])( receive_event ) ) return bp","title":"register_function()"},{"location":"api/#centraal_client_flow.events.receiver.Recieve","text":"Clase para manejar la recepci\u00f3n y procesamiento de eventos desde una fuente espec\u00edfica. Esta clase define y registra reglas de procesamiento de eventos utilizando una fuente de eventos, un modelo de evento, y un procesador de eventos. Source code in centraal_client_flow/events/receiver.py class Recieve : \"\"\" Clase para manejar la recepci\u00f3n y procesamiento de eventos desde una fuente espec\u00edfica. Esta clase define y registra reglas de procesamiento de eventos utilizando una fuente de eventos, un modelo de evento, y un procesador de eventos. \"\"\" def __init__ ( self , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , ): \"\"\" Inicializa una instancia de Receiver. Args: event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. \"\"\" self . function_name = f \" { event_source . lower () } _receive_event\" self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client def register_function ( self , bp : Blueprint , processor : EventProcessor , event_model : type [ BaseModel ], ) -> None : \"\"\" Crea y registra una funci\u00f3n para recibir y procesar eventos en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. processor: Instancia de una clase que hereda de EventProcessor. event_model: Modelo Pydantic para validar y parsear el evento. Returns: El Blueprint actualizado con la funci\u00f3n de procesamiento de eventos registrada. \"\"\" builder = EventFunctionBuilder ( function_name = self . function_name , event_source = self . event_source , queue_name = self . queue_name , service_bus_client = self . service_bus_client , processor = processor , event_model = event_model , ) builder . register_function ( bp )","title":"Recieve"},{"location":"api/#centraal_client_flow.events.receiver.Recieve.__init__","text":"Inicializa una instancia de Receiver. Parameters: Name Type Description Default event_source str Nombre de la fuente del evento. required queue_name str Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. required service_bus_client IServiceBusClient Cliente de Service Bus para enviar mensajes. required Source code in centraal_client_flow/events/receiver.py def __init__ ( self , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , ): \"\"\" Inicializa una instancia de Receiver. Args: event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. \"\"\" self . function_name = f \" { event_source . lower () } _receive_event\" self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client","title":"__init__()"},{"location":"api/#centraal_client_flow.events.receiver.Recieve.register_function","text":"Crea y registra una funci\u00f3n para recibir y procesar eventos en el Blueprint proporcionado. Parameters: Name Type Description Default bp Blueprint Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. required processor EventProcessor Instancia de una clase que hereda de EventProcessor. required event_model type[pydantic.main.BaseModel] Modelo Pydantic para validar y parsear el evento. required Returns: Type Description None El Blueprint actualizado con la funci\u00f3n de procesamiento de eventos registrada. Source code in centraal_client_flow/events/receiver.py def register_function ( self , bp : Blueprint , processor : EventProcessor , event_model : type [ BaseModel ], ) -> None : \"\"\" Crea y registra una funci\u00f3n para recibir y procesar eventos en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. processor: Instancia de una clase que hereda de EventProcessor. event_model: Modelo Pydantic para validar y parsear el evento. Returns: El Blueprint actualizado con la funci\u00f3n de procesamiento de eventos registrada. \"\"\" builder = EventFunctionBuilder ( function_name = self . function_name , event_source = self . event_source , queue_name = self . queue_name , service_bus_client = self . service_bus_client , processor = processor , event_model = event_model , ) builder . register_function ( bp )","title":"register_function()"},{"location":"api/#centraal_client_flow.events.timer","text":"M\u00f3dulo para recibir eventos desde una fuente externa y procesarlos a trav\u00e9s de Azure Functions.","title":"timer"},{"location":"api/#centraal_client_flow.events.timer.Pull","text":"Clase para manejar la ejecuci\u00f3n de tareas programadas y el env\u00edo de datos a Service Bus. Esta clase define y registra reglas de procesamiento de tareas utilizando un temporizador, un procesador de eventos y un cliente de Service Bus. Source code in centraal_client_flow/events/timer.py class Pull : \"\"\" Clase para manejar la ejecuci\u00f3n de tareas programadas y el env\u00edo de datos a Service Bus. Esta clase define y registra reglas de procesamiento de tareas utilizando un temporizador, un procesador de eventos y un cliente de Service Bus. \"\"\" def __init__ ( self , schedule : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , ): \"\"\" Inicializa una instancia de Pull. Args: schedule: Cadena que define el horario del temporizador (CRON). event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. \"\"\" self . function_name = f \" { event_source . lower () } _scheduled_event\" self . schedule = schedule self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client def register_function ( self , bp : Blueprint , processor : PullProcessor , ) -> None : \"\"\" Crea y registra una funci\u00f3n programada para ejecutar tareas peri\u00f3dicamente en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. processor: Instancia de una clase que hereda de PullProcessor. Returns: El Blueprint actualizado con la funci\u00f3n programada registrada. \"\"\" builder = TimerFunctionBuilder ( function_name = self . function_name , schedule = self . schedule , event_source = self . event_source , queue_name = self . queue_name , service_bus_client = self . service_bus_client , processor = processor , ) builder . register_function ( bp )","title":"Pull"},{"location":"api/#centraal_client_flow.events.timer.Pull.__init__","text":"Inicializa una instancia de Pull. Parameters: Name Type Description Default schedule str Cadena que define el horario del temporizador (CRON). required event_source str Nombre de la fuente del evento. required queue_name str Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. required service_bus_client IServiceBusClient Cliente de Service Bus para enviar mensajes. required Source code in centraal_client_flow/events/timer.py def __init__ ( self , schedule : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , ): \"\"\" Inicializa una instancia de Pull. Args: schedule: Cadena que define el horario del temporizador (CRON). event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. \"\"\" self . function_name = f \" { event_source . lower () } _scheduled_event\" self . schedule = schedule self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client","title":"__init__()"},{"location":"api/#centraal_client_flow.events.timer.Pull.register_function","text":"Crea y registra una funci\u00f3n programada para ejecutar tareas peri\u00f3dicamente en el Blueprint proporcionado. Parameters: Name Type Description Default bp Blueprint Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. required processor PullProcessor Instancia de una clase que hereda de PullProcessor. required Returns: Type Description None El Blueprint actualizado con la funci\u00f3n programada registrada. Source code in centraal_client_flow/events/timer.py def register_function ( self , bp : Blueprint , processor : PullProcessor , ) -> None : \"\"\" Crea y registra una funci\u00f3n programada para ejecutar tareas peri\u00f3dicamente en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. processor: Instancia de una clase que hereda de PullProcessor. Returns: El Blueprint actualizado con la funci\u00f3n programada registrada. \"\"\" builder = TimerFunctionBuilder ( function_name = self . function_name , schedule = self . schedule , event_source = self . event_source , queue_name = self . queue_name , service_bus_client = self . service_bus_client , processor = processor , ) builder . register_function ( bp )","title":"register_function()"},{"location":"api/#centraal_client_flow.events.timer.TimerFunctionBuilder","text":"Clase para construir y registrar funciones de Azure programadas. Esta clase permite construir din\u00e1micamente funciones de Azure que se desencadenan por un temporizador, procesan eventos y los env\u00edan a un Service Bus. Source code in centraal_client_flow/events/timer.py class TimerFunctionBuilder : \"\"\" Clase para construir y registrar funciones de Azure programadas. Esta clase permite construir din\u00e1micamente funciones de Azure que se desencadenan por un temporizador, procesan eventos y los env\u00edan a un Service Bus. \"\"\" def __init__ ( self , function_name : str , schedule : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , processor : PullProcessor , ): \"\"\" Inicializa un constructor de funciones programadas con los par\u00e1metros especificados. Args: function_name: Nombre \u00fanico de la funci\u00f3n que se va a registrar. schedule: Cadena que define el horario del temporizador (CRON). event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. processor: Procesador de eventos que hereda de PullProcessor. \"\"\" self . function_name = function_name self . schedule = schedule self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client self . processor = processor def build_function ( self ): \"\"\" Construye la funci\u00f3n de Azure programada para ejecutar tareas peri\u00f3dicamente. Returns: Una funci\u00f3n que se ejecuta en base a un temporizador, procesa datos y los env\u00eda a una cola de Service Bus. \"\"\" def timer_function ( mytimer : TimerRequest ): if mytimer . past_due : logging . info ( \"The timer is past due!\" ) event_data = self . processor . get_data () for event_in_data in event_data : try : event_validado = self . processor . process_event ( event_in_data ) data_validada = event_validado . model_dump ( mode = \"json\" , exclude_none = True ) self . service_bus_client . send_message_to_queue ( data_validada , str ( event_validado . id ), self . queue_name ) except ValidationError as e : logging . error ( \"Error en %s , excepci\u00f3n: \\n %s \" , event_in_data , e ) return timer_function def register_function ( self , bp : Blueprint ): \"\"\" Registra la funci\u00f3n construida en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. Returns: El Blueprint actualizado con la funci\u00f3n registrada. \"\"\" timer_function = self . build_function () bp . function_name ( name = self . function_name )( bp . schedule ( schedule = self . schedule , arg_name = \"mytimer\" , run_on_startup = False )( timer_function ) ) return bp","title":"TimerFunctionBuilder"},{"location":"api/#centraal_client_flow.events.timer.TimerFunctionBuilder.__init__","text":"Inicializa un constructor de funciones programadas con los par\u00e1metros especificados. Parameters: Name Type Description Default function_name str Nombre \u00fanico de la funci\u00f3n que se va a registrar. required schedule str Cadena que define el horario del temporizador (CRON). required event_source str Nombre de la fuente del evento. required queue_name str Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. required service_bus_client IServiceBusClient Cliente de Service Bus para enviar mensajes. required processor PullProcessor Procesador de eventos que hereda de PullProcessor. required Source code in centraal_client_flow/events/timer.py def __init__ ( self , function_name : str , schedule : str , event_source : str , queue_name : str , service_bus_client : IServiceBusClient , processor : PullProcessor , ): \"\"\" Inicializa un constructor de funciones programadas con los par\u00e1metros especificados. Args: function_name: Nombre \u00fanico de la funci\u00f3n que se va a registrar. schedule: Cadena que define el horario del temporizador (CRON). event_source: Nombre de la fuente del evento. queue_name: Nombre de la cola de Service Bus donde se enviar\u00e1n los mensajes. service_bus_client: Cliente de Service Bus para enviar mensajes. processor: Procesador de eventos que hereda de PullProcessor. \"\"\" self . function_name = function_name self . schedule = schedule self . event_source = event_source self . queue_name = queue_name self . service_bus_client = service_bus_client self . processor = processor","title":"__init__()"},{"location":"api/#centraal_client_flow.events.timer.TimerFunctionBuilder.build_function","text":"Construye la funci\u00f3n de Azure programada para ejecutar tareas peri\u00f3dicamente. Returns: Type Description Una funci\u00f3n que se ejecuta en base a un temporizador, procesa datos y los env\u00eda a una cola de Service Bus. Source code in centraal_client_flow/events/timer.py def build_function ( self ): \"\"\" Construye la funci\u00f3n de Azure programada para ejecutar tareas peri\u00f3dicamente. Returns: Una funci\u00f3n que se ejecuta en base a un temporizador, procesa datos y los env\u00eda a una cola de Service Bus. \"\"\" def timer_function ( mytimer : TimerRequest ): if mytimer . past_due : logging . info ( \"The timer is past due!\" ) event_data = self . processor . get_data () for event_in_data in event_data : try : event_validado = self . processor . process_event ( event_in_data ) data_validada = event_validado . model_dump ( mode = \"json\" , exclude_none = True ) self . service_bus_client . send_message_to_queue ( data_validada , str ( event_validado . id ), self . queue_name ) except ValidationError as e : logging . error ( \"Error en %s , excepci\u00f3n: \\n %s \" , event_in_data , e ) return timer_function","title":"build_function()"},{"location":"api/#centraal_client_flow.events.timer.TimerFunctionBuilder.register_function","text":"Registra la funci\u00f3n construida en el Blueprint proporcionado. Parameters: Name Type Description Default bp Blueprint Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. required Returns: Type Description El Blueprint actualizado con la funci\u00f3n registrada. Source code in centraal_client_flow/events/timer.py def register_function ( self , bp : Blueprint ): \"\"\" Registra la funci\u00f3n construida en el Blueprint proporcionado. Args: bp: Blueprint de Azure Functions donde se registrar\u00e1 la funci\u00f3n. Returns: El Blueprint actualizado con la funci\u00f3n registrada. \"\"\" timer_function = self . build_function () bp . function_name ( name = self . function_name )( bp . schedule ( schedule = self . schedule , arg_name = \"mytimer\" , run_on_startup = False )( timer_function ) ) return bp","title":"register_function()"},{"location":"api/#centraal_client_flow.helpers","text":"","title":"helpers"},{"location":"api/#centraal_client_flow.helpers.cosmos","text":"Helpers para interactuar con cosmos.","title":"cosmos"},{"location":"api/#centraal_client_flow.helpers.cosmos.save_model_to_cosmos","text":"Saves a Pydantic model instance to the specified Cosmos DB container. Source code in centraal_client_flow/helpers/cosmos.py def save_model_to_cosmos ( cosmos_db : CosmosDBSingleton , container_name : str , model_instance : Type [ BaseModel ] ) -> dict : \"\"\"Saves a Pydantic model instance to the specified Cosmos DB container.\"\"\" container_client = cosmos_db . get_container_client ( container_name ) item_written = write_model_to_cosmos ( container_client , model_instance ) return item_written","title":"save_model_to_cosmos()"},{"location":"api/#centraal_client_flow.helpers.cosmos.write_model_to_cosmos","text":"Writes a Pydantic model instance to the specified Cosmos DB container. Source code in centraal_client_flow/helpers/cosmos.py def write_model_to_cosmos ( container_client : ContainerProxy , model_instance : Type [ BaseModel ] ) -> dict : \"\"\"Writes a Pydantic model instance to the specified Cosmos DB container.\"\"\" return container_client . upsert_item ( body = model_instance . model_dump ( mode = \"json\" , exclude_none = True ) )","title":"write_model_to_cosmos()"},{"location":"api/#centraal_client_flow.helpers.logger","text":"Utilidades para logger.","title":"logger"},{"location":"api/#centraal_client_flow.helpers.logger.LoggerMixin","text":"Clase base abstracta para proveer funcionalidad de logging. Source code in centraal_client_flow/helpers/logger.py class LoggerMixin : \"\"\"Clase base abstracta para proveer funcionalidad de logging.\"\"\" def __init__ ( self , logger : Optional [ logging . Logger ] = None ): \"\"\" Inicializa la clase base con un logger opcional. Parameters: logger: Instancia de logging.Logger para registrar eventos. \"\"\" self . logger = logger or logging . getLogger ( self . __class__ . __name__ )","title":"LoggerMixin"},{"location":"api/#centraal_client_flow.helpers.logger.LoggerMixin.__init__","text":"Inicializa la clase base con un logger opcional. Parameters: Name Type Description Default logger Optional[logging.Logger] Instancia de logging.Logger para registrar eventos. None Source code in centraal_client_flow/helpers/logger.py def __init__ ( self , logger : Optional [ logging . Logger ] = None ): \"\"\" Inicializa la clase base con un logger opcional. Parameters: logger: Instancia de logging.Logger para registrar eventos. \"\"\" self . logger = logger or logging . getLogger ( self . __class__ . __name__ )","title":"__init__()"},{"location":"api/#centraal_client_flow.helpers.pydantic","text":"Helpers relacionados con pydantic.","title":"pydantic"},{"location":"api/#centraal_client_flow.helpers.pydantic.built_valid_json_str_with_aditional_info","text":"Construye una cadena JSON v\u00e1lida con informaci\u00f3n adicional. Source code in centraal_client_flow/helpers/pydantic.py def built_valid_json_str_with_aditional_info ( error_message : str , additional_info : str ) -> str : \"\"\" Construye una cadena JSON v\u00e1lida con informaci\u00f3n adicional. \"\"\" valid_dict = { \"error_validacion\" : error_message } if additional_info : valid_dict [ \"error_validacion_detalle\" ] = additional_info return json . dumps ( valid_dict , ensure_ascii = False )","title":"built_valid_json_str_with_aditional_info()"},{"location":"api/#centraal_client_flow.helpers.pydantic.serialize_validation_errors","text":"Serializa los errores de validaci\u00f3n en una cadena JSON adecuada para Cosmos DB. Parameters: Name Type Description Default errors list[pydantic_core.ErrorDetails] Lista de diccionarios que describen los errores de validaci\u00f3n. required Returns: Type Description str Cadena JSON que representa los errores de validaci\u00f3n. Source code in centraal_client_flow/helpers/pydantic.py def serialize_validation_errors ( errors : list [ ErrorDetails ]) -> str : \"\"\" Serializa los errores de validaci\u00f3n en una cadena JSON adecuada para Cosmos DB. Args: errors: Lista de diccionarios que describen los errores de validaci\u00f3n. Returns: Cadena JSON que representa los errores de validaci\u00f3n. \"\"\" return json . dumps ( errors , default = _custom_serializer , ensure_ascii = False )","title":"serialize_validation_errors()"},{"location":"api/#centraal_client_flow.rules","text":"Comun para rules.","title":"rules"},{"location":"api/#centraal_client_flow.rules.NoHayReglas","text":"Excepci\u00f3n personalizada cuando no existen reglas. Source code in centraal_client_flow/rules/__init__.py class NoHayReglas ( Exception ): \"\"\"Excepci\u00f3n personalizada cuando no existen reglas.\"\"\" def __init__ ( self , mensaje : str ): super () . __init__ ( mensaje ) self . mensaje = mensaje","title":"NoHayReglas"},{"location":"api/#centraal_client_flow.rules.integration","text":"","title":"integration"},{"location":"api/#centraal_client_flow.rules.integration.processor","text":"Reglas de integraci\u00f3n.","title":"processor"},{"location":"api/#centraal_client_flow.rules.integration.processor.IntegrationRule","text":"Clase para definir y registrar reglas de integraci\u00f3n basadas en topics de Service Bus. Esta clase encapsula la l\u00f3gica para definir una regla de integraci\u00f3n utilizando un topic, una suscripci\u00f3n y una estrategia de integraci\u00f3n espec\u00edfica. Source code in centraal_client_flow/rules/integration/processor.py class IntegrationRule : \"\"\" Clase para definir y registrar reglas de integraci\u00f3n basadas en topics de Service Bus. Esta clase encapsula la l\u00f3gica para definir una regla de integraci\u00f3n utilizando un topic, una suscripci\u00f3n y una estrategia de integraci\u00f3n espec\u00edfica. \"\"\" def __init__ ( self , topic_name : str , connection_str : str , subscription_name : str , integration_strategy : IntegrationStrategy , model_unficado : type [ EntradaEsquemaUnificado ], ): \"\"\" Inicializa una regla de integraci\u00f3n con los par\u00e1metros especificados. Args: topic_name: Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. connection_str: Cadena de conexi\u00f3n para el Service Bus. subscription_name: Nombre de la suscripci\u00f3n en el topic de Service Bus. integration_strategy: Estrategia de integraci\u00f3n a aplicar en los mensajes procesados. model_unficado: Modelo de esquema unificado para validar y mapear los mensajes recibidos. \"\"\" if integration_strategy . name is not None : self . function_name = ( f \" { integration_strategy . name . lower () } _ { topic_name } _intrule\" ) else : self . function_name = f \" { topic_name } _intrule\" self . topic_name = topic_name self . connection_str = connection_str self . subscription_name = subscription_name self . integration_strategy = integration_strategy self . model_unficado = model_unficado self . id_esquema : Optional [ IDModel ] = None def run ( self , message : ServiceBusMessage | dict , logger : logging . Logger ) -> Optional [ StrategyResult ]: \"\"\"Ejecuta la regla de integraci\u00f3n.\"\"\" if isinstance ( message , ServiceBusMessage ): message = json . loads ( message . message ) try : message_esquema = self . model_unficado . model_validate ( message ) self . id_esquema = message_esquema . id output_model = self . integration_strategy . modelo_unificado_mapping ( message_esquema ) except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) logger . error ( \"Error antes de integraci\u00f3n en validaci\u00f3n %s \" , error_val_cosmos_friendly , exc_info = True , ) return StrategyResult ( success = False , response = { \"error_validacion\" : error_val_cosmos_friendly }, bodysent = { \"error_validacion\" : True }, ) return self . integration_strategy . integrate ( output_model ) def register_log ( self , result : StrategyResult , cosmos_client : CosmosDBSingleton , container_name : str , ): container = cosmos_client . get_container_client ( container_name ) if self . id_esquema is not None : entry = AuditoriaEntryIntegracion ( id = self . id_esquema , regla = self . function_name , contenido = result . bodysent , sucess = result . success , response = result . response , ) item_written = container . upsert_item ( entry . model_dump ( mode = \"json\" , exclude_none = True ), ) return item_written raise ValueError ( \"No es posible usar registro del log.\" )","title":"IntegrationRule"},{"location":"api/#centraal_client_flow.rules.integration.processor.IntegrationRule.__init__","text":"Inicializa una regla de integraci\u00f3n con los par\u00e1metros especificados. Parameters: Name Type Description Default topic_name str Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. required connection_str str Cadena de conexi\u00f3n para el Service Bus. required subscription_name str Nombre de la suscripci\u00f3n en el topic de Service Bus. required integration_strategy IntegrationStrategy Estrategia de integraci\u00f3n a aplicar en los mensajes procesados. required model_unficado type[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] Modelo de esquema unificado para validar y mapear los mensajes recibidos. required Source code in centraal_client_flow/rules/integration/processor.py def __init__ ( self , topic_name : str , connection_str : str , subscription_name : str , integration_strategy : IntegrationStrategy , model_unficado : type [ EntradaEsquemaUnificado ], ): \"\"\" Inicializa una regla de integraci\u00f3n con los par\u00e1metros especificados. Args: topic_name: Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. connection_str: Cadena de conexi\u00f3n para el Service Bus. subscription_name: Nombre de la suscripci\u00f3n en el topic de Service Bus. integration_strategy: Estrategia de integraci\u00f3n a aplicar en los mensajes procesados. model_unficado: Modelo de esquema unificado para validar y mapear los mensajes recibidos. \"\"\" if integration_strategy . name is not None : self . function_name = ( f \" { integration_strategy . name . lower () } _ { topic_name } _intrule\" ) else : self . function_name = f \" { topic_name } _intrule\" self . topic_name = topic_name self . connection_str = connection_str self . subscription_name = subscription_name self . integration_strategy = integration_strategy self . model_unficado = model_unficado self . id_esquema : Optional [ IDModel ] = None","title":"__init__()"},{"location":"api/#centraal_client_flow.rules.integration.processor.IntegrationRule.run","text":"Ejecuta la regla de integraci\u00f3n. Source code in centraal_client_flow/rules/integration/processor.py def run ( self , message : ServiceBusMessage | dict , logger : logging . Logger ) -> Optional [ StrategyResult ]: \"\"\"Ejecuta la regla de integraci\u00f3n.\"\"\" if isinstance ( message , ServiceBusMessage ): message = json . loads ( message . message ) try : message_esquema = self . model_unficado . model_validate ( message ) self . id_esquema = message_esquema . id output_model = self . integration_strategy . modelo_unificado_mapping ( message_esquema ) except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) logger . error ( \"Error antes de integraci\u00f3n en validaci\u00f3n %s \" , error_val_cosmos_friendly , exc_info = True , ) return StrategyResult ( success = False , response = { \"error_validacion\" : error_val_cosmos_friendly }, bodysent = { \"error_validacion\" : True }, ) return self . integration_strategy . integrate ( output_model )","title":"run()"},{"location":"api/#centraal_client_flow.rules.integration.strategy","text":"Estrategias.","title":"strategy"},{"location":"api/#centraal_client_flow.rules.integration.strategy.IntegrationStrategy","text":"Clase Abstracta para definir estrategias de integracion. Source code in centraal_client_flow/rules/integration/strategy.py class IntegrationStrategy ( ABC ): \"\"\"Clase Abstracta para definir estrategias de integracion.\"\"\" name : Optional [ str ] = None logger : logging . Logger def __init__ ( self , logger : Optional [ logging . Logger ] = None , name : Optional [ str ] = None ): \"\"\" Inicializa la estrategia de integraci\u00f3n con un logger opcional. Parameters: logger: Instancia opcional de logging.Logger. \"\"\" self . logger = logger or logging . getLogger ( self . __class__ . __name__ ) self . name = name @abstractmethod def modelo_unificado_mapping ( self , message : EntradaEsquemaUnificado ) -> Optional [ BaseModel ]: \"\"\"Mapea el mensaje de entrada a un modelo unificado de salida. Args: message: El mensaje de entrada a ser mapeado. Returns: Un modelo Pydantic que representa la salida mapeada. \"\"\" @abstractmethod def integrate ( self , output_model : Optional [ BaseModel ]) -> Optional [ Any ]: \"\"\"Realiza la integraci\u00f3n utilizando el modelo de salida. Args: output_model: El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. Returns: La respuesta de la integraci\u00f3n, generalmente en formato JSON. \"\"\"","title":"IntegrationStrategy"},{"location":"api/#centraal_client_flow.rules.integration.strategy.IntegrationStrategy.__init__","text":"Inicializa la estrategia de integraci\u00f3n con un logger opcional. Parameters: Name Type Description Default logger Optional[logging.Logger] Instancia opcional de logging.Logger. None Source code in centraal_client_flow/rules/integration/strategy.py def __init__ ( self , logger : Optional [ logging . Logger ] = None , name : Optional [ str ] = None ): \"\"\" Inicializa la estrategia de integraci\u00f3n con un logger opcional. Parameters: logger: Instancia opcional de logging.Logger. \"\"\" self . logger = logger or logging . getLogger ( self . __class__ . __name__ ) self . name = name","title":"__init__()"},{"location":"api/#centraal_client_flow.rules.integration.strategy.IntegrationStrategy.integrate","text":"Realiza la integraci\u00f3n utilizando el modelo de salida. Parameters: Name Type Description Default output_model Optional[pydantic.main.BaseModel] El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. required Returns: Type Description Optional[Any] La respuesta de la integraci\u00f3n, generalmente en formato JSON. Source code in centraal_client_flow/rules/integration/strategy.py @abstractmethod def integrate ( self , output_model : Optional [ BaseModel ]) -> Optional [ Any ]: \"\"\"Realiza la integraci\u00f3n utilizando el modelo de salida. Args: output_model: El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. Returns: La respuesta de la integraci\u00f3n, generalmente en formato JSON. \"\"\"","title":"integrate()"},{"location":"api/#centraal_client_flow.rules.integration.strategy.IntegrationStrategy.modelo_unificado_mapping","text":"Mapea el mensaje de entrada a un modelo unificado de salida. Parameters: Name Type Description Default message EntradaEsquemaUnificado El mensaje de entrada a ser mapeado. required Returns: Type Description Optional[pydantic.main.BaseModel] Un modelo Pydantic que representa la salida mapeada. Source code in centraal_client_flow/rules/integration/strategy.py @abstractmethod def modelo_unificado_mapping ( self , message : EntradaEsquemaUnificado ) -> Optional [ BaseModel ]: \"\"\"Mapea el mensaje de entrada a un modelo unificado de salida. Args: message: El mensaje de entrada a ser mapeado. Returns: Un modelo Pydantic que representa la salida mapeada. \"\"\"","title":"modelo_unificado_mapping()"},{"location":"api/#centraal_client_flow.rules.integration.strategy.OAuthConfigPassFlow","text":"Configuraci\u00f3n necesaria para la autenticaci\u00f3n OAuth 2.0 con grant_type=password. Source code in centraal_client_flow/rules/integration/strategy.py @dataclass class OAuthConfigPassFlow : \"\"\"Configuraci\u00f3n necesaria para la autenticaci\u00f3n OAuth 2.0 con grant_type=password.\"\"\" client_id : str client_secret : str username : str password : str token_resource : str api_url : str use_url_params_for_auth : bool = True","title":"OAuthConfigPassFlow"},{"location":"api/#centraal_client_flow.rules.integration.strategy.OAuthTokenPass","text":"Representa el token OAuth obtenido tras la autenticaci\u00f3n. Source code in centraal_client_flow/rules/integration/strategy.py @dataclass class OAuthTokenPass : \"\"\"Representa el token OAuth obtenido tras la autenticaci\u00f3n.\"\"\" access_token : str instance_url : str id : str token_type : str issued_at : int signature : str expires_in : int = 1800 def __post_init__ ( self ): if isinstance ( self . issued_at , str ): self . issued_at = int ( self . issued_at )","title":"OAuthTokenPass"},{"location":"api/#centraal_client_flow.rules.integration.strategy.RESTIntegration","text":"Estrategia de integracion basada en REST. Source code in centraal_client_flow/rules/integration/strategy.py class RESTIntegration ( IntegrationStrategy ): \"\"\"Estrategia de integracion basada en REST.\"\"\" def __init__ ( self , oauth_config : OAuthConfigPassFlow , method : str = \"POST\" , resource : str = \"\" , mapping_function : Optional [ Callable [[ EntradaEsquemaUnificado ], Optional [ BaseModel ]] ] = None , logger : Optional [ logging . Logger ] = None , ): \"\"\"Inicializa una instancia de RESTIntegration con la configuraci\u00f3n de OAuth y los par\u00e1metros REST. Args: oauth_config: Configuraci\u00f3n necesaria para autenticarse con OAuth 2.0. method: El m\u00e9todo HTTP que se utilizar\u00e1 para la integraci\u00f3n (por ejemplo, 'POST', 'PATCH'). resource: El recurso espec\u00edfico de la API con el cual se interactuar\u00e1. mapping_function: Una funci\u00f3n opcional que define c\u00f3mo mapear un `EntradaEsquemaUnificado` a un modelo Pydantic. \"\"\" if mapping_function is not None : super () . __init__ ( logger = logger , name = f \" { method } _ { mapping_function . __name__ } \" ) self . oauth_config = oauth_config self . method = method self . resource = resource self . mapping_function = mapping_function self . response_processor = lambda r , m : StrategyResult ( success = True , response = r , bodysent = m ) self . _token : Optional [ OAuthTokenPass ] = None def _authenticate ( self ) -> OAuthTokenPass : \"\"\"Autentica usando OAuth 2.0 con grant_type=password y obtiene un token de acceso. Returns: Un objeto `OAuthTokenPass` que contiene el token de acceso y otra informaci\u00f3n relevante. \"\"\" auth_data = { \"grant_type\" : \"password\" , \"client_id\" : self . oauth_config . client_id , \"client_secret\" : self . oauth_config . client_secret , \"username\" : self . oauth_config . username , \"password\" : self . oauth_config . password , } if self . oauth_config . use_url_params_for_auth : token_url = f \" { self . oauth_config . api_url } / { self . oauth_config . token_resource } ? { urlencode ( auth_data ) } \" response = requests . post ( token_url , headers = {}, timeout = 30 ) else : token_url = ( f \" { self . oauth_config . api_url } / { self . oauth_config . token_resource } \" ) response = requests . post ( token_url , data = auth_data , headers = {}, timeout = 30 ) response . raise_for_status () token_data = response . json () self . _token = OAuthTokenPass ( ** token_data ) return self . _token def _get_token ( self ) -> Optional [ str ]: \"\"\"Obtiene el token actual o lo renueva si ha expirado. Returns: El token de acceso en formato de cadena. \"\"\" if self . _token is None : self . _authenticate () if self . _token is not None : current_time = int ( time . time ()) expiration_time = self . _token . issued_at / 1000 + self . _token . expires_in if current_time >= expiration_time : self . logger . info ( \"El token ha expirado. Renovando...\" ) self . _authenticate () return self . _token . access_token raise ValueError ( \"error en autenticaci\u00f3n\" ) def modelo_unificado_mapping ( self , message : EntradaEsquemaUnificado ) -> Optional [ BaseModel ]: \"\"\"Mapea el mensaje de entrada a un modelo unificado de salida utilizando la funci\u00f3n de mapeo proporcionada. Args: message: El mensaje de entrada que ser\u00e1 mapeado. Returns: Un modelo Pydantic que representa la salida mapeada. Raises: TypeError: Si el mensaje no es una instancia de `EntradaEsquemaUnificado`. NotImplementedError: Si no se ha proporcionado una funci\u00f3n de mapeo personalizada. \"\"\" if self . mapping_function : if not isinstance ( message , EntradaEsquemaUnificado ): raise TypeError ( \"El mensaje debe ser una instancia de EntradaEsquemaUnificado\" ) return self . mapping_function ( message ) raise NotImplementedError ( \"No se ha proporcionado una funci\u00f3n de mapeo personalizada.\" ) def integrate ( self , output_model : Optional [ BaseModel ]) -> Optional [ StrategyResult ]: \"\"\"Realiza la integraci\u00f3n utilizando el modelo de salida mapeado. Args: output_model: El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. Returns: La respuesta defina en response_processor. Raises: HTTPError: Si la solicitud HTTP a la API falla. \"\"\" token = self . _get_token () headers = { \"Authorization\" : f \"Bearer { token } \" , \"Content-Type\" : \"application/json\" , } url = f \" { self . oauth_config . api_url } / { self . resource } \" if output_model is not None : response = requests . request ( self . method , url , json = output_model . model_dump ( mode = \"json\" , exclude_none = True ), headers = headers , timeout = 300 , ) response . raise_for_status () return self . response_processor ( response , output_model ) self . logger . info ( \"Evento es ignorado.\" ) return StrategyResult ( success = True , response = { \"evento_ignorado\" : True }, bodysent = { \"evento_ignorado\" : True }, ) def set_response_processor ( self , processor : Callable [[ requests . Response , BaseModel ], StrategyResult ] ): \"\"\"Configura un procesamiento de la respuesta.\"\"\" self . response_processor = processor","title":"RESTIntegration"},{"location":"api/#centraal_client_flow.rules.integration.strategy.RESTIntegration.__init__","text":"Inicializa una instancia de RESTIntegration con la configuraci\u00f3n de OAuth y los par\u00e1metros REST. Parameters: Name Type Description Default oauth_config OAuthConfigPassFlow Configuraci\u00f3n necesaria para autenticarse con OAuth 2.0. required method str El m\u00e9todo HTTP que se utilizar\u00e1 para la integraci\u00f3n (por ejemplo, 'POST', 'PATCH'). 'POST' resource str El recurso espec\u00edfico de la API con el cual se interactuar\u00e1. '' mapping_function Optional[Callable[[centraal_client_flow.models.schemas.EntradaEsquemaUnificado], Optional[pydantic.main.BaseModel]]] Una funci\u00f3n opcional que define c\u00f3mo mapear un EntradaEsquemaUnificado a un modelo Pydantic. None Source code in centraal_client_flow/rules/integration/strategy.py def __init__ ( self , oauth_config : OAuthConfigPassFlow , method : str = \"POST\" , resource : str = \"\" , mapping_function : Optional [ Callable [[ EntradaEsquemaUnificado ], Optional [ BaseModel ]] ] = None , logger : Optional [ logging . Logger ] = None , ): \"\"\"Inicializa una instancia de RESTIntegration con la configuraci\u00f3n de OAuth y los par\u00e1metros REST. Args: oauth_config: Configuraci\u00f3n necesaria para autenticarse con OAuth 2.0. method: El m\u00e9todo HTTP que se utilizar\u00e1 para la integraci\u00f3n (por ejemplo, 'POST', 'PATCH'). resource: El recurso espec\u00edfico de la API con el cual se interactuar\u00e1. mapping_function: Una funci\u00f3n opcional que define c\u00f3mo mapear un `EntradaEsquemaUnificado` a un modelo Pydantic. \"\"\" if mapping_function is not None : super () . __init__ ( logger = logger , name = f \" { method } _ { mapping_function . __name__ } \" ) self . oauth_config = oauth_config self . method = method self . resource = resource self . mapping_function = mapping_function self . response_processor = lambda r , m : StrategyResult ( success = True , response = r , bodysent = m ) self . _token : Optional [ OAuthTokenPass ] = None","title":"__init__()"},{"location":"api/#centraal_client_flow.rules.integration.strategy.RESTIntegration.integrate","text":"Realiza la integraci\u00f3n utilizando el modelo de salida mapeado. Parameters: Name Type Description Default output_model Optional[pydantic.main.BaseModel] El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. required Returns: Type Description Optional[centraal_client_flow.rules.integration.strategy.StrategyResult] La respuesta defina en response_processor. Exceptions: Type Description HTTPError Si la solicitud HTTP a la API falla. Source code in centraal_client_flow/rules/integration/strategy.py def integrate ( self , output_model : Optional [ BaseModel ]) -> Optional [ StrategyResult ]: \"\"\"Realiza la integraci\u00f3n utilizando el modelo de salida mapeado. Args: output_model: El modelo de datos ya mapeado que se enviar\u00e1 a la integraci\u00f3n. Returns: La respuesta defina en response_processor. Raises: HTTPError: Si la solicitud HTTP a la API falla. \"\"\" token = self . _get_token () headers = { \"Authorization\" : f \"Bearer { token } \" , \"Content-Type\" : \"application/json\" , } url = f \" { self . oauth_config . api_url } / { self . resource } \" if output_model is not None : response = requests . request ( self . method , url , json = output_model . model_dump ( mode = \"json\" , exclude_none = True ), headers = headers , timeout = 300 , ) response . raise_for_status () return self . response_processor ( response , output_model ) self . logger . info ( \"Evento es ignorado.\" ) return StrategyResult ( success = True , response = { \"evento_ignorado\" : True }, bodysent = { \"evento_ignorado\" : True }, )","title":"integrate()"},{"location":"api/#centraal_client_flow.rules.integration.strategy.RESTIntegration.modelo_unificado_mapping","text":"Mapea el mensaje de entrada a un modelo unificado de salida utilizando la funci\u00f3n de mapeo proporcionada. Parameters: Name Type Description Default message EntradaEsquemaUnificado El mensaje de entrada que ser\u00e1 mapeado. required Returns: Type Description Optional[pydantic.main.BaseModel] Un modelo Pydantic que representa la salida mapeada. Exceptions: Type Description TypeError Si el mensaje no es una instancia de EntradaEsquemaUnificado . NotImplementedError Si no se ha proporcionado una funci\u00f3n de mapeo personalizada. Source code in centraal_client_flow/rules/integration/strategy.py def modelo_unificado_mapping ( self , message : EntradaEsquemaUnificado ) -> Optional [ BaseModel ]: \"\"\"Mapea el mensaje de entrada a un modelo unificado de salida utilizando la funci\u00f3n de mapeo proporcionada. Args: message: El mensaje de entrada que ser\u00e1 mapeado. Returns: Un modelo Pydantic que representa la salida mapeada. Raises: TypeError: Si el mensaje no es una instancia de `EntradaEsquemaUnificado`. NotImplementedError: Si no se ha proporcionado una funci\u00f3n de mapeo personalizada. \"\"\" if self . mapping_function : if not isinstance ( message , EntradaEsquemaUnificado ): raise TypeError ( \"El mensaje debe ser una instancia de EntradaEsquemaUnificado\" ) return self . mapping_function ( message ) raise NotImplementedError ( \"No se ha proporcionado una funci\u00f3n de mapeo personalizada.\" )","title":"modelo_unificado_mapping()"},{"location":"api/#centraal_client_flow.rules.integration.strategy.RESTIntegration.set_response_processor","text":"Configura un procesamiento de la respuesta. Source code in centraal_client_flow/rules/integration/strategy.py def set_response_processor ( self , processor : Callable [[ requests . Response , BaseModel ], StrategyResult ] ): \"\"\"Configura un procesamiento de la respuesta.\"\"\" self . response_processor = processor","title":"set_response_processor()"},{"location":"api/#centraal_client_flow.rules.integration.strategy.StrategyResult","text":"Resultado de Estrategia. Source code in centraal_client_flow/rules/integration/strategy.py @dataclass class StrategyResult : \"\"\"Resultado de Estrategia.\"\"\" success : bool response : dict bodysent : dict","title":"StrategyResult"},{"location":"api/#centraal_client_flow.rules.integration.v2","text":"Implementaci\u00f3n de la regla de integraci\u00f3n v2.","title":"v2"},{"location":"api/#centraal_client_flow.rules.integration.v2.IntegrationResult","text":"Resultado de integraci\u00f3n. Source code in centraal_client_flow/rules/integration/v2.py @dataclass class IntegrationResult : \"\"\"Resultado de integraci\u00f3n.\"\"\" success : bool response : dict bodysent : dict def __post_init__ ( self ): \"\"\"Valida que bodysent no sea un diccionario vac\u00edo.\"\"\" if not self . bodysent : raise ValueError ( \"bodysent no puede ser un diccionario vac\u00edo\" ) if not self . response : raise ValueError ( \"response no puede ser un diccionario vac\u00edo\" )","title":"IntegrationResult"},{"location":"api/#centraal_client_flow.rules.integration.v2.IntegrationResult.__post_init__","text":"Valida que bodysent no sea un diccionario vac\u00edo. Source code in centraal_client_flow/rules/integration/v2.py def __post_init__ ( self ): \"\"\"Valida que bodysent no sea un diccionario vac\u00edo.\"\"\" if not self . bodysent : raise ValueError ( \"bodysent no puede ser un diccionario vac\u00edo\" ) if not self . response : raise ValueError ( \"response no puede ser un diccionario vac\u00edo\" )","title":"__post_init__()"},{"location":"api/#centraal_client_flow.rules.integration.v2.IntegrationRule","text":"Implementaci\u00f3n de la regla de integraci\u00f3n v2. Esta implementaci\u00f3n es una regla tiene el objetivo de simplicar la implementaci\u00f3n, se observa que en los casos de uso la estrategias de integraci\u00f3n no son valiosas y dan muy poca flexibilidad. Adicional en general las reglas de integraci\u00f3n son un concpeto mas directo y claro para representar la logica de transformaci\u00f3n del modelo unficaido a lo que necesita el sistema destino, esto ayudara a que el usuario implemente directamente la transformaci\u00f3n y operaciones necesarias sin necesidad de definirla en un objeto diferente. La reglas integraci\u00f3n se implementa como una clase abstracta con metodos compartidos, el usuario solo debera implementar el metodo abstracto integrate , que debe recibir el mensaje del topic, codificarlo mediante el modelo unificado y hacer la implemetaci\u00f3n que requiera (inlcuido mapping o logicas adicionales para realizar la integraci\u00f3n), y el set de body_sent que se enviara a la auditoria de cosmos, par asaber que se envio al sistema destino. con el unico requisito de devolver un IntegrationResult, que indicara el resultado de la transformaci\u00f3n. la clase abstracta tendra la implementaci\u00f3n de metodos concretos: run: se encarga de ejecutar integrate y realizar el logging a la auditoria de cosmos. register_log: se encarga de realizar el logging de la auditoria de cosmos. Source code in centraal_client_flow/rules/integration/v2.py class IntegrationRule ( ABC ): \"\"\"Implementaci\u00f3n de la regla de integraci\u00f3n v2. Esta implementaci\u00f3n es una regla tiene el objetivo de simplicar la implementaci\u00f3n, se observa que en los casos de uso la estrategias de integraci\u00f3n no son valiosas y dan muy poca flexibilidad. Adicional en general las reglas de integraci\u00f3n son un concpeto mas directo y claro para representar la logica de transformaci\u00f3n del modelo unficaido a lo que necesita el sistema destino, esto ayudara a que el usuario implemente directamente la transformaci\u00f3n y operaciones necesarias sin necesidad de definirla en un objeto diferente. La reglas integraci\u00f3n se implementa como una clase abstracta con metodos compartidos, el usuario solo debera implementar el metodo abstracto `integrate`, que debe recibir el mensaje del topic, codificarlo mediante el modelo unificado y hacer la implemetaci\u00f3n que requiera (inlcuido mapping o logicas adicionales para realizar la integraci\u00f3n), y el set de body_sent que se enviara a la auditoria de cosmos, par asaber que se envio al sistema destino. con el unico requisito de devolver un IntegrationResult, que indicara el resultado de la transformaci\u00f3n. la clase abstracta tendra la implementaci\u00f3n de metodos concretos: run: se encarga de ejecutar `integrate` y realizar el logging a la auditoria de cosmos. register_log: se encarga de realizar el logging de la auditoria de cosmos. \"\"\" def __init__ ( self , name : str , model_unficado : type [ EntradaEsquemaUnificado ], logger : logging . Logger , container_name_aud : str , ): \"\"\" Inicializa una regla de integraci\u00f3n. Args: name: Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. model_unficado: Modelo de esquema unificado para validar y mapear los mensajes recibidos. container_name_aud: Nombre del contenedor de la auditoria de cosmos. \"\"\" self . name = name self . model_unficado = model_unficado self . logger = logger self . id_esquema = None self . container_name_aud = container_name_aud self . body_sent = {} @abstractmethod def integrate ( self , entrada_esquema_unificado : EntradaEsquemaUnificado ) -> Optional [ IntegrationResult ]: pass def _validate_modelo_unificado ( self , message : dict ) -> Union [ IntegrationResult , EntradaEsquemaUnificado ]: try : message_esquema = self . model_unficado . model_validate ( message ) self . id_esquema = message_esquema . id return message_esquema except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) response = built_valid_json_str_with_aditional_info ( error_val_cosmos_friendly , f \"Mensaje no cumple con el esquema { self . model_unficado . __name__ } \" , ) self . logger . error ( \"Error en validaci\u00f3n del modelo unificado %s \" , error_val_cosmos_friendly , exc_info = True , ) return IntegrationResult ( success = False , response = response , bodysent = { \"error_validacion\" : True }, ) def run ( self , message : Union [ ServiceBusMessage , dict ], cosmos_client : CosmosDBSingleton , ): \"\"\"Ejecuta la regla de integraci\u00f3n.\"\"\" if isinstance ( message , ServiceBusMessage ): message = json . loads ( message . get_body () . decode ( \"utf-8\" )) message_esquema = self . _validate_modelo_unificado ( message ) if isinstance ( message_esquema , IntegrationResult ): raise ValueError ( f \"Error en validaci\u00f3n del modelo unificado. Se recibe un mensaje no valido { message_esquema } \" ) try : self . id_esquema = message_esquema . id result = self . _retry_with_exponential_backoff ( self . integrate , message_esquema ) if self . body_sent is None : raise ValueError ( \"No se ha definido el body_sent. Integrate debe setear el atributo body_sent.\" ) except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) self . logger . error ( \"Error de validaci\u00f3n en integraci\u00f3n %s \" , error_val_cosmos_friendly , exc_info = True , ) result = IntegrationResult ( success = False , response = { \"error_validacion\" : error_val_cosmos_friendly }, bodysent = { \"error_validacion\" : True }, ) except Exception as e : self . logger . error ( \"Error en integraci\u00f3n %s \" , e , exc_info = True , ) raise e self . register_log ( result , cosmos_client ) return result def register_log ( self , result : IntegrationResult , cosmos_client : CosmosDBSingleton , ): container = cosmos_client . get_container_client ( self . container_name_aud ) if self . id_esquema is not None : entry = AuditoriaEntryIntegracion ( id = self . id_esquema , regla = self . name , contenido = result . bodysent , sucess = result . success , response = result . response , ) item_written = container . upsert_item ( entry . model_dump ( mode = \"json\" , exclude_none = True ), ) return item_written raise ValueError ( \"No es posible usar registro del log.\" ) def _retry_with_exponential_backoff ( self , func , * args , max_retries = 3 , base_delay = 1 , ** kwargs ): \"\"\"Retries a function with exponential backoff.\"\"\" for attempt in range ( max_retries ): try : return func ( * args , ** kwargs ) except Exception as e : if attempt < max_retries - 1 : delay = base_delay * ( 2 ** attempt ) self . logger . warning ( \"Retrying due to error: %s . Attempt %d / %d . Retrying in %d seconds...\" , e , attempt + 1 , max_retries , delay , ) time . sleep ( delay ) else : self . logger . error ( \"Max retries reached. Last error: %s \" , e , exc_info = True ) raise e","title":"IntegrationRule"},{"location":"api/#centraal_client_flow.rules.integration.v2.IntegrationRule.__init__","text":"Inicializa una regla de integraci\u00f3n. Parameters: Name Type Description Default name str Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. required model_unficado type[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] Modelo de esquema unificado para validar y mapear los mensajes recibidos. required container_name_aud str Nombre del contenedor de la auditoria de cosmos. required Source code in centraal_client_flow/rules/integration/v2.py def __init__ ( self , name : str , model_unficado : type [ EntradaEsquemaUnificado ], logger : logging . Logger , container_name_aud : str , ): \"\"\" Inicializa una regla de integraci\u00f3n. Args: name: Nombre del topic de Service Bus que se utilizar\u00e1 para la integraci\u00f3n. model_unficado: Modelo de esquema unificado para validar y mapear los mensajes recibidos. container_name_aud: Nombre del contenedor de la auditoria de cosmos. \"\"\" self . name = name self . model_unficado = model_unficado self . logger = logger self . id_esquema = None self . container_name_aud = container_name_aud self . body_sent = {}","title":"__init__()"},{"location":"api/#centraal_client_flow.rules.integration.v2.IntegrationRule.run","text":"Ejecuta la regla de integraci\u00f3n. Source code in centraal_client_flow/rules/integration/v2.py def run ( self , message : Union [ ServiceBusMessage , dict ], cosmos_client : CosmosDBSingleton , ): \"\"\"Ejecuta la regla de integraci\u00f3n.\"\"\" if isinstance ( message , ServiceBusMessage ): message = json . loads ( message . get_body () . decode ( \"utf-8\" )) message_esquema = self . _validate_modelo_unificado ( message ) if isinstance ( message_esquema , IntegrationResult ): raise ValueError ( f \"Error en validaci\u00f3n del modelo unificado. Se recibe un mensaje no valido { message_esquema } \" ) try : self . id_esquema = message_esquema . id result = self . _retry_with_exponential_backoff ( self . integrate , message_esquema ) if self . body_sent is None : raise ValueError ( \"No se ha definido el body_sent. Integrate debe setear el atributo body_sent.\" ) except ValidationError as e : error_val_cosmos_friendly = serialize_validation_errors ( e . errors ()) self . logger . error ( \"Error de validaci\u00f3n en integraci\u00f3n %s \" , error_val_cosmos_friendly , exc_info = True , ) result = IntegrationResult ( success = False , response = { \"error_validacion\" : error_val_cosmos_friendly }, bodysent = { \"error_validacion\" : True }, ) except Exception as e : self . logger . error ( \"Error en integraci\u00f3n %s \" , e , exc_info = True , ) raise e self . register_log ( result , cosmos_client ) return result","title":"run()"},{"location":"api/#centraal_client_flow.rules.update","text":"M\u00f3dulo para las reglas de actualizaci\u00f3n.","title":"update"},{"location":"api/#centraal_client_flow.rules.update.Rule","text":"Representa una regla de procesamiento que asocia un modelo Pydantic con un procesador y los t\u00f3picos relevantes. Attributes: Name Type Description model Type[centraal_client_flow.models.schemas.EventoBase] El tipo de modelo Pydantic que la regla procesa. processor UpdateProcessor El procesador que manejar\u00e1 la l\u00f3gica de actualizaci\u00f3n. topics Set[str] Los t\u00f3picos a los que la regla est\u00e1 asociada. name str El nombre asignado a la regla basado en el nombre de la clase del modelo. Source code in centraal_client_flow/rules/update.py @dataclass class Rule : \"\"\" Representa una regla de procesamiento que asocia un modelo Pydantic con un procesador y los t\u00f3picos relevantes. Attributes: model: El tipo de modelo Pydantic que la regla procesa. processor: El procesador que manejar\u00e1 la l\u00f3gica de actualizaci\u00f3n. topics: Los t\u00f3picos a los que la regla est\u00e1 asociada. name: El nombre asignado a la regla basado en el nombre de la clase del modelo. \"\"\" model : Type [ EventoBase ] processor : UpdateProcessor topics : Set [ str ] name : str = \"\" def __post_init__ ( self ): \"\"\"Inicializa el nombre de la regla basado en el nombre de la clase del modelo.\"\"\" self . name = self . model . __name__ def process_rule ( self , data : EventoBase , current : Optional [ EntradaEsquemaUnificado ] ) -> EntradaEsquemaUnificado : \"\"\" Procesa una entrada de datos usando la regla definida. Parameters: data: El evento que se procesar\u00e1. current: El registro actual a ser actualizado. Returns: EntradaEsquemaUnificado: El registro actualizado. \"\"\" data_copy = data . model_copy ( deep = True ) current_copy = current . model_copy ( deep = True ) if current else None result = self . processor . process_message ( data_copy , current_copy ) return result","title":"Rule"},{"location":"api/#centraal_client_flow.rules.update.Rule.__post_init__","text":"Inicializa el nombre de la regla basado en el nombre de la clase del modelo. Source code in centraal_client_flow/rules/update.py def __post_init__ ( self ): \"\"\"Inicializa el nombre de la regla basado en el nombre de la clase del modelo.\"\"\" self . name = self . model . __name__","title":"__post_init__()"},{"location":"api/#centraal_client_flow.rules.update.Rule.process_rule","text":"Procesa una entrada de datos usando la regla definida. Parameters: Name Type Description Default data EventoBase El evento que se procesar\u00e1. required current Optional[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] El registro actual a ser actualizado. required Returns: Type Description EntradaEsquemaUnificado El registro actualizado. Source code in centraal_client_flow/rules/update.py def process_rule ( self , data : EventoBase , current : Optional [ EntradaEsquemaUnificado ] ) -> EntradaEsquemaUnificado : \"\"\" Procesa una entrada de datos usando la regla definida. Parameters: data: El evento que se procesar\u00e1. current: El registro actual a ser actualizado. Returns: EntradaEsquemaUnificado: El registro actualizado. \"\"\" data_copy = data . model_copy ( deep = True ) current_copy = current . model_copy ( deep = True ) if current else None result = self . processor . process_message ( data_copy , current_copy ) return result","title":"process_rule()"},{"location":"api/#centraal_client_flow.rules.update.RuleProcessor","text":"Clase que orquesta el procesamiento de reglas y la interacci\u00f3n con Service Bus y Cosmos DB. Source code in centraal_client_flow/rules/update.py class RuleProcessor : \"\"\"Clase que orquesta el procesamiento de reglas y la interacci\u00f3n con Service Bus y Cosmos DB.\"\"\" def __init__ ( self , queue_name : str , unified_container_name : str , auditoria_container_name : str , service_bus_client : IServiceBusClient , cosmos_client : CosmosDBSingleton , rule_selector : RuleSelector , ): self . queue_name = queue_name self . unified_container_name = unified_container_name self . auditoria_container_name = auditoria_container_name self . service_bus_client = service_bus_client self . cosmos_client = cosmos_client self . rule_selector = rule_selector def save_unified_model ( self , new_data : EntradaEsquemaUnificado , ) -> dict : \"\"\" Guarda el modelo de EntradaEsquemaUnificado actualizado en Cosmos DB. Parameters: new_data: El modelo actualizado de EntradaEsquemaUnificado. Returns: EntradaEsquemaUnificado: El modelo almacenado en la base de datos. \"\"\" container = self . cosmos_client . get_container_client ( self . unified_container_name ) item_written = container . upsert_item ( new_data . model_dump ( mode = \"json\" , exclude_none = True ) ) return item_written def record_auditoria ( self , changes : List [ AuditoriaEntry ]): \"\"\" Registra los cambios detectados en el contenedor de auditor\u00eda de Cosmos DB. Parameters: changes: Lista de entradas de auditor\u00eda que contienen los cambios detectados. \"\"\" container = self . cosmos_client . get_container_client ( self . auditoria_container_name ) for change in changes : container . create_item ( change . model_dump ( mode = \"json\" , exclude_none = True ), enable_automatic_id_generation = True , ) def get_current_entrada ( self , id_entrada : IDModel , model_unificado : EntradaEsquemaUnificado ) -> Optional [ EntradaEsquemaUnificado ]: \"\"\" Recupera el registro actual desde Cosmos DB basado en el ID proporcionado. Parameters: id_entrada: El ID del registro que se desea recuperar. Returns: Optional[EntradaEsquemaUnificado]: El registro actual, si existe. \"\"\" container = self . cosmos_client . get_container_client ( self . unified_container_name ) query = f \"SELECT * FROM c WHERE c.id = ' { id_entrada . model_dump () } '\" current_items = list ( container . query_items ( query , enable_cross_partition_query = True ) ) if current_items : return model_unificado . model_validate ( current_items [ 0 ]) return None def detect_changes ( self , current_data : Optional [ EntradaEsquemaUnificado ], updated_data : EntradaEsquemaUnificado , id_model : IDModel , regla_name : str , ) -> List [ AuditoriaEntry ]: \"\"\" Detecta cambios entre los datos actuales y los actualizados en el modelo EntradaEsquemaUnificado. Parameters: current_data: Los datos actuales en la base de datos. updated_data: Los datos actualizados a comparar. id_model: El ID del modelo que se est\u00e1 procesando. Returns: List[AuditoriaEntry]: Lista de entradas de auditor\u00eda que reflejan los cambios detectados. \"\"\" changes = [] def _log_changes ( subesquema_name : str , old_value : Any , new_value : Any , field_name : str ): \"\"\"Funci\u00f3n auxiliar para registrar cambios detectados.\"\"\" changes . append ( AuditoriaEntry ( id_entrada = id_model , subesquema = subesquema_name , campo = field_name , new_value = new_value , old_value = old_value , regla = regla_name , ) ) if current_data is None : # No hay datos actuales, se registran todos los campos como cambios for field_name in updated_data . model_fields_set : new_value = getattr ( updated_data , field_name ) if isinstance ( new_value , BaseModel ) and not ( isinstance ( new_value , IDModel ) ): # Es un modelo Pydantic anidado (subesquema) for sub_field_name in new_value . model_fields_set : sub_field_value = getattr ( new_value , sub_field_name ) _log_changes ( field_name , None , sub_field_value , sub_field_name ) else : # Si es principal es \"root\" _log_changes ( \"root\" , None , new_value , field_name ) else : for field_name in updated_data . model_fields_set : old_value = getattr ( current_data , field_name ) new_value = getattr ( updated_data , field_name ) if isinstance ( new_value , BaseModel ): # Es un modelo Pydantic anidado (subesquema) for sub_field_name in new_value . model_fields_set : sub_old_value = ( getattr ( old_value , sub_field_name , None ) if old_value else None ) sub_new_value = getattr ( new_value , sub_field_name , None ) if sub_old_value != sub_new_value : _log_changes ( field_name , sub_old_value , sub_new_value , sub_field_name ) else : if old_value != new_value : _log_changes ( \"root\" , old_value , new_value , field_name ) if not changes : changes . append ( AuditoriaEntry ( id_entrada = id_model , subesquema = \"No Changes\" , campo = \"Ninguno\" , new_value = \"No cambios\" , old_value = \"No cambios\" , regla = regla_name , ) ) return changes def publish_to_topics ( self , processed_data : EntradaEsquemaUnificado , topic_names : List [ str ], ): \"\"\" Publica los datos procesados a los t\u00f3picos de Service Bus relevantes. Parameters: processed_data: Los datos procesados que se enviar\u00e1n. topic_names: Lista de t\u00f3picos a los que se enviar\u00e1n los datos. \"\"\" client = self . service_bus_client . client for topic_name in topic_names : body = processed_data . model_dump ( mode = \"json\" , exclude_none = True ) with client . get_topic_sender ( topic_name = topic_name ) as sender : message = SBMessage ( body = json . dumps ( body )) sender . send_messages ( message )","title":"RuleProcessor"},{"location":"api/#centraal_client_flow.rules.update.RuleProcessor.detect_changes","text":"Detecta cambios entre los datos actuales y los actualizados en el modelo EntradaEsquemaUnificado. Parameters: Name Type Description Default current_data Optional[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] Los datos actuales en la base de datos. required updated_data EntradaEsquemaUnificado Los datos actualizados a comparar. required id_model IDModel El ID del modelo que se est\u00e1 procesando. required Returns: Type Description List[AuditoriaEntry] Lista de entradas de auditor\u00eda que reflejan los cambios detectados. Source code in centraal_client_flow/rules/update.py def detect_changes ( self , current_data : Optional [ EntradaEsquemaUnificado ], updated_data : EntradaEsquemaUnificado , id_model : IDModel , regla_name : str , ) -> List [ AuditoriaEntry ]: \"\"\" Detecta cambios entre los datos actuales y los actualizados en el modelo EntradaEsquemaUnificado. Parameters: current_data: Los datos actuales en la base de datos. updated_data: Los datos actualizados a comparar. id_model: El ID del modelo que se est\u00e1 procesando. Returns: List[AuditoriaEntry]: Lista de entradas de auditor\u00eda que reflejan los cambios detectados. \"\"\" changes = [] def _log_changes ( subesquema_name : str , old_value : Any , new_value : Any , field_name : str ): \"\"\"Funci\u00f3n auxiliar para registrar cambios detectados.\"\"\" changes . append ( AuditoriaEntry ( id_entrada = id_model , subesquema = subesquema_name , campo = field_name , new_value = new_value , old_value = old_value , regla = regla_name , ) ) if current_data is None : # No hay datos actuales, se registran todos los campos como cambios for field_name in updated_data . model_fields_set : new_value = getattr ( updated_data , field_name ) if isinstance ( new_value , BaseModel ) and not ( isinstance ( new_value , IDModel ) ): # Es un modelo Pydantic anidado (subesquema) for sub_field_name in new_value . model_fields_set : sub_field_value = getattr ( new_value , sub_field_name ) _log_changes ( field_name , None , sub_field_value , sub_field_name ) else : # Si es principal es \"root\" _log_changes ( \"root\" , None , new_value , field_name ) else : for field_name in updated_data . model_fields_set : old_value = getattr ( current_data , field_name ) new_value = getattr ( updated_data , field_name ) if isinstance ( new_value , BaseModel ): # Es un modelo Pydantic anidado (subesquema) for sub_field_name in new_value . model_fields_set : sub_old_value = ( getattr ( old_value , sub_field_name , None ) if old_value else None ) sub_new_value = getattr ( new_value , sub_field_name , None ) if sub_old_value != sub_new_value : _log_changes ( field_name , sub_old_value , sub_new_value , sub_field_name ) else : if old_value != new_value : _log_changes ( \"root\" , old_value , new_value , field_name ) if not changes : changes . append ( AuditoriaEntry ( id_entrada = id_model , subesquema = \"No Changes\" , campo = \"Ninguno\" , new_value = \"No cambios\" , old_value = \"No cambios\" , regla = regla_name , ) ) return changes","title":"detect_changes()"},{"location":"api/#centraal_client_flow.rules.update.RuleProcessor.get_current_entrada","text":"Recupera el registro actual desde Cosmos DB basado en el ID proporcionado. Parameters: Name Type Description Default id_entrada IDModel El ID del registro que se desea recuperar. required Returns: Type Description Optional[EntradaEsquemaUnificado] El registro actual, si existe. Source code in centraal_client_flow/rules/update.py def get_current_entrada ( self , id_entrada : IDModel , model_unificado : EntradaEsquemaUnificado ) -> Optional [ EntradaEsquemaUnificado ]: \"\"\" Recupera el registro actual desde Cosmos DB basado en el ID proporcionado. Parameters: id_entrada: El ID del registro que se desea recuperar. Returns: Optional[EntradaEsquemaUnificado]: El registro actual, si existe. \"\"\" container = self . cosmos_client . get_container_client ( self . unified_container_name ) query = f \"SELECT * FROM c WHERE c.id = ' { id_entrada . model_dump () } '\" current_items = list ( container . query_items ( query , enable_cross_partition_query = True ) ) if current_items : return model_unificado . model_validate ( current_items [ 0 ]) return None","title":"get_current_entrada()"},{"location":"api/#centraal_client_flow.rules.update.RuleProcessor.publish_to_topics","text":"Publica los datos procesados a los t\u00f3picos de Service Bus relevantes. Parameters: Name Type Description Default processed_data EntradaEsquemaUnificado Los datos procesados que se enviar\u00e1n. required topic_names List[str] Lista de t\u00f3picos a los que se enviar\u00e1n los datos. required Source code in centraal_client_flow/rules/update.py def publish_to_topics ( self , processed_data : EntradaEsquemaUnificado , topic_names : List [ str ], ): \"\"\" Publica los datos procesados a los t\u00f3picos de Service Bus relevantes. Parameters: processed_data: Los datos procesados que se enviar\u00e1n. topic_names: Lista de t\u00f3picos a los que se enviar\u00e1n los datos. \"\"\" client = self . service_bus_client . client for topic_name in topic_names : body = processed_data . model_dump ( mode = \"json\" , exclude_none = True ) with client . get_topic_sender ( topic_name = topic_name ) as sender : message = SBMessage ( body = json . dumps ( body )) sender . send_messages ( message )","title":"publish_to_topics()"},{"location":"api/#centraal_client_flow.rules.update.RuleProcessor.record_auditoria","text":"Registra los cambios detectados en el contenedor de auditor\u00eda de Cosmos DB. Parameters: Name Type Description Default changes List[centraal_client_flow.models.schemas.AuditoriaEntry] Lista de entradas de auditor\u00eda que contienen los cambios detectados. required Source code in centraal_client_flow/rules/update.py def record_auditoria ( self , changes : List [ AuditoriaEntry ]): \"\"\" Registra los cambios detectados en el contenedor de auditor\u00eda de Cosmos DB. Parameters: changes: Lista de entradas de auditor\u00eda que contienen los cambios detectados. \"\"\" container = self . cosmos_client . get_container_client ( self . auditoria_container_name ) for change in changes : container . create_item ( change . model_dump ( mode = \"json\" , exclude_none = True ), enable_automatic_id_generation = True , )","title":"record_auditoria()"},{"location":"api/#centraal_client_flow.rules.update.RuleProcessor.save_unified_model","text":"Guarda el modelo de EntradaEsquemaUnificado actualizado en Cosmos DB. Parameters: Name Type Description Default new_data EntradaEsquemaUnificado El modelo actualizado de EntradaEsquemaUnificado. required Returns: Type Description EntradaEsquemaUnificado El modelo almacenado en la base de datos. Source code in centraal_client_flow/rules/update.py def save_unified_model ( self , new_data : EntradaEsquemaUnificado , ) -> dict : \"\"\" Guarda el modelo de EntradaEsquemaUnificado actualizado en Cosmos DB. Parameters: new_data: El modelo actualizado de EntradaEsquemaUnificado. Returns: EntradaEsquemaUnificado: El modelo almacenado en la base de datos. \"\"\" container = self . cosmos_client . get_container_client ( self . unified_container_name ) item_written = container . upsert_item ( new_data . model_dump ( mode = \"json\" , exclude_none = True ) ) return item_written","title":"save_unified_model()"},{"location":"api/#centraal_client_flow.rules.update.RuleSelector","text":"Clase encargada de seleccionar y aplicar reglas de procesamiento sobre los eventos. Source code in centraal_client_flow/rules/update.py class RuleSelector : \"\"\"Clase encargada de seleccionar y aplicar reglas de procesamiento sobre los eventos.\"\"\" def __init__ ( self , modelo_unificado : EntradaEsquemaUnificado ): self . rules : List [ Rule ] = [] self . modelo_unificado = modelo_unificado def register_rule ( self , rule : Rule ): \"\"\" Registra una nueva regla para su uso futuro en el procesamiento de eventos. Parameters: rule: La regla que se va a registrar. \"\"\" self . _validate_rule ( rule ) self . rules . append ( rule ) def _validate_rule ( self , rule : Rule ): \"\"\" Valida que los t\u00f3picos de la regla coincidan con los subesquemas en el modelo unificado. Parameters: rule: La regla a validar. Raises: ValueError: Si alg\u00fan t\u00f3pico de la regla no corresponde a un subesquema v\u00e1lido. \"\"\" model_fields = set ( self . modelo_unificado . model_fields ) for t in rule . topics : if t == \"root\" : pass elif t not in model_fields : raise ValueError ( f \"El t\u00f3pico { t } debe corresponder a un subesquema { model_fields } \" ) def select_rule ( self , data : dict ) -> Tuple [ EventoBase , Rule ]: \"\"\" Selecciona la regla adecuada para los datos proporcionados. Parameters: data: Un diccionario con los datos a validar y procesar. Returns: Tuple[EventoBase, Rule]: Los datos validados y la regla seleccionada. Raises: NoHayReglas: Si no se encuentra una regla v\u00e1lida para los datos proporcionados. \"\"\" for rule in self . rules : try : validated_data = rule . model . model_validate ( data ) return validated_data , rule except ValidationError : continue raise NoHayReglas ( f \"No se encontr\u00f3 una regla v\u00e1lida para { data } .\" ) def get_topics_by_changes ( self , rule_topics : Set [ str ], changes : List [ AuditoriaEntry ], include_root : bool = False , ) -> List [ str ]: \"\"\" Selecciona los t\u00f3picos relevantes basados en los cambios detectados. Parameters: rule_topics: Conjunto de t\u00f3picos definidos en la regla. changes: Lista de entradas de auditor\u00eda con los cambios detectados. Returns: List[str]: Lista de t\u00f3picos que necesitan ser notificados. \"\"\" topics_to_notify = set () for change in changes : if change . subesquema in rule_topics : if include_root : topics_to_notify . add ( change . subesquema ) elif change . subesquema != \"root\" : topics_to_notify . add ( change . subesquema ) return list ( topics_to_notify )","title":"RuleSelector"},{"location":"api/#centraal_client_flow.rules.update.RuleSelector.get_topics_by_changes","text":"Selecciona los t\u00f3picos relevantes basados en los cambios detectados. Parameters: Name Type Description Default rule_topics Set[str] Conjunto de t\u00f3picos definidos en la regla. required changes List[centraal_client_flow.models.schemas.AuditoriaEntry] Lista de entradas de auditor\u00eda con los cambios detectados. required Returns: Type Description List[str] Lista de t\u00f3picos que necesitan ser notificados. Source code in centraal_client_flow/rules/update.py def get_topics_by_changes ( self , rule_topics : Set [ str ], changes : List [ AuditoriaEntry ], include_root : bool = False , ) -> List [ str ]: \"\"\" Selecciona los t\u00f3picos relevantes basados en los cambios detectados. Parameters: rule_topics: Conjunto de t\u00f3picos definidos en la regla. changes: Lista de entradas de auditor\u00eda con los cambios detectados. Returns: List[str]: Lista de t\u00f3picos que necesitan ser notificados. \"\"\" topics_to_notify = set () for change in changes : if change . subesquema in rule_topics : if include_root : topics_to_notify . add ( change . subesquema ) elif change . subesquema != \"root\" : topics_to_notify . add ( change . subesquema ) return list ( topics_to_notify )","title":"get_topics_by_changes()"},{"location":"api/#centraal_client_flow.rules.update.RuleSelector.register_rule","text":"Registra una nueva regla para su uso futuro en el procesamiento de eventos. Parameters: Name Type Description Default rule Rule La regla que se va a registrar. required Source code in centraal_client_flow/rules/update.py def register_rule ( self , rule : Rule ): \"\"\" Registra una nueva regla para su uso futuro en el procesamiento de eventos. Parameters: rule: La regla que se va a registrar. \"\"\" self . _validate_rule ( rule ) self . rules . append ( rule )","title":"register_rule()"},{"location":"api/#centraal_client_flow.rules.update.RuleSelector.select_rule","text":"Selecciona la regla adecuada para los datos proporcionados. Parameters: Name Type Description Default data dict Un diccionario con los datos a validar y procesar. required Returns: Type Description Tuple[EventoBase, Rule] Los datos validados y la regla seleccionada. Exceptions: Type Description NoHayReglas Si no se encuentra una regla v\u00e1lida para los datos proporcionados. Source code in centraal_client_flow/rules/update.py def select_rule ( self , data : dict ) -> Tuple [ EventoBase , Rule ]: \"\"\" Selecciona la regla adecuada para los datos proporcionados. Parameters: data: Un diccionario con los datos a validar y procesar. Returns: Tuple[EventoBase, Rule]: Los datos validados y la regla seleccionada. Raises: NoHayReglas: Si no se encuentra una regla v\u00e1lida para los datos proporcionados. \"\"\" for rule in self . rules : try : validated_data = rule . model . model_validate ( data ) return validated_data , rule except ValidationError : continue raise NoHayReglas ( f \"No se encontr\u00f3 una regla v\u00e1lida para { data } .\" )","title":"select_rule()"},{"location":"api/#centraal_client_flow.rules.update.UpdateProcessor","text":"Clase base abstracta para procesadores de eventos. Source code in centraal_client_flow/rules/update.py class UpdateProcessor ( LoggerMixin , ABC ): \"\"\"Clase base abstracta para procesadores de eventos.\"\"\" @abstractmethod def process_message ( self , event : EventoBase , current_registro : Optional [ EntradaEsquemaUnificado ] ) -> EntradaEsquemaUnificado : \"\"\" Procesa el evento recibido y retorna un modelo actualizado de EntradaEsquemaUnificado. Parameters: event: El evento que contiene la informaci\u00f3n del cambio, basado en un modelo Pydantic. current_registro: El registro actual que ser\u00e1 actualizado. Returns: EntradaEsquemaUnificado: El registro actualizado despu\u00e9s de aplicar el evento. \"\"\"","title":"UpdateProcessor"},{"location":"api/#centraal_client_flow.rules.update.UpdateProcessor.process_message","text":"Procesa el evento recibido y retorna un modelo actualizado de EntradaEsquemaUnificado. Parameters: Name Type Description Default event EventoBase El evento que contiene la informaci\u00f3n del cambio, basado en un modelo Pydantic. required current_registro Optional[centraal_client_flow.models.schemas.EntradaEsquemaUnificado] El registro actual que ser\u00e1 actualizado. required Returns: Type Description EntradaEsquemaUnificado El registro actualizado despu\u00e9s de aplicar el evento. Source code in centraal_client_flow/rules/update.py @abstractmethod def process_message ( self , event : EventoBase , current_registro : Optional [ EntradaEsquemaUnificado ] ) -> EntradaEsquemaUnificado : \"\"\" Procesa el evento recibido y retorna un modelo actualizado de EntradaEsquemaUnificado. Parameters: event: El evento que contiene la informaci\u00f3n del cambio, basado en un modelo Pydantic. current_registro: El registro actual que ser\u00e1 actualizado. Returns: EntradaEsquemaUnificado: El registro actualizado despu\u00e9s de aplicar el evento. \"\"\"","title":"process_message()"},{"location":"authors/","text":"Credits \u00b6 Development Lead \u00b6 German equipo@centraal.studio Contributors \u00b6 None yet. Why not be the first?","title":"authors"},{"location":"authors/#credits","text":"","title":"Credits"},{"location":"authors/#development-lead","text":"German equipo@centraal.studio","title":"Development Lead"},{"location":"authors/#contributors","text":"None yet. Why not be the first?","title":"Contributors"},{"location":"contributing/","text":"Contributing \u00b6 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions \u00b6 Report Bugs \u00b6 Report bugs at https://github.com/centraal-api/centraal_client_flow/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs \u00b6 Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it. Implement Features \u00b6 Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation \u00b6 centraal-client-flow could always use more documentation, whether as part of the official centraal-client-flow docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback \u00b6 The best way to send feedback is to file an issue at https://github.com/centraal-api/centraal_client_flow/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! \u00b6 Ready to contribute? Here's how to set up centraal_client_flow for local development. Fork the centraal_client_flow repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/centraal_client_flow.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines \u00b6 Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.9, 3.10, 3.11 and for PyPy. Check https://github.com/centraal-api/centraal_client_flow/actions and make sure that the tests pass for all supported Python versions. Tips``` \u00b6 1 $ pytest tests.test_centraal_client_flow ```To run a subset of tests. Deploying \u00b6 A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in HISTORY.md). Then run: 1 2 3 4 5 6 $ poetry version patch # possible: major / minor / patch $ git commit $ git push $ git tag v.{version} $ git push $ git push --tags Github Actions will then deploy to PyPI if tests pass. Configuraciones para desarroladores \u00b6 en dev.yml - remover python 3.8. - ajustar la publicaci\u00f3n 1 2 3 4 5 - name : publish to Test PyPI uses : pypa/gh-action-pypi-publish@release/v1 with : repository-url : https://test.pypi.org/legacy/ skip-existing : true - remover todo lo relacionado con la notificaci\u00f3n en release.yml - remover el trigger en main - ajustar las versiones python-versions: ['3.9', '3.10', '3.11'] - ajustar la publicacion a pypi 1 2 3 4 - name : publish to PYPI uses : pypa/gh-action-pypi-publish@release/v1 with : skip-existing : true remover todo lo relacionado con la notificaci\u00f3n pyrightconfig.json - version python 3.11","title":"contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing"},{"location":"contributing/#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"contributing/#report-bugs","text":"Report bugs at https://github.com/centraal-api/centraal_client_flow/issues. If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"contributing/#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.","title":"Fix Bugs"},{"location":"contributing/#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"contributing/#write-documentation","text":"centraal-client-flow could always use more documentation, whether as part of the official centraal-client-flow docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"contributing/#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/centraal-api/centraal_client_flow/issues. If you are proposing a feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"contributing/#get-started","text":"Ready to contribute? Here's how to set up centraal_client_flow for local development. Fork the centraal_client_flow repo on GitHub. Clone your fork locally 1 $ git clone git@github.com:your_name_here/centraal_client_flow.git Ensure poetry is installed. Install dependencies and start your virtualenv: 1 $ poetry install -E test -E doc -E dev Create a branch for local development: 1 $ git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. When you're done making changes, check that your changes pass the tests, including testing other Python versions, with tox: 1 $ tox Commit your changes and push your branch to GitHub: 1 2 3 $ git add . $ git commit -m \"Your detailed description of your changes.\" $ git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"contributing/#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md. The pull request should work for Python 3.9, 3.10, 3.11 and for PyPy. Check https://github.com/centraal-api/centraal_client_flow/actions and make sure that the tests pass for all supported Python versions.","title":"Pull Request Guidelines"},{"location":"contributing/#tips","text":"1 $ pytest tests.test_centraal_client_flow ```To run a subset of tests.","title":"Tips```"},{"location":"contributing/#deploying","text":"A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in HISTORY.md). Then run: 1 2 3 4 5 6 $ poetry version patch # possible: major / minor / patch $ git commit $ git push $ git tag v.{version} $ git push $ git push --tags Github Actions will then deploy to PyPI if tests pass.","title":"Deploying"},{"location":"contributing/#configuraciones-para-desarroladores","text":"en dev.yml - remover python 3.8. - ajustar la publicaci\u00f3n 1 2 3 4 5 - name : publish to Test PyPI uses : pypa/gh-action-pypi-publish@release/v1 with : repository-url : https://test.pypi.org/legacy/ skip-existing : true - remover todo lo relacionado con la notificaci\u00f3n en release.yml - remover el trigger en main - ajustar las versiones python-versions: ['3.9', '3.10', '3.11'] - ajustar la publicacion a pypi 1 2 3 4 - name : publish to PYPI uses : pypa/gh-action-pypi-publish@release/v1 with : skip-existing : true remover todo lo relacionado con la notificaci\u00f3n pyrightconfig.json - version python 3.11","title":"Configuraciones para desarroladores"},{"location":"history/","text":"History \u00b6 0.1.17 (2025-06-15) \u00b6 Added \u00b6 Tests unitarios para la clase Rule Archivo: tests/rules/test_update.py Cobertura completa de funcionalidad de Rule Tests para inicializaci\u00f3n, procesamiento y manejo de casos edge Fixed \u00b6 M\u00e9todo Rule.process_rule() Manejo correcto cuando current_registro es None Creaci\u00f3n apropiada de copias profundas de los datos 0.1.16 (2025-05-19) \u00b6 Fixed \u00b6 ServiceBusClientSingleton : configurar nivel de logging. 0.1.15 (2025-05-19) \u00b6 Fixed \u00b6 ServiceBusClientSingleton : Mejoras para eviatar errores. 0.1.14 (2024-12-14) \u00b6 Fixed \u00b6 serialize_validation_errors : Fix the serialization problem of exceptions. 0.1.13 (2024-12-05) \u00b6 Fixed \u00b6 IntegrationRule : Fixed message decoding for ServiceBusMessage handling. Added \u00b6 EventProcessor : Added helper functions for Pydantic validation error serialization. IntegrationRule : Enhanced error handling and logging capabilities. IntegrationRuleV2 : Created new version with simplified integration logic. 0.1.12 (2024-10-24) \u00b6 Added \u00b6 ServiceBusClientSingleton : Optimized to reuse existing senders instead of creating new ones. 0.1.11 (2024-09-16) \u00b6 Fixed \u00b6 RESTIntegration : Added support for non-integer values. 0.1.10 (2024-09-16) \u00b6 Fixed \u00b6 RESTIntegration : Improved token renewal handling. 0.1.9 (2024-09-12) \u00b6 Fixed \u00b6 AuditoriaEntryIntegracion : Preserved ID for tracing at ID and rule level. 0.1.8 (2024-09-12) \u00b6 Fixed \u00b6 IntegrationRule : Returns unsuccessful result when validation error occurs. 0.1.7 (2024-09-12) \u00b6 Added \u00b6 RESTIntegration : Added new integration result object for integration auditing. 0.1.6 (2024-09-10) \u00b6 Added \u00b6 RESTIntegration : Added capability to ignore events. 0.1.5 (2024-09-03) \u00b6 Added \u00b6 IntegrationRule : Added method to execute integration rule. 0.1.4 (2024-09-03) \u00b6 Fixed \u00b6 RESTIntegration : Added support for processing with provided model. 0.1.3 (2024-09-02) \u00b6 Fixed \u00b6 Improved JSON string handling when sending to topics. 0.1.2 (2024-09-02) \u00b6 Fixed \u00b6 Prevented unnecessary JSON string conversion when informing topics. 0.1.0 (2024-08-13) \u00b6 First release on PyPI.","title":"history"},{"location":"history/#history","text":"","title":"History"},{"location":"history/#0117-2025-06-15","text":"","title":"0.1.17 (2025-06-15)"},{"location":"history/#added","text":"Tests unitarios para la clase Rule Archivo: tests/rules/test_update.py Cobertura completa de funcionalidad de Rule Tests para inicializaci\u00f3n, procesamiento y manejo de casos edge","title":"Added"},{"location":"history/#fixed","text":"M\u00e9todo Rule.process_rule() Manejo correcto cuando current_registro es None Creaci\u00f3n apropiada de copias profundas de los datos","title":"Fixed"},{"location":"history/#0116-2025-05-19","text":"","title":"0.1.16 (2025-05-19)"},{"location":"history/#fixed_1","text":"ServiceBusClientSingleton : configurar nivel de logging.","title":"Fixed"},{"location":"history/#0115-2025-05-19","text":"","title":"0.1.15 (2025-05-19)"},{"location":"history/#fixed_2","text":"ServiceBusClientSingleton : Mejoras para eviatar errores.","title":"Fixed"},{"location":"history/#0114-2024-12-14","text":"","title":"0.1.14 (2024-12-14)"},{"location":"history/#fixed_3","text":"serialize_validation_errors : Fix the serialization problem of exceptions.","title":"Fixed"},{"location":"history/#0113-2024-12-05","text":"","title":"0.1.13 (2024-12-05)"},{"location":"history/#fixed_4","text":"IntegrationRule : Fixed message decoding for ServiceBusMessage handling.","title":"Fixed"},{"location":"history/#added_1","text":"EventProcessor : Added helper functions for Pydantic validation error serialization. IntegrationRule : Enhanced error handling and logging capabilities. IntegrationRuleV2 : Created new version with simplified integration logic.","title":"Added"},{"location":"history/#0112-2024-10-24","text":"","title":"0.1.12 (2024-10-24)"},{"location":"history/#added_2","text":"ServiceBusClientSingleton : Optimized to reuse existing senders instead of creating new ones.","title":"Added"},{"location":"history/#0111-2024-09-16","text":"","title":"0.1.11 (2024-09-16)"},{"location":"history/#fixed_5","text":"RESTIntegration : Added support for non-integer values.","title":"Fixed"},{"location":"history/#0110-2024-09-16","text":"","title":"0.1.10 (2024-09-16)"},{"location":"history/#fixed_6","text":"RESTIntegration : Improved token renewal handling.","title":"Fixed"},{"location":"history/#019-2024-09-12","text":"","title":"0.1.9 (2024-09-12)"},{"location":"history/#fixed_7","text":"AuditoriaEntryIntegracion : Preserved ID for tracing at ID and rule level.","title":"Fixed"},{"location":"history/#018-2024-09-12","text":"","title":"0.1.8 (2024-09-12)"},{"location":"history/#fixed_8","text":"IntegrationRule : Returns unsuccessful result when validation error occurs.","title":"Fixed"},{"location":"history/#017-2024-09-12","text":"","title":"0.1.7 (2024-09-12)"},{"location":"history/#added_3","text":"RESTIntegration : Added new integration result object for integration auditing.","title":"Added"},{"location":"history/#016-2024-09-10","text":"","title":"0.1.6 (2024-09-10)"},{"location":"history/#added_4","text":"RESTIntegration : Added capability to ignore events.","title":"Added"},{"location":"history/#015-2024-09-03","text":"","title":"0.1.5 (2024-09-03)"},{"location":"history/#added_5","text":"IntegrationRule : Added method to execute integration rule.","title":"Added"},{"location":"history/#014-2024-09-03","text":"","title":"0.1.4 (2024-09-03)"},{"location":"history/#fixed_9","text":"RESTIntegration : Added support for processing with provided model.","title":"Fixed"},{"location":"history/#013-2024-09-02","text":"","title":"0.1.3 (2024-09-02)"},{"location":"history/#fixed_10","text":"Improved JSON string handling when sending to topics.","title":"Fixed"},{"location":"history/#012-2024-09-02","text":"","title":"0.1.2 (2024-09-02)"},{"location":"history/#fixed_11","text":"Prevented unnecessary JSON string conversion when informing topics.","title":"Fixed"},{"location":"history/#010-2024-08-13","text":"First release on PyPI.","title":"0.1.0 (2024-08-13)"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install centraal-client-flow, run this command in your terminal: 1 pip install centraal_client_flow This is the preferred method to install centraal-client-flow, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for centraal-client-flow can be downloaded from the Github repo . You can either clone the public repository: 1 git clone git://github.com/centraal-api/centraal_client_flow Or download the tarball : 1 curl -OJL https://github.com/centraal-api/centraal_client_flow/tarball/master Once you have a copy of the source, you can install it with: 1 pip install .","title":"installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install centraal-client-flow, run this command in your terminal: 1 pip install centraal_client_flow This is the preferred method to install centraal-client-flow, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for centraal-client-flow can be downloaded from the Github repo . You can either clone the public repository: 1 git clone git://github.com/centraal-api/centraal_client_flow Or download the tarball : 1 curl -OJL https://github.com/centraal-api/centraal_client_flow/tarball/master Once you have a copy of the source, you can install it with: 1 pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 To use centraal-client-flow in a project 1 import centraal_client_flow","title":"usage"},{"location":"usage/#usage","text":"To use centraal-client-flow in a project 1 import centraal_client_flow","title":"Usage"}]}